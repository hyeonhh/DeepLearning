{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dEBRZtzIiIvt"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as img\n",
        "\n",
        "from torch.utils.data import DataLoader, Dataset, Subset\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"akash2sharma/tiny-imagenet\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "id": "OEYyCdG_7G6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Xvx1-i0b8E5W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd test"
      ],
      "metadata": {
        "id": "Xb6Cowbe8q0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 불러오기\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    # # 이미지 해상도 맞추기\n",
        "    #transforms.Resize(size= (256)),\n",
        "    # transforms.CenterCrop(256),\n",
        "    ]\n",
        ")\n",
        "\n",
        "train_dir = '/kaggle/input/tiny-imagenet/tiny-imagenet-200/train'\n",
        "test_dir = '/kaggle/input/tiny-imagenet/tiny-imagenet-200/test'\n",
        "\n",
        "train_dataset = datasets.ImageFolder(train_dir, transform=transform)\n",
        "\n",
        "# train_dataloader = DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle = True)\n",
        "\n",
        "test_dataset = datasets.ImageFolder(test_dir, transform= transform)\n",
        "# test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle = False)"
      ],
      "metadata": {
        "id": "5ldd4jWqrjFK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_classes = train_dataset.classes[:10]\n",
        "selected_classes\n",
        "\n",
        "# for i , (_, label) in enumerate(train_dataset):\n",
        "\n",
        "#     if label < 10:\n",
        "#         print(label)\n",
        "\n",
        "selected_indices = [i for i, (_, label) in enumerate(train_dataset) if label < 10]\n",
        "selected_indices"
      ],
      "metadata": {
        "collapsed": true,
        "id": "1S3TfmLc_OkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sub_train_dataset = Subset(train_dataset,selected_indices )"
      ],
      "metadata": {
        "id": "AvTs3b6nBYuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지 사이즈 확인하기\n",
        "\n",
        "len(sub_train_dataset.dataset.imgs) # 100000\n"
      ],
      "metadata": {
        "id": "4ZBBPnSysYnx",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_img(img_path):\n",
        "    image = img.imread(fname=img_path)\n",
        "    print(image.shape) # (64, 64, 3)\n",
        "    plt.imshow(image)"
      ],
      "metadata": {
        "id": "i1vt7TPcCrtJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(np.mean(train_dataset.data[:,:,:,2])) # 0 : 125.306918046875, 1 : 122.950394140625, 2 : 113.86538318359375\n",
        "show_img(sub_train_dataset.dataset.imgs[2][0])"
      ],
      "metadata": {
        "id": "0THrWGaG1FY1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_train_dataset = train_dataset.imgs\n",
        "\n",
        "# preprocessed_train_dataset[:,:,:,0] = preprocessed_train_dataset[:,:,:,0] - (125.306918046875)\n",
        "# preprocessed_train_dataset[:,:,:,1] = preprocessed_train_dataset[:,:,:,1] - (122.950394140625)\n",
        "# preprocessed_train_dataset[:,:,:,2] = preprocessed_train_dataset[:,:,:,2] - (113.86538318359375)\n",
        "\n",
        "preprocessed_train_dataset"
      ],
      "metadata": {
        "id": "4BnuLnZi6Xeq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qzD-Zc-758ob"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}