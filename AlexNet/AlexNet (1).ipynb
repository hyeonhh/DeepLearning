{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "yf0kwQ6T5kws"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### 필요한 라이브러리 import하기"
      ],
      "metadata": {
        "id": "KBE8e1VS81pV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dEBRZtzIiIvt"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as img\n",
        "\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torch.utils.data import DataLoader, Dataset, Subset\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####데이터 불러오기"
      ],
      "metadata": {
        "id": "ZXUrJD5e8vxA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"akash2sharma/tiny-imagenet\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "id": "OEYyCdG_7G6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "id": "dUIX0f-iCPjy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Xvx1-i0b8E5W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "    transforms.Resize(size =(224,224)),\n",
        "    # # 이미지 해상도 맞추기\n",
        "    #transforms.Resize(size= (256)),\n",
        "    # transforms.CenterCrop(256),\n",
        "   #MeanSubstractionTransform()\n",
        "    ]\n",
        ")\n",
        "\n",
        "train_dir = path + '/tiny-imagenet-200/tiny-imagenet-200/train'\n",
        "test_dir = path + '/tiny-imagenet-200/tiny-imagenet-200/test'\n"
      ],
      "metadata": {
        "id": "5ldd4jWqrjFK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = datasets.ImageFolder(train_dir, transform=transform)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle = True)\n",
        "\n",
        "test_dataset = datasets.ImageFolder(test_dir, transform= transform)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle = False)"
      ],
      "metadata": {
        "id": "AwWLw7lhqd83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[0][0].shape # torch.Size([3, 224, 224])\n",
        "plt.imshow(train_dataset[0][0].permute(1,2,0)) # C,H,W를 H,W,C순서로 바꿔주기"
      ],
      "metadata": {
        "id": "jC_m4RE74kMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataloader.dataset) # 100000"
      ],
      "metadata": {
        "id": "v_XOaQv3rFRj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_img(img):\n",
        "    plt.imshow(img)"
      ],
      "metadata": {
        "id": "i1vt7TPcCrtJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[0][0].shape # torch.Size([3, 224, 224]), 사이즈가 잘 변경됨."
      ],
      "metadata": {
        "id": "8NFrSYZprJGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 채널별 평균값을 구하고, mean substraction 수행하기"
      ],
      "metadata": {
        "id": "iWptpIdm8qaD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 사용자 정의 transform 만들기\n",
        "\n",
        "class MeanSubstractionTransform:\n",
        "    def __call__(self,img):\n",
        "        print(img.shape)\n",
        "        mean = img.mean(dim=[1,2])  # 각 채널별 행, 열의 평균을 구할 수 있다 1행, 3열 형태이다.\n",
        "        img -= mean.view(3,1,1) # mean을 C : 3개 , H : 1, W : 1의 3x1x1 형태로 바꿔주고 원본 이미지에서 빼기 연산을 수행해준다.\n",
        "\n",
        "        return img"
      ],
      "metadata": {
        "collapsed": true,
        "id": "u7A7POYL8ubE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = torch.randn(3, 224, 224)\n",
        "mean = img.mean(dim=[1,2])  # shape: [3]\n",
        "print(mean)\n",
        "mean.view(3,1,1)"
      ],
      "metadata": {
        "id": "rZeMtQ0R9crA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 신경망 정의하기 (Alexnet)"
      ],
      "metadata": {
        "id": "ncoDz8ROGSWy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Alexnet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        dropout = nn.Dropout(p=0.5)\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=96,kernel_size=(11,11),stride=4)\n",
        "        self.conv2= nn.Conv2d(in_channels=96, out_channels=256, kernel_size=(5,5))\n",
        "        self.conv3= nn.Conv2d(in_channels=256, out_channels=384, kernel_size=(3,3),padding=1)\n",
        "        self.conv4= nn.Conv2d(in_channels=384, out_channels=384, kernel_size=(3,3),padding=1)\n",
        "        self.conv5= nn.Conv2d(in_channels=384, out_channels=256, kernel_size=(3,3),padding = 1)\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(in_features=4096, out_features=4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(in_features = 4096, out_features=4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(in_features = 4096, out_features=1000),\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self,x):\n",
        "        # ---- Conv1 ----\n",
        "        # ReLU\n",
        "        out = F.relu(self.conv1(x))\n",
        "        #  Response Normalization 적용하기\n",
        "        lrn = nn.LocalResponseNorm(size = 5, alpha=10**(-4),beta=0.75,k = 2)\n",
        "        out = lrn(out)\n",
        "        # MaxPooling 적용 (window = 3, stride = 2)\n",
        "        out = F.max_pool2d(input = out,kernel_size=3, stride=2)\n",
        "\n",
        "\n",
        "        # ---- Conv2 ----\n",
        "        out = F.relu(self.conv2(out))\n",
        "        #  Response Normalization 적용하기\n",
        "        out = lrn(out)\n",
        "\n",
        "        # MaxPooling 적용 (window = 3, stride = 2)\n",
        "        out = F.max_pool2d(input = out,kernel_size=3, stride=2)\n",
        "\n",
        "        # ---- Conv3 ----\n",
        "        out = F.relu(self.conv3(out))\n",
        "        out = F.max_pool2d(input = out, kernel_size = 3, stride= 2 )\n",
        "\n",
        "        # ---- Conv4 ----\n",
        "        out = F.relu(self.conv4(out))\n",
        "\n",
        "        # ---- Conv5 ----\n",
        "        out = F.relu(self.conv5(out))\n",
        "\n",
        "        # ---- Flatten ----\n",
        "\n",
        "        out = torch.flatten(out,1)\n",
        "\n",
        "        # ---- Fully Connected layer ----\n",
        "        logits = self.classifier(out)\n",
        "\n",
        "        # ---- softmax ----\n",
        "        probs = F.softmax(logits, dim=1)\n",
        "\n",
        "        return logits, probs\n"
      ],
      "metadata": {
        "id": "Uu08A6SDD9Dp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Alexnet()\n",
        "\n",
        "model"
      ],
      "metadata": {
        "id": "Gg-AziuY4mnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####  Local Response Normalization 함수 구현하기 -> 라이브러리에서 제공"
      ],
      "metadata": {
        "id": "yf0kwQ6T5kws"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vpaG0T9BK_Xo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = torch.randn(3,4,2)\n",
        "print(f'unsqueeze 전 {data.shape}')\n",
        "size = 5\n",
        "\n",
        "data0 = data.unsqueeze(0)\n",
        "data1 = data.unsqueeze(1)\n",
        "\n",
        "print(f'data0 : {data0.shape}')\n",
        "print(f'data1 : {data1.shape}')\n",
        "\n",
        "data0 = F.pad(data0, (0,0,size//2, (size-1)//2))\n",
        "data1 = F.pad(data1, (0,0,size//2, (size-1)//2))\n",
        "\n",
        "data0 = F.avg_pool2d(data0, (size,1),stride = 1)\n",
        "data1 = F.avg_pool2d(data1, (size,1),stride = 1)\n",
        "\n",
        "print(f'avg_pool 후 data0 {data0}')\n",
        "\n",
        "print(f'avg_pool 후 data1 {data1}')\n",
        "\n",
        "data0 = data0.squeeze(0)\n",
        "\n",
        "print(f'squeeze 후 data0 :{data0}')\n",
        "print(f'squeeze 후 data0 : {data0.shape}')"
      ],
      "metadata": {
        "id": "1JkcIukb5mgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = torch.randn(4,4)\n",
        "\n",
        "print(input)\n",
        "\n",
        "input =input.view(2,8).unsqueeze(0)\n",
        "\n",
        "print(input.shape)\n",
        "\n",
        "input = input.squeeze(0)\n",
        "print(input)\n",
        "print(input.shape)\n"
      ],
      "metadata": {
        "id": "Ch92c_atxXUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 손실 함수 & 옵티마이저 정의"
      ],
      "metadata": {
        "id": "odq4JRoOttL2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Alexnet()\n",
        "\n",
        "EPOCH = 10\n",
        "LEARNING_RATE = 1e-5\n",
        "\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(),lr=LEARNING_RATE,momentum=0.9,weight_decay=0.0005)\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "schedular = StepLR(optimizer=optimizer, step_size=1, gamma=0.0001)"
      ],
      "metadata": {
        "id": "Zzv9FuvWtupE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataloader.dataset) # 100000"
      ],
      "metadata": {
        "id": "quZmIpVd67t5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 학습하기"
      ],
      "metadata": {
        "id": "CXG1hXBTtaSv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, dataloader):\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    last_loss = 0.0\n",
        "\n",
        "    for batch , (data,label) in enumerate(dataloader):\n",
        "        print(f'train batch :{batch}')\n",
        "\n",
        "        data = data.to(device)\n",
        "        label = label.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        logits,probs = model(data)\n",
        "        loss = loss_fn(logits,label)\n",
        "\n",
        "       # print(type(loss))  # tensor(6.9069, grad_fn=<NllLossBackward0>) 이렇게 나온다. loss값만 이용하려면 loss.item()을 써주면 된다.\n",
        "\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "       # print(f'loss : {loss.item()}')\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        if batch % 10 == 0: # 데이터 개수가 10000\n",
        "            last_loss  = running_loss / (batch+1)\n",
        "            print(f'train batch {batch} loss {last_loss}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "    return last_loss\n",
        "\n"
      ],
      "metadata": {
        "id": "1GoXQD6P_zW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(model, dataloader):\n",
        "\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for batch, (data, label) in enumerate(dataloader):\n",
        "            data = data.to(device)\n",
        "            label = label.to(device)\n",
        "            logits, probs = model(data)\n",
        "            loss = loss_fn(logits, label)\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            if (batch % 10) == 0:\n",
        "                print(f'validation batch {batch}, loss {running_loss / (batch+1)}')\n",
        "                running_loss = 0.0"
      ],
      "metadata": {
        "id": "JGNS1h017jOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(EPOCH):\n",
        "    print(f'Epoch : {epoch}')\n",
        "\n",
        "    train_model(model, train_dataloader)\n",
        "    validate(model, test_dataloader)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "4aXkraHN0xN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), './model')"
      ],
      "metadata": {
        "id": "VnQ15qeKc81S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model =  Alexnet()\n",
        "model.load_state_dict(torch.load('./model', weights_only=True))\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "EF2GOAJGdFJT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}