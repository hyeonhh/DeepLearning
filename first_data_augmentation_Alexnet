{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":109264,"sourceType":"datasetVersion","datasetId":56828,"isSourceIdPinned":false},{"sourceId":998277,"sourceType":"datasetVersion","datasetId":547506,"isSourceIdPinned":false}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 필요한 라이브러리 불러오기(import)","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport numpy as np\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt\nimport matplotlib.image as img\n\nfrom torch.optim.lr_scheduler import StepLR\nfrom torch.utils.data import DataLoader, Dataset, random_split,Subset\nfrom torchvision import datasets, transforms\nfrom torchvision.transforms import v2\nfrom torch.utils.tensorboard import SummaryWriter\nfrom torch.utils.data import ConcatDataset\n\nfrom sklearn import decomposition\nfrom PIL import Image\nimport os","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T13:06:53.404490Z","iopub.execute_input":"2025-12-05T13:06:53.405091Z","iopub.status.idle":"2025-12-05T13:06:53.410885Z","shell.execute_reply.started":"2025-12-05T13:06:53.405069Z","shell.execute_reply":"2025-12-05T13:06:53.409892Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import kagglehub\n\n# Download latest version\npath = kagglehub.dataset_download(\"akash2sharma/tiny-imagenet\")\n\nprint(\"Path to dataset files:\", path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T10:58:27.612780Z","iopub.execute_input":"2025-11-27T10:58:27.613119Z","iopub.status.idle":"2025-11-27T10:58:28.041396Z","shell.execute_reply.started":"2025-11-27T10:58:27.613082Z","shell.execute_reply":"2025-11-27T10:58:28.040565Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_root = '/kaggle/input/tiny-imagenet/tiny-imagenet-200/train'\n\nall_pixels = []\n\nfor class_id in os.listdir(train_root):\n    class_dir = os.path.join(train_root,class_id,\"images\")\n    if not os.path.isdir(class_dir):\n        continue\n\n    for fname in os.listdir(class_dir):\n        if not fname.lower().endswith((\".jpg\",\".jpeg\",\".png\")):\n            contitnue\n        path = os.path.join(class_dir,fname)\n        img = Image.open(path).convert(\"RGB\")\n        arr = np.array(img,dtype=np.float32) / 255.0\n        pixels = arr.reshape(-1,3)\n        all_pixels.append(pixels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T13:06:56.059796Z","iopub.execute_input":"2025-12-05T13:06:56.060248Z","iopub.status.idle":"2025-12-05T13:06:58.382022Z","shell.execute_reply.started":"2025-12-05T13:06:56.060223Z","shell.execute_reply":"2025-12-05T13:06:58.380825Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_47/2184163662.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mcontitnue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mpixels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3522\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3524\u001b[0;31m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3526\u001b[0m     \u001b[0mpreinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":3},{"cell_type":"code","source":"len(all_pixels) # 100000","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T13:07:00.379725Z","iopub.execute_input":"2025-12-05T13:07:00.380044Z","iopub.status.idle":"2025-12-05T13:07:00.386594Z","shell.execute_reply.started":"2025-12-05T13:07:00.380022Z","shell.execute_reply":"2025-12-05T13:07:00.385705Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"226"},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"# Transform 만들기 ","metadata":{}},{"cell_type":"code","source":"# 사용자 정의 transform 만들기\n\npca = np.load('/kaggle/working/pca_result.npz')\neigen_vector = pca['eigen_vector']\neigen_value = pca['eigen_value']\n\ndef getEigenFactor():\n    \n        img_array = np.array(all_pixels).astype(np.float32)\n        # print(f'(img_array.dtype) : {(img_array.dtype)}') # uint8 -> float32 \n    \n        H,W,C= img_array.shape\n        # print(f'img shape : {img_array.shape}')\n    \n        img_array = img_array.reshape(-1,3) \n        pca = decomposition.PCA(n_components=3)\n        pca.fit(img_array)\n        pca_result = pca.transform(img_array)\n          \n        # 주성분 벡터(고유벡터) , 각 행이 [R,G,B]\n        eigen_vector = pca.components_\n        # print(f'eigen_vector : {eigen_vector}')\n    \n        \n        # 분산(고유값)\n        eigen_value = pca.explained_variance_\n        # print(f'eigen_value : {eigen_value}')\n        \n        return eigen_vector, eigen_value\n\n#eigen_vector , eigen_value = getEigenFactor()\n\nclass AugmentDataPCA():\n\n  def __init__(self):\n    self.std = 0.1\n\n  def __call__(self,img):\n\n    img_arr = np.array(img).astype(np.float32)\n   # print(f'img_arr :{img_arr.shape}') # (224, 224, 3)\n    H,W,C = img_arr.shape\n\n    alpha = np.random.randn(3).astype(np.float32) * self.std\n      \n    delta = eigen_value * alpha \n\n    color_shift = eigen_vector @ delta # principal_components와 delta.T와의 내적합을 구해준다.\n    augmented_img = img_arr + color_shift # img_array에 채널별 계산값을 더해준다.\n      \n    # print(f'augmented_img shape : {augmented_img.shape}') # 50176, 3\n    augmented_img = augmented_img.reshape(H,W,C)\n    # print(f'augmented_img shape : {augmented_img.shape}') # 50176, 3\n\n    augmented_img = np.clip(augmented_img, 0,255).astype(np.uint8)\n\n    return Image.fromarray(augmented_img)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T13:07:09.117378Z","iopub.execute_input":"2025-12-05T13:07:09.118164Z","iopub.status.idle":"2025-12-05T13:07:09.127549Z","shell.execute_reply.started":"2025-12-05T13:07:09.118137Z","shell.execute_reply":"2025-12-05T13:07:09.126566Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"eigen_value\neigen_vector","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T13:07:13.742264Z","iopub.execute_input":"2025-12-05T13:07:13.742590Z","iopub.status.idle":"2025-12-05T13:07:13.748547Z","shell.execute_reply.started":"2025-12-05T13:07:13.742562Z","shell.execute_reply":"2025-12-05T13:07:13.747581Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"array([[ 0.6132164 ,  0.58443445,  0.53141505],\n       [-0.6817293 ,  0.05173409,  0.729773  ],\n       [-0.39901224,  0.80978984, -0.43015045]], dtype=float32)"},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"# PCA 결과 저장 & 불러오기","metadata":{}},{"cell_type":"code","source":"# PCA 결과 저장하기\nimport numpy as np\n\nnp.savez(\"pca_result.npz\",\n         eigen_vector = eigen_vector,\n        eigen_value = eigen_value\n        )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T07:58:35.474855Z","iopub.execute_input":"2025-12-03T07:58:35.475233Z","iopub.status.idle":"2025-12-03T07:58:35.482261Z","shell.execute_reply.started":"2025-12-03T07:58:35.475209Z","shell.execute_reply":"2025-12-03T07:58:35.480887Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize(size =(256,256)),\n    transforms.CenterCrop(size= (224,224)),\n    AugmentDataPCA(),\n    transforms.ToTensor(),\n   # 전체 데이터의 각 채널별 평균 빼주기 \n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\nflip_transform = transforms.Compose([\n    transforms.Resize(size =(256,256)),\n    transforms.CenterCrop(size= (224,224)),\n    transforms.RandomHorizontalFlip(p=1.0),\n    AugmentDataPCA(),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n]\n)\n\ntest_transform = transforms.Compose([\n    transforms.Resize(size =(256,256)),\n    transforms.TenCrop(224),#10개 crop을 tuple로 반환    \n    # (10,3,224,224)형태로 stack\n    transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops])),\n    transforms.Lambda(lambda crops: torch.stack([\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])(c) for c in crops\n    ]))\n    ]\n)\n\n\ntrain_dir = '/kaggle/input/tiny-imagenet/tiny-imagenet-200/train/'\nval_dir = '/kaggle/input/tiny-imagenet/tiny-imagenet-200/val/'\nval_reorg_dir='/kaggle/working/tiny-imagenet/val_reorganized'\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T13:07:17.824355Z","iopub.execute_input":"2025-12-05T13:07:17.824679Z","iopub.status.idle":"2025-12-05T13:07:17.832243Z","shell.execute_reply.started":"2025-12-05T13:07:17.824653Z","shell.execute_reply":"2025-12-05T13:07:17.831356Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"from IPython.utils.path import shutil\nimport os\nimport pandas as pd\n\nval_img_dir = os.path.join(val_dir, 'images')\nval_annotations = os.path.join(val_dir, 'val_annotations.txt')\n\nval_reorg_dir =  '/kaggle/working/tiny-imagenet/val_reorganized'\n\n# annotation 파일 읽기\n\nval_df = pd.read_csv(val_annotations, sep='\\t', header=None,names=['filename','class_id','x','y','w','h'])\n\nfor _,row in val_df.iterrows():\n    filename = row['filename']\n    class_id = row['class_id']\n\n    # 클래스 폴더 생성\n    class_folder = os.path.join(val_reorg_dir, class_id)\n    os.makedirs(class_folder, exist_ok=True)\n\n    # 이미지 복사\n    src = os.path.join(val_img_dir, filename)\n    dst = os.path.join(class_folder, filename)\n\n    shutil.copy(src,dst)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T06:11:03.591786Z","iopub.execute_input":"2025-12-01T06:11:03.592072Z","iopub.status.idle":"2025-12-01T06:12:40.017148Z","shell.execute_reply.started":"2025-12-01T06:11:03.592051Z","shell.execute_reply":"2025-12-01T06:12:40.016513Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 데이터 불러오기 ","metadata":{}},{"cell_type":"code","source":"BATCH_SIZE = 128\ntrain_dataset = datasets.ImageFolder(train_dir, transform=transform)\ntrain_flip_dataset = datasets.ImageFolder(train_dir, transform=flip_transform)\n\nval_dataset = datasets.ImageFolder(val_reorg_dir, transform = test_transform)\n\nfull_train_dataset = ConcatDataset([train_dataset, train_flip_dataset])\n\ntrain_dataloader = DataLoader(full_train_dataset, batch_size = BATCH_SIZE, shuffle = True)#  shuffle: 에포크마다 배치 순서를 섞을지 여부\n\nVAL_BATCH_SIZE = 32\nval_dataloader = DataLoader(val_dataset, batch_size= VAL_BATCH_SIZE, shuffle = False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T13:07:21.290267Z","iopub.execute_input":"2025-12-05T13:07:21.290579Z","iopub.status.idle":"2025-12-05T13:14:02.780863Z","shell.execute_reply.started":"2025-12-05T13:07:21.290555Z","shell.execute_reply":"2025-12-05T13:14:02.780027Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"print(len(val_dataloader.dataset))# 200000\nlen(val_dataset) # 10000\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T01:24:27.169295Z","iopub.execute_input":"2025-12-05T01:24:27.169625Z","iopub.status.idle":"2025-12-05T01:24:27.176904Z","shell.execute_reply.started":"2025-12-05T01:24:27.169600Z","shell.execute_reply":"2025-12-05T01:24:27.175994Z"}},"outputs":[{"name":"stdout","text":"10000\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"10000"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"# print(val_dataset[0][0].shape) # torch.Size([10, 3, 224, 224])\n   \n\n# torch.Size([3, 224, 224])\n# tiny dataset : torch.Size([3, 64, 64]) -> torch.Size([3, 224, 224])로 수정\n\n\nplt.imshow(train_dataloader.dataset[0][0].permute(1,2,0))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T01:24:29.751036Z","iopub.execute_input":"2025-12-05T01:24:29.751585Z","iopub.status.idle":"2025-12-05T01:24:30.164676Z","shell.execute_reply.started":"2025-12-05T01:24:29.751551Z","shell.execute_reply":"2025-12-05T01:24:30.162778Z"}},"outputs":[{"name":"stderr","text":"Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"<matplotlib.image.AxesImage at 0x781c56673510>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":11},{"cell_type":"markdown","source":"# Tiny버전 모델 정의하기","metadata":{}},{"cell_type":"code","source":"class Alexnet_Tiny(nn.Module):\n    def __init__(self):\n        super().__init__()\n        dropout = nn.Dropout(p=0.5),\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64,kernel_size=(11,11),stride=4,padding=2)\n        nn.init.normal_(self.conv1.weight, mean = 0.0, std = 0.01)\n        nn.init.constant_(self.conv1.bias,val=0)\n        self.lrn1 = nn.LocalResponseNorm(size = 5, alpha=10**(-4),beta=0.75,k = 2)\n\n\n        self.conv2= nn.Conv2d(in_channels=64, out_channels=192, kernel_size=(5,5),padding = 2)\n        nn.init.normal_(self.conv2.weight, mean = 0.0, std = 0.01)\n        nn.init.constant_(self.conv2.bias,val=1)\n        self.lrn2 = nn.LocalResponseNorm(size = 5, alpha=10**(-4),beta=0.75,k = 2)\n\n        self.conv3= nn.Conv2d(in_channels=192, out_channels=384, kernel_size=(3,3),padding=1)\n        nn.init.normal_(self.conv3.weight, mean = 0.0, std = 0.01)\n        nn.init.constant_(self.conv3.bias,val=0)\n        \n\n        self.conv4= nn.Conv2d(in_channels=384, out_channels=256, kernel_size=(3,3),padding=1)\n        nn.init.normal_(self.conv4.weight, mean = 0.0, std = 0.01)\n        nn.init.constant_(self.conv4.bias,val=1)\n\n        self.conv5= nn.Conv2d(in_channels=256, out_channels=256, kernel_size=(3,3),padding = 1)\n        nn.init.normal_(self.conv5.weight, mean = 0.0, std = 0.01)\n        nn.init.constant_(self.conv5.bias,val=1)\n\n        self.avgpool = nn.AdaptiveAvgPool2d((6,6))\n        self.fc1= nn.Linear(in_features=256*6*6, out_features=4096)\n        nn.init.constant_(self.fc1.bias,val=1)\n        self.fc2 = nn.Linear(in_features = 4096, out_features=4096)\n        nn.init.constant_(self.fc2.bias,val=1)\n        self.fc3 = nn.Linear(in_features = 4096, out_features=200)\n        nn.init.constant_(self.fc3.bias,val=0)\n        nn.init.normal_(self.fc1.weight, mean=0.0, std=0.01)\n        nn.init.normal_(self.fc2.weight, mean=0.0, std=0.01)\n        nn.init.normal_(self.fc3.weight, mean=0.0, std=0.01)\n\n\n        self.classifier = nn.Sequential(\n            nn.Flatten(),\n            self.fc1,\n            nn.ReLU(),\n            nn.Dropout(p=0.5),\n            self.fc2,\n            nn.ReLU(),\n            nn.Dropout(p=0.5),\n            self.fc3\n        )\n\n\n\n    def forward(self,x):\n        # ---- Conv1 ----\n        # ReLU\n\n        # print(f'x : {x.shape}')\n        out = F.relu(self.conv1(x))\n        #  Response Normalization 적용하기\n        lrn = nn.LocalResponseNorm(size = 5, alpha=10**(-4),beta=0.75,k = 2)\n        out = self.lrn1(out)\n        # MaxPooling 적용 (window = 3, stride = 2)\n        out = F.max_pool2d(input = out, kernel_size=3, stride=2)\n\n       # print(f'conv1 후 : {out.shape}')\n\n\n\n        # ---- Conv2 ----\n        out = F.relu(self.conv2(out))\n        #  Response Normalization 적용하기\n        out = self.lrn2(out)\n\n        # MaxPooling 적용 (window = 3, stride = 2)\n        out = F.max_pool2d(input = out,kernel_size=3, stride=2)\n\n        # print(f'conv2 후 : {out.shape}')\n\n\n        # ---- Conv3 ----\n        out = F.relu(self.conv3(out))\n\n        # print(f'conv3 후 : {out.shape}')\n\n\n        # ---- Conv4 ----\n        out = F.relu(self.conv4(out))\n        # print(f'conv4 후 : {out.shape}')\n\n\n        # ---- Conv5 ----\n        out = F.relu(self.conv5(out))\n        out = F.max_pool2d(input = out, kernel_size = 3, stride= 2 )\n\n        # print(f'conv5 후 : {out.shape}')\n\n\n        # ---- Fully Connected layer ----\n        logits = self.classifier(out)\n\n        # print(f'logits : {logits.shape}')\n\n        # ---- softmax ----\n        #probs = F.softmax(logits, dim=1)\n\n        return logits\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T01:25:25.421890Z","iopub.execute_input":"2025-12-05T01:25:25.422278Z","iopub.status.idle":"2025-12-05T01:25:25.440585Z","shell.execute_reply.started":"2025-12-05T01:25:25.422254Z","shell.execute_reply":"2025-12-05T01:25:25.439093Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"class Alexnet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        dropout = nn.Dropout(p=0.5),\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=96,kernel_size=(11,11),stride=4,padding=2)\n        nn.init.normal_(self.conv1.weight, mean = 0.0, std = 0.01)\n        nn.init.constant_(self.conv1.bias,val=0)\n\n        self.conv2= nn.Conv2d(in_channels=96, out_channels=256, kernel_size=(5,5),padding = 2)\n        nn.init.normal_(self.conv2.weight, mean = 0.0, std = 0.01)\n        nn.init.constant_(self.conv2.bias,val=1)\n        self.conv3= nn.Conv2d(in_channels=256, out_channels=384, kernel_size=(3,3),padding=1)\n        nn.init.normal_(self.conv3.weight, mean = 0.0, std = 0.01)\n        nn.init.constant_(self.conv3.bias,val=0)\n\n        self.conv4= nn.Conv2d(in_channels=384, out_channels=384, kernel_size=(3,3),padding=1)\n        nn.init.normal_(self.conv4.weight, mean = 0.0, std = 0.01)\n        nn.init.constant_(self.conv4.bias,val=1)\n\n        self.conv5= nn.Conv2d(in_channels=384, out_channels=256, kernel_size=(3,3),padding = 1)\n        nn.init.normal_(self.conv5.weight, mean = 0.0, std = 0.01)\n        nn.init.constant_(self.conv5.bias,val=1)\n\n        self.fc1= nn.Linear(in_features=256*6*6, out_features=4096)\n        nn.init.constant_(self.fc1.bias,val=1)\n        self.fc2 = nn.Linear(in_features = 4096, out_features=4096)\n        nn.init.constant_(self.fc2.bias,val=1)\n        self.fc3 = nn.Linear(in_features = 4096, out_features=200)\n        nn.init.constant_(self.fc3.bias,val=0)\n\n\n        self.classifier = nn.Sequential(\n            nn.Flatten(),\n            self.fc1,\n            nn.ReLU(),\n            nn.Dropout(p=0.5),\n            self.fc2,\n            nn.ReLU(),\n            nn.Dropout(p=0.5),\n            self.fc3\n        )\n\n\n\n    def forward(self,x):\n        # ---- Conv1 ----\n        # ReLU\n\n        print(f'x : {x.shape}')\n        out = F.relu(self.conv1(x))\n        #  Response Normalization 적용하기\n        lrn = nn.LocalResponseNorm(size = 5, alpha=10**(-4),beta=0.75,k = 2)\n        out = lrn(out)\n        # MaxPooling 적용 (window = 3, stride = 2)\n        out = F.max_pool2d(input = out, kernel_size=3, stride=2)\n\n        print(f'conv1 후 : {out.shape}')\n\n\n\n        # ---- Conv2 ----\n        out = F.relu(self.conv2(out))\n        #  Response Normalization 적용하기\n        out = lrn(out)\n\n        # MaxPooling 적용 (window = 3, stride = 2)\n        out = F.max_pool2d(input = out,kernel_size=3, stride=2)\n\n        print(f'conv2 후 : {out.shape}')\n\n\n        # ---- Conv3 ----\n        out = F.relu(self.conv3(out))\n\n        print(f'conv3 후 : {out.shape}')\n\n\n        # ---- Conv4 ----\n        out = F.relu(self.conv4(out))\n        print(f'conv4 후 : {out.shape}')\n\n\n        # ---- Conv5 ----\n        out = F.relu(self.conv5(out))\n        out = F.max_pool2d(input = out, kernel_size = 3, stride= 2 )\n\n        print(f'conv5 후 : {out.shape}')\n\n\n        # ---- Fully Connected layer ----\n        logits = self.classifier(out)\n\n        print(f'logits : {logits.shape}')\n\n        # ---- softmax ----\n        probs = F.softmax(logits, dim=1)\n\n        return logits, probs\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T11:20:14.844860Z","iopub.execute_input":"2025-11-27T11:20:14.845155Z","iopub.status.idle":"2025-11-27T11:20:14.859359Z","shell.execute_reply.started":"2025-11-27T11:20:14.845135Z","shell.execute_reply":"2025-11-27T11:20:14.858595Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# # tpu용\n# device = xm.xla_device() \n\nmodel = Alexnet_Tiny().to(device)# 먼저 모델을 디바이스로 보내기 \n\nEPOCH = 30\n\nLEARNING_RATE = 1e-3 # validation loss에 따라 조절하기\n\nloss_fn = torch.nn.CrossEntropyLoss()\n#optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=0.9) # 그 다음 optimizer 만들기 \n# # 또는\noptimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n\n#schedular = StepLR(optimizer=optimizer, step_size=1, gamma=0.0001)\n\nwriter = SummaryWriter()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T01:40:34.156101Z","iopub.execute_input":"2025-12-05T01:40:34.156525Z","iopub.status.idle":"2025-12-05T01:40:35.256741Z","shell.execute_reply.started":"2025-12-05T01:40:34.156487Z","shell.execute_reply":"2025-12-05T01:40:35.255574Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"def train_model(model, data,label):\n  \n  model.train()\n\n  running_loss = 0.0\n  last_loss = 0.0\n  true_prediction = 0\n\n\n  data ,label = data.to(device),label.to(device)\n\n  optimizer.zero_grad()\n\n  logits = model(data)\n  loss = loss_fn(logits,label)\n\n \n  loss.backward()\n  optimizer.step()\n\n # 정확도 계산\n  label, logits = label.cpu().detach().numpy(), logits.cpu().detach().numpy()\n\n  label_predict = np.argmax(logits,axis=1)\n\n  true_prediction = np.sum(label == label_predict)\n  train_loss = loss.item()\n\n  return train_loss , true_prediction\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T01:40:37.059203Z","iopub.execute_input":"2025-12-05T01:40:37.059546Z","iopub.status.idle":"2025-12-05T01:40:37.067888Z","shell.execute_reply.started":"2025-12-05T01:40:37.059520Z","shell.execute_reply":"2025-12-05T01:40:37.066095Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"def validate(model,data,label):\n\n    model.eval()\n\n    running_loss = 0.0\n    last_loss= 0.0\n    true_prediction = 0\n\n    # print(f'val - before view : {data.shape}')\n\n    B,flip,C,H,W = data.shape\n    \n    data = data.view(-1, C,H,W)\n    # print(f'val after view : {data.shape}')\n\n    data ,label = data.to(device),  label.to(device)\n    logits = model(data) # bx10 , num_classes\n    # print(f'logits1.shape : {logits.shape}')\n    logits = logits.view(B,flip,-1)\n    # print(f'logits2.shape : {logits.shape}')\n\n    logits_mean = logits.mean(1)\n\n    \n    # print(f'logits_mean.shape : {logits_mean.shape}')\n\n    loss = loss_fn(logits_mean, label)\n\n    label = label.to('cpu').detach().numpy()\n\n    logits_mean = logits_mean.to('cpu').detach().numpy()\n\n    # print(f'logits : {logits}')\n\n    prob_label = np.argmax(logits_mean,axis = 1)\n    print(f'VAL : 예측라벨 : {prob_label}, 정답 {label}')\n\n    true_prediction = np.sum(label == prob_label)\n    val_loss = loss.item()\n    \n    return val_loss , true_prediction\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T06:23:16.483862Z","iopub.execute_input":"2025-12-05T06:23:16.484196Z","iopub.status.idle":"2025-12-05T06:23:16.493736Z","shell.execute_reply.started":"2025-12-05T06:23:16.484176Z","shell.execute_reply":"2025-12-05T06:23:16.492643Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"def valAugmentation(img):\n    crop_size = 224\n    five_crop = v2.TenCrop(crop_size)\n    ten_cropped_img = five_crop(img)\n\n    plt.imshow(ten_cropped_img)\n    return ten_cropped_img\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T13:27:56.581088Z","iopub.execute_input":"2025-11-30T13:27:56.581678Z","iopub.status.idle":"2025-11-30T13:27:56.585458Z","shell.execute_reply.started":"2025-11-30T13:27:56.581654Z","shell.execute_reply":"2025-11-30T13:27:56.584729Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test = torch.rand(3,3)\nprint(test)\nprint(test.sum())\nprint(test.sum(dim=[0]))\n\nprint(test.size(0))\nprint(test.sum(dim=[0])/test.size(0))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T12:54:45.420874Z","iopub.execute_input":"2025-11-26T12:54:45.421624Z","iopub.status.idle":"2025-11-26T12:54:45.435192Z","shell.execute_reply.started":"2025-11-26T12:54:45.421597Z","shell.execute_reply":"2025-11-26T12:54:45.434598Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"total_img_value = torch.zeros(3)\ntotal_pixels =  0\n\nfor batch,(data,label) in enumerate(val_dataloader):\n\n    # print(data.shape) # torch.Size([120, 3, 224, 224])\n\n    total_img_value += data.sum(dim=[0,2,3]) # dim을 한꺼번에 모두 더함 \n    total_pixels += data.size(0) * data.size(2) * data.size(3)\n\nmean = total_img_value/total_pixels\n\nmean","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T06:18:37.723789Z","iopub.execute_input":"2025-11-26T06:18:37.724518Z","iopub.status.idle":"2025-11-26T06:19:34.811753Z","shell.execute_reply.started":"2025-11-26T06:18:37.724490Z","shell.execute_reply":"2025-11-26T06:19:34.810982Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def unnormalize(img, mean, std):\n    img = img.clone()\n    for t, m, s in zip(img, mean, std):\n        t.mul_(s).add_(m)\n    return img\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T08:39:56.259128Z","iopub.execute_input":"2025-11-26T08:39:56.259678Z","iopub.status.idle":"2025-11-26T08:39:56.263674Z","shell.execute_reply.started":"2025-11-26T08:39:56.259655Z","shell.execute_reply":"2025-11-26T08:39:56.262934Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(train_dataset.transform)\n\nimg = unnormalize(train_dataset[0][0], [0.4777, 0.4520, 0.4032], [1.0,1.0,1.0])\n\n# 또는\nprint(img.shape, img.min(), img.max())\n\nplt.imshow(img.permute(1,2,0))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T06:05:03.632319Z","iopub.execute_input":"2025-12-01T06:05:03.632927Z","iopub.status.idle":"2025-12-01T06:05:03.652761Z","shell.execute_reply.started":"2025-12-01T06:05:03.632880Z","shell.execute_reply":"2025-12-01T06:05:03.651854Z"},"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for data, label in train_dataloader:\n    print(label.min(), label.max())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T12:56:11.014193Z","iopub.execute_input":"2025-11-26T12:56:11.014501Z","iopub.status.idle":"2025-11-26T12:56:18.984007Z","shell.execute_reply.started":"2025-11-26T12:56:11.014462Z","shell.execute_reply":"2025-11-26T12:56:18.982965Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Early Stopping 구현하기 \n\n- 4시간 넘게 돌렸는데 val accuracy가 좋아지지 않았다 - early stopping 추가해서 더이상 올라가지 않으면 종료하기 ","metadata":{}},{"cell_type":"code","source":"class EarlyStopping:\n    def __init__(self,patience = 10, verbose=False, delta=0,path = 'checkpoing.pt',trace_func=print):\n        self.patience= patience\n        self.verbose = verbose # True이면 개선 시마다 메시지 출력 \n        self.delta = delta # 개선으로 인정할 최소 변화량 \n        self.path = path\n        self.trace_func = trace_func\n\n        self.best_val_accuracy = None\n        self.early_stop = False\n        self.val_accuracy_max = - np.inf\n        self.counter = 0\n    def __call__(self, val_accuracy, model):\n        if np.isnan(val_accuracy):\n            self.trace_func(\"Validation accuracy is NaN. Ignoring this epoch\")\n            return \n        if self.best_val_accuracy is None :\n            self.best_val_accuracy = val_accuracy\n            self.save_checkpoint(self.best_val_accuracy, model)\n        elif val_accuracy >  self.best_val_accuracy + self.delta:\n            self.best_val_accuracy = val_accuracy\n            self.save_checkpoint(val_accuracy,model)\n            self.counter = 0 \n        else:\n            self.counter += 1\n            self.trace_func(f'EarlyStopping counter : {self.counter} out of {self.patience}')\n            if self.counter >= self.patience:\n                self.early_stop = True\n    def save_checkpoint(self,val_accuracy, model):\n        if self.verbose:\n            self.trace_func(f'Validation accuracy increased {self.best_val_accuracy} -> {val_accuracy}. Saving Model...' \n                           )\n            torch.save(model.state_dict(),self.path)\n            self.best_val_accuracy = val_accuracy\n\nearly_stopping = EarlyStopping(patience = 15,verbose = True, delta = 1e-3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T02:20:22.224849Z","iopub.execute_input":"2025-11-29T02:20:22.225647Z","iopub.status.idle":"2025-11-29T02:20:22.232198Z","shell.execute_reply.started":"2025-11-29T02:20:22.225610Z","shell.execute_reply":"2025-11-29T02:20:22.231426Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"start_epoch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T06:02:11.565554Z","iopub.execute_input":"2025-12-03T06:02:11.565805Z","iopub.status.idle":"2025-12-03T06:02:11.589460Z","shell.execute_reply.started":"2025-12-03T06:02:11.565785Z","shell.execute_reply":"2025-12-03T06:02:11.588771Z"}},"outputs":[{"traceback":["\u001b[31m---------------------------------------------------------------------------\u001b[39m","\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)","\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[75]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mstart_epoch\u001b[49m\n","\u001b[31mNameError\u001b[39m: name 'start_epoch' is not defined"],"ename":"NameError","evalue":"name 'start_epoch' is not defined","output_type":"error"}],"execution_count":75},{"cell_type":"code","source":"batch_train_losses = []\nbatch_val_losses = []\nbatch_train_accuracies = []\nbatch_val_accuracies = []\n\n\n# epoch_train_losses = []\n# epoch_val_losses = []\n# epoch_train_accuracies = []\n# epoch_val_accuracies = []\n\n\n\n#start_epoch = 0\n\nfor epoch in range(start_epoch, EPOCH):\n\n      epoch_train_loss = 0.0\n      epoch_train_accuracy = 0.0\n      epoch_true_prediction= 0\n      epoch_total = 0\n\n      epoch_val_loss = 0.0\n      epoch_val_accuracy = 0.0\n      epoch_val_true_prediction= 0\n      epoch_val_total = 0\n\n      for batch , (train_data,train_label) in enumerate(train_dataloader):\n\n        global_step = epoch * len(train_dataloader) + batch\n        # 총 batch가 200번 반복됨 , 에포크 5니까 총 1000번 반복됨.\n        print(f'Epoch : {epoch}, batch {batch}')\n        train_loss , batch_true_prediction = train_model(model,train_data,train_label)\n\n        batch_size = train_label.shape[0]\n\n        epoch_train_loss += train_loss\n        epoch_true_prediction += batch_true_prediction\n        epoch_total += batch_size\n\n        # 각 배치별 스칼라 기록\n        batch_train_accuracy = batch_true_prediction / batch_size\n\n        batch_train_losses.append(train_loss)\n        batch_train_accuracies.append(batch_train_accuracy)\n\n        print(f'(Train) Batch {batch} Loss : {train_loss}, 맞은 개수 : {batch_true_prediction}')\n        writer.add_scalar(\"Batch별 Loss/Train\", train_loss, global_step)\n        writer.add_scalar(\"Batch별 Accuracy/Train\", batch_train_accuracy,global_step)\n\n      # 각 에포크별 스칼라 기록\n      epoch_train_losses.append(epoch_train_loss / len(train_dataloader))#배치의 개수로 나누면 됨\n      epoch_train_accuracies.append(epoch_true_prediction / epoch_total)\n    \n      writer.add_scalar(\"Epoch별 Loss/Train\", epoch_train_loss / len(train_dataloader), epoch)\n      writer.add_scalar(\"Epoch별 Accuracy/Train\", epoch_true_prediction / epoch_total,epoch)\n      print(f'epoch {epoch} Loss/Train :{epoch_train_loss / len(train_dataloader)} ')\n      print(f'epoch {epoch} Accuracy/Train : {epoch_true_prediction / epoch_total}')\n\n\n    # 정확도 추가하자\n      with torch.no_grad():\n        for batch,(val_data,val_label) in enumerate(val_dataloader):\n          # print(\"data shape:\", val_data.shape, \"label shape:\", val_label.shape)\n          global_step = epoch * len(val_dataloader) + batch\n          val_loss , val_true_predction = validate(model,val_data,val_label)\n          batch_size = val_label.shape[0]\n          epoch_val_loss+= val_loss\n          epoch_val_true_prediction += val_true_predction\n          epoch_val_total += batch_size\n\n          print(f'(VAL) Batch {batch} Loss : {val_loss}, accuracy: {val_true_predction/batch_size}')\n          batch_val_losses.append(val_loss)\n          batch_val_accuracies.append(val_true_predction/batch_size)\n          writer.add_scalar(\"Batch별 Loss/Validate\", val_loss, global_step)\n          writer.add_scalar(\"Batch별 Accuracy/Validate Batch\", val_true_predction/batch_size,global_step)\n\n        epoch_val_losses.append(epoch_val_loss/len(val_dataloader))\n        epoch_val_accuracies.append(epoch_val_true_prediction/epoch_val_total)\n\n       # early_stopping(val_accuracy = epoch_val_true_prediction/epoch_val_total, model = model)\n     \n        writer.add_scalar(\"Epoch별 Loss/Validate\", epoch_val_loss/len(val_dataloader), epoch)\n        writer.add_scalar(\"Epoch별 Accuracy/Validate\", epoch_val_true_prediction/epoch_val_total,epoch)\n        print(f'epoch {epoch} Loss/Validate :{epoch_val_loss/len(val_dataloader)} ')\n        print(f'epoch {epoch} Accuracy/Validate : {epoch_val_true_prediction/epoch_val_total}')\n        \n        torch.save(\n    {'epoch' : EPOCH,\n    'model_state_dict':model.state_dict(),\n    'optimizer' : optimizer.state_dict()}\n   ,'alexnet_ckpt.pth')\n\n        # if early_stopping.early_stop:\n        #     print(f'Early Stopped : {epoch} ')\n        #     break\n\n\nwriter.flush()\n\n\n%load_ext tensorboard\n%tensorboard --logdir=runs\n\nwriter.close()\n\n# https://ysg2997.tistory.com/16","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T06:25:25.341212Z","iopub.execute_input":"2025-12-05T06:25:25.341559Z"}},"outputs":[{"name":"stdout","text":"Epoch : 3, batch 0\n(Train) Batch 0 Loss : 3.2981534004211426, 맞은 개수 : 31\nEpoch : 3, batch 1\n(Train) Batch 1 Loss : 3.1935384273529053, 맞은 개수 : 40\nEpoch : 3, batch 2\n(Train) Batch 2 Loss : 2.9246139526367188, 맞은 개수 : 43\nEpoch : 3, batch 3\n(Train) Batch 3 Loss : 3.3291547298431396, 맞은 개수 : 28\nEpoch : 3, batch 4\n(Train) Batch 4 Loss : 3.173676013946533, 맞은 개수 : 34\nEpoch : 3, batch 5\n(Train) Batch 5 Loss : 3.204052209854126, 맞은 개수 : 35\nEpoch : 3, batch 6\n(Train) Batch 6 Loss : 3.225632667541504, 맞은 개수 : 34\nEpoch : 3, batch 7\n(Train) Batch 7 Loss : 3.0827722549438477, 맞은 개수 : 36\nEpoch : 3, batch 8\n(Train) Batch 8 Loss : 3.3177685737609863, 맞은 개수 : 32\nEpoch : 3, batch 9\n(Train) Batch 9 Loss : 3.025831937789917, 맞은 개수 : 39\nEpoch : 3, batch 10\n(Train) Batch 10 Loss : 3.3381943702697754, 맞은 개수 : 31\nEpoch : 3, batch 11\n(Train) Batch 11 Loss : 3.3335494995117188, 맞은 개수 : 36\nEpoch : 3, batch 12\n(Train) Batch 12 Loss : 3.126333713531494, 맞은 개수 : 46\nEpoch : 3, batch 13\n(Train) Batch 13 Loss : 3.380134105682373, 맞은 개수 : 36\nEpoch : 3, batch 14\n(Train) Batch 14 Loss : 3.322291851043701, 맞은 개수 : 27\nEpoch : 3, batch 15\n(Train) Batch 15 Loss : 3.0103392601013184, 맞은 개수 : 37\nEpoch : 3, batch 16\n(Train) Batch 16 Loss : 3.1395163536071777, 맞은 개수 : 37\nEpoch : 3, batch 17\n(Train) Batch 17 Loss : 3.2765920162200928, 맞은 개수 : 33\nEpoch : 3, batch 18\n(Train) Batch 18 Loss : 3.193429708480835, 맞은 개수 : 29\nEpoch : 3, batch 19\n(Train) Batch 19 Loss : 3.3857650756835938, 맞은 개수 : 31\nEpoch : 3, batch 20\n(Train) Batch 20 Loss : 2.9177539348602295, 맞은 개수 : 46\nEpoch : 3, batch 21\n(Train) Batch 21 Loss : 2.9023544788360596, 맞은 개수 : 42\nEpoch : 3, batch 22\n(Train) Batch 22 Loss : 3.2771823406219482, 맞은 개수 : 30\nEpoch : 3, batch 23\n(Train) Batch 23 Loss : 2.9504427909851074, 맞은 개수 : 35\nEpoch : 3, batch 24\n(Train) Batch 24 Loss : 2.8149025440216064, 맞은 개수 : 45\nEpoch : 3, batch 25\n(Train) Batch 25 Loss : 3.0870089530944824, 맞은 개수 : 38\nEpoch : 3, batch 26\n(Train) Batch 26 Loss : 3.153515577316284, 맞은 개수 : 40\nEpoch : 3, batch 27\n(Train) Batch 27 Loss : 2.9451704025268555, 맞은 개수 : 38\nEpoch : 3, batch 28\n(Train) Batch 28 Loss : 3.2330830097198486, 맞은 개수 : 32\nEpoch : 3, batch 29\n(Train) Batch 29 Loss : 2.8664729595184326, 맞은 개수 : 44\nEpoch : 3, batch 30\n(Train) Batch 30 Loss : 3.3268086910247803, 맞은 개수 : 27\nEpoch : 3, batch 31\n(Train) Batch 31 Loss : 3.328453302383423, 맞은 개수 : 25\nEpoch : 3, batch 32\n(Train) Batch 32 Loss : 3.326368808746338, 맞은 개수 : 21\nEpoch : 3, batch 33\n(Train) Batch 33 Loss : 3.0702836513519287, 맞은 개수 : 39\nEpoch : 3, batch 34\n(Train) Batch 34 Loss : 2.9808924198150635, 맞은 개수 : 40\nEpoch : 3, batch 35\n(Train) Batch 35 Loss : 3.2292683124542236, 맞은 개수 : 39\nEpoch : 3, batch 36\n(Train) Batch 36 Loss : 3.1482138633728027, 맞은 개수 : 42\nEpoch : 3, batch 37\n(Train) Batch 37 Loss : 2.772742509841919, 맞은 개수 : 45\nEpoch : 3, batch 38\n(Train) Batch 38 Loss : 3.2269837856292725, 맞은 개수 : 30\nEpoch : 3, batch 39\n(Train) Batch 39 Loss : 3.033647060394287, 맞은 개수 : 38\nEpoch : 3, batch 40\n(Train) Batch 40 Loss : 3.2516376972198486, 맞은 개수 : 31\nEpoch : 3, batch 41\n(Train) Batch 41 Loss : 3.1488606929779053, 맞은 개수 : 40\nEpoch : 3, batch 42\n(Train) Batch 42 Loss : 3.153501033782959, 맞은 개수 : 36\nEpoch : 3, batch 43\n(Train) Batch 43 Loss : 3.0398049354553223, 맞은 개수 : 34\nEpoch : 3, batch 44\n(Train) Batch 44 Loss : 3.0125272274017334, 맞은 개수 : 32\nEpoch : 3, batch 45\n(Train) Batch 45 Loss : 2.836319923400879, 맞은 개수 : 41\nEpoch : 3, batch 46\n(Train) Batch 46 Loss : 2.9572043418884277, 맞은 개수 : 41\nEpoch : 3, batch 47\n(Train) Batch 47 Loss : 3.3796639442443848, 맞은 개수 : 29\nEpoch : 3, batch 48\n(Train) Batch 48 Loss : 3.141343832015991, 맞은 개수 : 33\nEpoch : 3, batch 49\n(Train) Batch 49 Loss : 3.036780834197998, 맞은 개수 : 39\nEpoch : 3, batch 50\n(Train) Batch 50 Loss : 2.9170217514038086, 맞은 개수 : 45\nEpoch : 3, batch 51\n(Train) Batch 51 Loss : 3.341005325317383, 맞은 개수 : 34\nEpoch : 3, batch 52\n(Train) Batch 52 Loss : 3.248410940170288, 맞은 개수 : 33\nEpoch : 3, batch 53\n(Train) Batch 53 Loss : 3.06874418258667, 맞은 개수 : 39\nEpoch : 3, batch 54\n(Train) Batch 54 Loss : 3.370156764984131, 맞은 개수 : 29\nEpoch : 3, batch 55\n(Train) Batch 55 Loss : 3.02455997467041, 맞은 개수 : 33\nEpoch : 3, batch 56\n(Train) Batch 56 Loss : 3.1011645793914795, 맞은 개수 : 40\nEpoch : 3, batch 57\n(Train) Batch 57 Loss : 3.0751466751098633, 맞은 개수 : 41\nEpoch : 3, batch 58\n(Train) Batch 58 Loss : 3.071732997894287, 맞은 개수 : 35\nEpoch : 3, batch 59\n(Train) Batch 59 Loss : 3.105882167816162, 맞은 개수 : 38\nEpoch : 3, batch 60\n(Train) Batch 60 Loss : 2.9541778564453125, 맞은 개수 : 37\nEpoch : 3, batch 61\n(Train) Batch 61 Loss : 3.037846326828003, 맞은 개수 : 33\nEpoch : 3, batch 62\n(Train) Batch 62 Loss : 3.207263469696045, 맞은 개수 : 31\nEpoch : 3, batch 63\n(Train) Batch 63 Loss : 2.9602420330047607, 맞은 개수 : 33\nEpoch : 3, batch 64\n(Train) Batch 64 Loss : 3.1035995483398438, 맞은 개수 : 39\nEpoch : 3, batch 65\n(Train) Batch 65 Loss : 3.2998502254486084, 맞은 개수 : 31\nEpoch : 3, batch 66\n(Train) Batch 66 Loss : 3.1581180095672607, 맞은 개수 : 33\nEpoch : 3, batch 67\n(Train) Batch 67 Loss : 3.21053147315979, 맞은 개수 : 28\nEpoch : 3, batch 68\n(Train) Batch 68 Loss : 2.915975570678711, 맞은 개수 : 46\nEpoch : 3, batch 69\n(Train) Batch 69 Loss : 2.8592302799224854, 맞은 개수 : 46\nEpoch : 3, batch 70\n(Train) Batch 70 Loss : 3.314228057861328, 맞은 개수 : 30\nEpoch : 3, batch 71\n(Train) Batch 71 Loss : 3.264958381652832, 맞은 개수 : 31\nEpoch : 3, batch 72\n(Train) Batch 72 Loss : 3.079360008239746, 맞은 개수 : 44\nEpoch : 3, batch 73\n(Train) Batch 73 Loss : 3.0092215538024902, 맞은 개수 : 43\nEpoch : 3, batch 74\n(Train) Batch 74 Loss : 3.0663845539093018, 맞은 개수 : 36\nEpoch : 3, batch 75\n(Train) Batch 75 Loss : 3.141836643218994, 맞은 개수 : 39\nEpoch : 3, batch 76\n(Train) Batch 76 Loss : 3.105196952819824, 맞은 개수 : 41\nEpoch : 3, batch 77\n(Train) Batch 77 Loss : 2.735802173614502, 맞은 개수 : 49\nEpoch : 3, batch 78\n(Train) Batch 78 Loss : 3.0626978874206543, 맞은 개수 : 36\nEpoch : 3, batch 79\n(Train) Batch 79 Loss : 2.924229383468628, 맞은 개수 : 44\nEpoch : 3, batch 80\n(Train) Batch 80 Loss : 3.462893009185791, 맞은 개수 : 29\nEpoch : 3, batch 81\n(Train) Batch 81 Loss : 3.451909065246582, 맞은 개수 : 28\nEpoch : 3, batch 82\n(Train) Batch 82 Loss : 3.537529945373535, 맞은 개수 : 35\nEpoch : 3, batch 83\n(Train) Batch 83 Loss : 3.0591282844543457, 맞은 개수 : 42\nEpoch : 3, batch 84\n(Train) Batch 84 Loss : 3.3275482654571533, 맞은 개수 : 28\nEpoch : 3, batch 85\n(Train) Batch 85 Loss : 3.080301284790039, 맞은 개수 : 37\nEpoch : 3, batch 86\n(Train) Batch 86 Loss : 3.218808174133301, 맞은 개수 : 34\nEpoch : 3, batch 87\n(Train) Batch 87 Loss : 3.1900110244750977, 맞은 개수 : 33\nEpoch : 3, batch 88\n(Train) Batch 88 Loss : 2.981396436691284, 맞은 개수 : 38\nEpoch : 3, batch 89\n(Train) Batch 89 Loss : 3.3289079666137695, 맞은 개수 : 32\nEpoch : 3, batch 90\n(Train) Batch 90 Loss : 3.042950391769409, 맞은 개수 : 39\nEpoch : 3, batch 91\n(Train) Batch 91 Loss : 3.095576286315918, 맞은 개수 : 32\nEpoch : 3, batch 92\n(Train) Batch 92 Loss : 3.4406380653381348, 맞은 개수 : 26\nEpoch : 3, batch 93\n(Train) Batch 93 Loss : 3.0798771381378174, 맞은 개수 : 35\nEpoch : 3, batch 94\n(Train) Batch 94 Loss : 3.2112700939178467, 맞은 개수 : 33\nEpoch : 3, batch 95\n(Train) Batch 95 Loss : 3.1191422939300537, 맞은 개수 : 38\nEpoch : 3, batch 96\n(Train) Batch 96 Loss : 3.3748152256011963, 맞은 개수 : 30\nEpoch : 3, batch 97\n(Train) Batch 97 Loss : 3.054626226425171, 맞은 개수 : 38\nEpoch : 3, batch 98\n(Train) Batch 98 Loss : 2.9716908931732178, 맞은 개수 : 39\nEpoch : 3, batch 99\n(Train) Batch 99 Loss : 3.2345213890075684, 맞은 개수 : 33\nEpoch : 3, batch 100\n(Train) Batch 100 Loss : 3.236694574356079, 맞은 개수 : 34\nEpoch : 3, batch 101\n(Train) Batch 101 Loss : 3.176548957824707, 맞은 개수 : 30\nEpoch : 3, batch 102\n(Train) Batch 102 Loss : 2.7819275856018066, 맞은 개수 : 45\nEpoch : 3, batch 103\n(Train) Batch 103 Loss : 3.007107973098755, 맞은 개수 : 35\nEpoch : 3, batch 104\n(Train) Batch 104 Loss : 3.4873952865600586, 맞은 개수 : 31\nEpoch : 3, batch 105\n(Train) Batch 105 Loss : 3.2457518577575684, 맞은 개수 : 34\nEpoch : 3, batch 106\n(Train) Batch 106 Loss : 2.807847023010254, 맞은 개수 : 43\nEpoch : 3, batch 107\n(Train) Batch 107 Loss : 3.0633151531219482, 맞은 개수 : 32\nEpoch : 3, batch 108\n(Train) Batch 108 Loss : 2.9317634105682373, 맞은 개수 : 43\nEpoch : 3, batch 109\n(Train) Batch 109 Loss : 2.955833911895752, 맞은 개수 : 41\nEpoch : 3, batch 110\n(Train) Batch 110 Loss : 3.0069239139556885, 맞은 개수 : 35\nEpoch : 3, batch 111\n(Train) Batch 111 Loss : 3.113508701324463, 맞은 개수 : 38\nEpoch : 3, batch 112\n(Train) Batch 112 Loss : 2.8782801628112793, 맞은 개수 : 42\nEpoch : 3, batch 113\n(Train) Batch 113 Loss : 3.2625579833984375, 맞은 개수 : 27\nEpoch : 3, batch 114\n(Train) Batch 114 Loss : 3.1317851543426514, 맞은 개수 : 37\nEpoch : 3, batch 115\n(Train) Batch 115 Loss : 3.25060772895813, 맞은 개수 : 29\nEpoch : 3, batch 116\n(Train) Batch 116 Loss : 3.2424542903900146, 맞은 개수 : 29\nEpoch : 3, batch 117\n(Train) Batch 117 Loss : 2.7986299991607666, 맞은 개수 : 42\nEpoch : 3, batch 118\n(Train) Batch 118 Loss : 3.3178226947784424, 맞은 개수 : 32\nEpoch : 3, batch 119\n(Train) Batch 119 Loss : 3.3476409912109375, 맞은 개수 : 33\nEpoch : 3, batch 120\n(Train) Batch 120 Loss : 2.9480292797088623, 맞은 개수 : 35\nEpoch : 3, batch 121\n(Train) Batch 121 Loss : 2.9219563007354736, 맞은 개수 : 42\nEpoch : 3, batch 122\n(Train) Batch 122 Loss : 3.445880889892578, 맞은 개수 : 27\nEpoch : 3, batch 123\n(Train) Batch 123 Loss : 3.2788338661193848, 맞은 개수 : 34\nEpoch : 3, batch 124\n(Train) Batch 124 Loss : 3.26810884475708, 맞은 개수 : 35\nEpoch : 3, batch 125\n(Train) Batch 125 Loss : 3.1890804767608643, 맞은 개수 : 36\nEpoch : 3, batch 126\n(Train) Batch 126 Loss : 3.2674953937530518, 맞은 개수 : 38\nEpoch : 3, batch 127\n(Train) Batch 127 Loss : 3.0917301177978516, 맞은 개수 : 39\nEpoch : 3, batch 128\n(Train) Batch 128 Loss : 3.148206949234009, 맞은 개수 : 32\nEpoch : 3, batch 129\n(Train) Batch 129 Loss : 2.9345016479492188, 맞은 개수 : 42\nEpoch : 3, batch 130\n(Train) Batch 130 Loss : 3.30212664604187, 맞은 개수 : 30\nEpoch : 3, batch 131\n(Train) Batch 131 Loss : 3.0899033546447754, 맞은 개수 : 33\nEpoch : 3, batch 132\n(Train) Batch 132 Loss : 3.187628984451294, 맞은 개수 : 36\nEpoch : 3, batch 133\n(Train) Batch 133 Loss : 2.9304416179656982, 맞은 개수 : 44\nEpoch : 3, batch 134\n(Train) Batch 134 Loss : 3.4687366485595703, 맞은 개수 : 34\nEpoch : 3, batch 135\n(Train) Batch 135 Loss : 3.1161677837371826, 맞은 개수 : 35\nEpoch : 3, batch 136\n(Train) Batch 136 Loss : 3.134030818939209, 맞은 개수 : 41\nEpoch : 3, batch 137\n(Train) Batch 137 Loss : 3.1657824516296387, 맞은 개수 : 31\nEpoch : 3, batch 138\n(Train) Batch 138 Loss : 3.1939752101898193, 맞은 개수 : 39\nEpoch : 3, batch 139\n(Train) Batch 139 Loss : 3.1219842433929443, 맞은 개수 : 34\nEpoch : 3, batch 140\n(Train) Batch 140 Loss : 3.07897686958313, 맞은 개수 : 33\nEpoch : 3, batch 141\n(Train) Batch 141 Loss : 2.9651341438293457, 맞은 개수 : 41\nEpoch : 3, batch 142\n(Train) Batch 142 Loss : 3.251502513885498, 맞은 개수 : 29\nEpoch : 3, batch 143\n(Train) Batch 143 Loss : 2.8920106887817383, 맞은 개수 : 43\nEpoch : 3, batch 144\n(Train) Batch 144 Loss : 3.0563454627990723, 맞은 개수 : 39\nEpoch : 3, batch 145\n(Train) Batch 145 Loss : 3.2731473445892334, 맞은 개수 : 35\nEpoch : 3, batch 146\n(Train) Batch 146 Loss : 2.8534018993377686, 맞은 개수 : 38\nEpoch : 3, batch 147\n(Train) Batch 147 Loss : 3.0131378173828125, 맞은 개수 : 39\nEpoch : 3, batch 148\n(Train) Batch 148 Loss : 2.865257740020752, 맞은 개수 : 42\nEpoch : 3, batch 149\n(Train) Batch 149 Loss : 3.1175267696380615, 맞은 개수 : 40\nEpoch : 3, batch 150\n(Train) Batch 150 Loss : 3.0523996353149414, 맞은 개수 : 41\nEpoch : 3, batch 151\n(Train) Batch 151 Loss : 3.0472092628479004, 맞은 개수 : 35\nEpoch : 3, batch 152\n(Train) Batch 152 Loss : 3.3994357585906982, 맞은 개수 : 31\nEpoch : 3, batch 153\n(Train) Batch 153 Loss : 3.026592254638672, 맞은 개수 : 36\nEpoch : 3, batch 154\n(Train) Batch 154 Loss : 2.993614673614502, 맞은 개수 : 39\nEpoch : 3, batch 155\n(Train) Batch 155 Loss : 3.1640048027038574, 맞은 개수 : 37\nEpoch : 3, batch 156\n(Train) Batch 156 Loss : 2.991039752960205, 맞은 개수 : 44\nEpoch : 3, batch 157\n(Train) Batch 157 Loss : 3.080894708633423, 맞은 개수 : 37\nEpoch : 3, batch 158\n(Train) Batch 158 Loss : 2.879077196121216, 맞은 개수 : 44\nEpoch : 3, batch 159\n(Train) Batch 159 Loss : 2.9601211547851562, 맞은 개수 : 36\nEpoch : 3, batch 160\n(Train) Batch 160 Loss : 3.14237117767334, 맞은 개수 : 39\nEpoch : 3, batch 161\n(Train) Batch 161 Loss : 3.159511089324951, 맞은 개수 : 31\nEpoch : 3, batch 162\n(Train) Batch 162 Loss : 3.4231529235839844, 맞은 개수 : 31\nEpoch : 3, batch 163\n(Train) Batch 163 Loss : 3.1010329723358154, 맞은 개수 : 35\nEpoch : 3, batch 164\n(Train) Batch 164 Loss : 3.1128602027893066, 맞은 개수 : 33\nEpoch : 3, batch 165\n(Train) Batch 165 Loss : 3.1527328491210938, 맞은 개수 : 38\nEpoch : 3, batch 166\n(Train) Batch 166 Loss : 3.085211992263794, 맞은 개수 : 38\nEpoch : 3, batch 167\n(Train) Batch 167 Loss : 3.0520031452178955, 맞은 개수 : 40\nEpoch : 3, batch 168\n(Train) Batch 168 Loss : 2.8717169761657715, 맞은 개수 : 40\nEpoch : 3, batch 169\n(Train) Batch 169 Loss : 3.295001268386841, 맞은 개수 : 33\nEpoch : 3, batch 170\n(Train) Batch 170 Loss : 3.125521183013916, 맞은 개수 : 39\nEpoch : 3, batch 171\n(Train) Batch 171 Loss : 2.8698644638061523, 맞은 개수 : 45\nEpoch : 3, batch 172\n(Train) Batch 172 Loss : 3.010732889175415, 맞은 개수 : 45\nEpoch : 3, batch 173\n(Train) Batch 173 Loss : 3.055314064025879, 맞은 개수 : 40\nEpoch : 3, batch 174\n(Train) Batch 174 Loss : 3.038555860519409, 맞은 개수 : 42\nEpoch : 3, batch 175\n(Train) Batch 175 Loss : 3.032787322998047, 맞은 개수 : 38\nEpoch : 3, batch 176\n(Train) Batch 176 Loss : 3.2153496742248535, 맞은 개수 : 30\nEpoch : 3, batch 177\n(Train) Batch 177 Loss : 3.337606430053711, 맞은 개수 : 35\nEpoch : 3, batch 178\n(Train) Batch 178 Loss : 2.978990077972412, 맞은 개수 : 43\nEpoch : 3, batch 179\n(Train) Batch 179 Loss : 2.9948439598083496, 맞은 개수 : 39\nEpoch : 3, batch 180\n(Train) Batch 180 Loss : 3.022702932357788, 맞은 개수 : 33\nEpoch : 3, batch 181\n(Train) Batch 181 Loss : 3.2220919132232666, 맞은 개수 : 30\nEpoch : 3, batch 182\n(Train) Batch 182 Loss : 3.3345823287963867, 맞은 개수 : 29\nEpoch : 3, batch 183\n(Train) Batch 183 Loss : 2.9289252758026123, 맞은 개수 : 41\nEpoch : 3, batch 184\n(Train) Batch 184 Loss : 2.9225666522979736, 맞은 개수 : 43\nEpoch : 3, batch 185\n(Train) Batch 185 Loss : 3.229398488998413, 맞은 개수 : 32\nEpoch : 3, batch 186\n(Train) Batch 186 Loss : 3.369483709335327, 맞은 개수 : 33\nEpoch : 3, batch 187\n(Train) Batch 187 Loss : 2.8649332523345947, 맞은 개수 : 48\nEpoch : 3, batch 188\n(Train) Batch 188 Loss : 2.9324164390563965, 맞은 개수 : 33\nEpoch : 3, batch 189\n(Train) Batch 189 Loss : 3.0070457458496094, 맞은 개수 : 40\nEpoch : 3, batch 190\n(Train) Batch 190 Loss : 3.034817934036255, 맞은 개수 : 44\nEpoch : 3, batch 191\n(Train) Batch 191 Loss : 3.18927264213562, 맞은 개수 : 31\nEpoch : 3, batch 192\n(Train) Batch 192 Loss : 3.344564199447632, 맞은 개수 : 28\nEpoch : 3, batch 193\n(Train) Batch 193 Loss : 3.2942826747894287, 맞은 개수 : 31\nEpoch : 3, batch 194\n(Train) Batch 194 Loss : 3.3427717685699463, 맞은 개수 : 31\nEpoch : 3, batch 195\n(Train) Batch 195 Loss : 3.0045762062072754, 맞은 개수 : 37\nEpoch : 3, batch 196\n(Train) Batch 196 Loss : 3.0802338123321533, 맞은 개수 : 43\nEpoch : 3, batch 197\n(Train) Batch 197 Loss : 3.4454288482666016, 맞은 개수 : 31\nEpoch : 3, batch 198\n(Train) Batch 198 Loss : 2.965240716934204, 맞은 개수 : 40\nEpoch : 3, batch 199\n(Train) Batch 199 Loss : 2.867372751235962, 맞은 개수 : 37\nEpoch : 3, batch 200\n(Train) Batch 200 Loss : 2.913386821746826, 맞은 개수 : 42\nEpoch : 3, batch 201\n(Train) Batch 201 Loss : 3.2090682983398438, 맞은 개수 : 40\nEpoch : 3, batch 202\n(Train) Batch 202 Loss : 3.1787350177764893, 맞은 개수 : 31\nEpoch : 3, batch 203\n(Train) Batch 203 Loss : 3.2664992809295654, 맞은 개수 : 27\nEpoch : 3, batch 204\n(Train) Batch 204 Loss : 3.1243438720703125, 맞은 개수 : 36\nEpoch : 3, batch 205\n(Train) Batch 205 Loss : 3.3454840183258057, 맞은 개수 : 36\nEpoch : 3, batch 206\n(Train) Batch 206 Loss : 3.089694023132324, 맞은 개수 : 33\nEpoch : 3, batch 207\n(Train) Batch 207 Loss : 3.3310043811798096, 맞은 개수 : 35\nEpoch : 3, batch 208\n(Train) Batch 208 Loss : 3.255992889404297, 맞은 개수 : 33\nEpoch : 3, batch 209\n(Train) Batch 209 Loss : 3.3003334999084473, 맞은 개수 : 36\nEpoch : 3, batch 210\n(Train) Batch 210 Loss : 3.0911741256713867, 맞은 개수 : 34\nEpoch : 3, batch 211\n(Train) Batch 211 Loss : 3.1680526733398438, 맞은 개수 : 37\nEpoch : 3, batch 212\n(Train) Batch 212 Loss : 3.1176798343658447, 맞은 개수 : 46\nEpoch : 3, batch 213\n(Train) Batch 213 Loss : 3.126077890396118, 맞은 개수 : 38\nEpoch : 3, batch 214\n(Train) Batch 214 Loss : 3.1040563583374023, 맞은 개수 : 38\nEpoch : 3, batch 215\n(Train) Batch 215 Loss : 3.3036301136016846, 맞은 개수 : 30\nEpoch : 3, batch 216\n(Train) Batch 216 Loss : 2.810202121734619, 맞은 개수 : 43\nEpoch : 3, batch 217\n(Train) Batch 217 Loss : 3.026571750640869, 맞은 개수 : 34\nEpoch : 3, batch 218\n(Train) Batch 218 Loss : 3.3346612453460693, 맞은 개수 : 30\nEpoch : 3, batch 219\n(Train) Batch 219 Loss : 2.9969828128814697, 맞은 개수 : 40\nEpoch : 3, batch 220\n(Train) Batch 220 Loss : 3.0438175201416016, 맞은 개수 : 41\nEpoch : 3, batch 221\n(Train) Batch 221 Loss : 3.305265426635742, 맞은 개수 : 38\nEpoch : 3, batch 222\n(Train) Batch 222 Loss : 3.1511433124542236, 맞은 개수 : 38\nEpoch : 3, batch 223\n(Train) Batch 223 Loss : 3.1266236305236816, 맞은 개수 : 41\nEpoch : 3, batch 224\n(Train) Batch 224 Loss : 3.2319817543029785, 맞은 개수 : 33\nEpoch : 3, batch 225\n(Train) Batch 225 Loss : 3.319334030151367, 맞은 개수 : 31\nEpoch : 3, batch 226\n(Train) Batch 226 Loss : 2.9378671646118164, 맞은 개수 : 41\nEpoch : 3, batch 227\n(Train) Batch 227 Loss : 2.963705062866211, 맞은 개수 : 41\nEpoch : 3, batch 228\n(Train) Batch 228 Loss : 3.257838249206543, 맞은 개수 : 34\nEpoch : 3, batch 229\n(Train) Batch 229 Loss : 3.078138589859009, 맞은 개수 : 36\nEpoch : 3, batch 230\n(Train) Batch 230 Loss : 3.046497344970703, 맞은 개수 : 43\nEpoch : 3, batch 231\n(Train) Batch 231 Loss : 3.116285800933838, 맞은 개수 : 38\nEpoch : 3, batch 232\n(Train) Batch 232 Loss : 3.043917179107666, 맞은 개수 : 37\nEpoch : 3, batch 233\n(Train) Batch 233 Loss : 2.952399730682373, 맞은 개수 : 36\nEpoch : 3, batch 234\n(Train) Batch 234 Loss : 3.0743606090545654, 맞은 개수 : 27\nEpoch : 3, batch 235\n(Train) Batch 235 Loss : 3.190401792526245, 맞은 개수 : 33\nEpoch : 3, batch 236\n(Train) Batch 236 Loss : 3.1339614391326904, 맞은 개수 : 36\nEpoch : 3, batch 237\n(Train) Batch 237 Loss : 3.036658763885498, 맞은 개수 : 40\nEpoch : 3, batch 238\n(Train) Batch 238 Loss : 3.039154052734375, 맞은 개수 : 40\nEpoch : 3, batch 239\n(Train) Batch 239 Loss : 3.120462656021118, 맞은 개수 : 32\nEpoch : 3, batch 240\n(Train) Batch 240 Loss : 3.1697397232055664, 맞은 개수 : 31\nEpoch : 3, batch 241\n(Train) Batch 241 Loss : 3.030797243118286, 맞은 개수 : 35\nEpoch : 3, batch 242\n(Train) Batch 242 Loss : 2.856306314468384, 맞은 개수 : 44\nEpoch : 3, batch 243\n(Train) Batch 243 Loss : 2.952975273132324, 맞은 개수 : 45\nEpoch : 3, batch 244\n(Train) Batch 244 Loss : 2.905116319656372, 맞은 개수 : 38\nEpoch : 3, batch 245\n(Train) Batch 245 Loss : 2.908238410949707, 맞은 개수 : 39\nEpoch : 3, batch 246\n(Train) Batch 246 Loss : 3.2115066051483154, 맞은 개수 : 35\nEpoch : 3, batch 247\n(Train) Batch 247 Loss : 3.1363894939422607, 맞은 개수 : 31\nEpoch : 3, batch 248\n(Train) Batch 248 Loss : 3.222414016723633, 맞은 개수 : 35\nEpoch : 3, batch 249\n(Train) Batch 249 Loss : 3.3784124851226807, 맞은 개수 : 24\nEpoch : 3, batch 250\n(Train) Batch 250 Loss : 2.785396099090576, 맞은 개수 : 46\nEpoch : 3, batch 251\n(Train) Batch 251 Loss : 2.952157735824585, 맞은 개수 : 32\nEpoch : 3, batch 252\n(Train) Batch 252 Loss : 3.229830741882324, 맞은 개수 : 29\nEpoch : 3, batch 253\n(Train) Batch 253 Loss : 3.0966055393218994, 맞은 개수 : 32\nEpoch : 3, batch 254\n(Train) Batch 254 Loss : 3.3502748012542725, 맞은 개수 : 34\nEpoch : 3, batch 255\n(Train) Batch 255 Loss : 3.100766181945801, 맞은 개수 : 35\nEpoch : 3, batch 256\n(Train) Batch 256 Loss : 3.001051425933838, 맞은 개수 : 37\nEpoch : 3, batch 257\n(Train) Batch 257 Loss : 2.9162261486053467, 맞은 개수 : 41\nEpoch : 3, batch 258\n(Train) Batch 258 Loss : 3.0755741596221924, 맞은 개수 : 37\nEpoch : 3, batch 259\n(Train) Batch 259 Loss : 3.0420022010803223, 맞은 개수 : 27\nEpoch : 3, batch 260\n(Train) Batch 260 Loss : 3.0655906200408936, 맞은 개수 : 40\nEpoch : 3, batch 261\n(Train) Batch 261 Loss : 3.0153896808624268, 맞은 개수 : 38\nEpoch : 3, batch 262\n(Train) Batch 262 Loss : 3.0149917602539062, 맞은 개수 : 41\nEpoch : 3, batch 263\n(Train) Batch 263 Loss : 2.9580273628234863, 맞은 개수 : 40\nEpoch : 3, batch 264\n(Train) Batch 264 Loss : 3.1751275062561035, 맞은 개수 : 39\nEpoch : 3, batch 265\n(Train) Batch 265 Loss : 3.210712432861328, 맞은 개수 : 44\nEpoch : 3, batch 266\n(Train) Batch 266 Loss : 2.988522529602051, 맞은 개수 : 46\nEpoch : 3, batch 267\n(Train) Batch 267 Loss : 3.080124616622925, 맞은 개수 : 37\nEpoch : 3, batch 268\n(Train) Batch 268 Loss : 3.141166925430298, 맞은 개수 : 33\nEpoch : 3, batch 269\n(Train) Batch 269 Loss : 2.861740827560425, 맞은 개수 : 45\nEpoch : 3, batch 270\n(Train) Batch 270 Loss : 3.197071075439453, 맞은 개수 : 33\nEpoch : 3, batch 271\n(Train) Batch 271 Loss : 3.1079273223876953, 맞은 개수 : 39\nEpoch : 3, batch 272\n(Train) Batch 272 Loss : 3.0738539695739746, 맞은 개수 : 37\nEpoch : 3, batch 273\n(Train) Batch 273 Loss : 2.875197172164917, 맞은 개수 : 42\nEpoch : 3, batch 274\n(Train) Batch 274 Loss : 3.264697551727295, 맞은 개수 : 33\nEpoch : 3, batch 275\n(Train) Batch 275 Loss : 3.252249240875244, 맞은 개수 : 35\nEpoch : 3, batch 276\n(Train) Batch 276 Loss : 3.2686309814453125, 맞은 개수 : 30\nEpoch : 3, batch 277\n(Train) Batch 277 Loss : 3.237778902053833, 맞은 개수 : 34\nEpoch : 3, batch 278\n(Train) Batch 278 Loss : 3.033907890319824, 맞은 개수 : 30\nEpoch : 3, batch 279\n(Train) Batch 279 Loss : 3.133037805557251, 맞은 개수 : 38\nEpoch : 3, batch 280\n(Train) Batch 280 Loss : 3.170687198638916, 맞은 개수 : 32\nEpoch : 3, batch 281\n(Train) Batch 281 Loss : 2.9659812450408936, 맞은 개수 : 38\nEpoch : 3, batch 282\n(Train) Batch 282 Loss : 3.207139253616333, 맞은 개수 : 41\nEpoch : 3, batch 283\n(Train) Batch 283 Loss : 3.1367106437683105, 맞은 개수 : 42\nEpoch : 3, batch 284\n(Train) Batch 284 Loss : 3.5360119342803955, 맞은 개수 : 26\nEpoch : 3, batch 285\n(Train) Batch 285 Loss : 3.091519594192505, 맞은 개수 : 33\nEpoch : 3, batch 286\n(Train) Batch 286 Loss : 3.317913055419922, 맞은 개수 : 31\nEpoch : 3, batch 287\n(Train) Batch 287 Loss : 3.051929235458374, 맞은 개수 : 40\nEpoch : 3, batch 288\n(Train) Batch 288 Loss : 3.1181163787841797, 맞은 개수 : 42\nEpoch : 3, batch 289\n(Train) Batch 289 Loss : 2.9627115726470947, 맞은 개수 : 40\nEpoch : 3, batch 290\n(Train) Batch 290 Loss : 3.4652438163757324, 맞은 개수 : 27\nEpoch : 3, batch 291\n(Train) Batch 291 Loss : 2.9312453269958496, 맞은 개수 : 38\nEpoch : 3, batch 292\n(Train) Batch 292 Loss : 3.1159071922302246, 맞은 개수 : 36\nEpoch : 3, batch 293\n(Train) Batch 293 Loss : 3.0647614002227783, 맞은 개수 : 35\nEpoch : 3, batch 294\n(Train) Batch 294 Loss : 3.0599567890167236, 맞은 개수 : 41\nEpoch : 3, batch 295\n(Train) Batch 295 Loss : 3.029142379760742, 맞은 개수 : 38\nEpoch : 3, batch 296\n(Train) Batch 296 Loss : 3.0999019145965576, 맞은 개수 : 41\nEpoch : 3, batch 297\n(Train) Batch 297 Loss : 2.9662277698516846, 맞은 개수 : 42\nEpoch : 3, batch 298\n(Train) Batch 298 Loss : 3.2911031246185303, 맞은 개수 : 39\nEpoch : 3, batch 299\n(Train) Batch 299 Loss : 3.09244966506958, 맞은 개수 : 30\nEpoch : 3, batch 300\n(Train) Batch 300 Loss : 2.8784234523773193, 맞은 개수 : 44\nEpoch : 3, batch 301\n(Train) Batch 301 Loss : 3.088090419769287, 맞은 개수 : 40\nEpoch : 3, batch 302\n(Train) Batch 302 Loss : 3.3640544414520264, 맞은 개수 : 27\nEpoch : 3, batch 303\n(Train) Batch 303 Loss : 3.21085786819458, 맞은 개수 : 29\nEpoch : 3, batch 304\n(Train) Batch 304 Loss : 2.9638283252716064, 맞은 개수 : 44\nEpoch : 3, batch 305\n(Train) Batch 305 Loss : 3.592787742614746, 맞은 개수 : 25\nEpoch : 3, batch 306\n(Train) Batch 306 Loss : 3.139601469039917, 맞은 개수 : 40\nEpoch : 3, batch 307\n(Train) Batch 307 Loss : 3.276843309402466, 맞은 개수 : 32\nEpoch : 3, batch 308\n(Train) Batch 308 Loss : 3.277271270751953, 맞은 개수 : 33\nEpoch : 3, batch 309\n(Train) Batch 309 Loss : 3.2027604579925537, 맞은 개수 : 36\nEpoch : 3, batch 310\n(Train) Batch 310 Loss : 3.1718990802764893, 맞은 개수 : 31\nEpoch : 3, batch 311\n(Train) Batch 311 Loss : 3.2740185260772705, 맞은 개수 : 33\nEpoch : 3, batch 312\n(Train) Batch 312 Loss : 3.027884006500244, 맞은 개수 : 42\nEpoch : 3, batch 313\n(Train) Batch 313 Loss : 3.3103713989257812, 맞은 개수 : 31\nEpoch : 3, batch 314\n(Train) Batch 314 Loss : 3.060025691986084, 맞은 개수 : 37\nEpoch : 3, batch 315\n(Train) Batch 315 Loss : 3.2019288539886475, 맞은 개수 : 32\nEpoch : 3, batch 316\n(Train) Batch 316 Loss : 3.0287160873413086, 맞은 개수 : 39\nEpoch : 3, batch 317\n(Train) Batch 317 Loss : 2.8337955474853516, 맞은 개수 : 35\nEpoch : 3, batch 318\n(Train) Batch 318 Loss : 2.998140811920166, 맞은 개수 : 31\nEpoch : 3, batch 319\n(Train) Batch 319 Loss : 3.2648515701293945, 맞은 개수 : 32\nEpoch : 3, batch 320\n(Train) Batch 320 Loss : 2.978135108947754, 맞은 개수 : 39\nEpoch : 3, batch 321\n(Train) Batch 321 Loss : 2.9606454372406006, 맞은 개수 : 35\nEpoch : 3, batch 322\n(Train) Batch 322 Loss : 3.3670473098754883, 맞은 개수 : 31\nEpoch : 3, batch 323\n(Train) Batch 323 Loss : 3.1549019813537598, 맞은 개수 : 34\nEpoch : 3, batch 324\n(Train) Batch 324 Loss : 2.9824697971343994, 맞은 개수 : 39\nEpoch : 3, batch 325\n(Train) Batch 325 Loss : 3.2283148765563965, 맞은 개수 : 28\nEpoch : 3, batch 326\n(Train) Batch 326 Loss : 2.9599082469940186, 맞은 개수 : 35\nEpoch : 3, batch 327\n(Train) Batch 327 Loss : 3.1699635982513428, 맞은 개수 : 38\nEpoch : 3, batch 328\n(Train) Batch 328 Loss : 2.702732801437378, 맞은 개수 : 45\nEpoch : 3, batch 329\n(Train) Batch 329 Loss : 3.2581379413604736, 맞은 개수 : 37\nEpoch : 3, batch 330\n(Train) Batch 330 Loss : 3.11362624168396, 맞은 개수 : 41\nEpoch : 3, batch 331\n(Train) Batch 331 Loss : 3.328108072280884, 맞은 개수 : 37\nEpoch : 3, batch 332\n(Train) Batch 332 Loss : 3.3424479961395264, 맞은 개수 : 30\nEpoch : 3, batch 333\n(Train) Batch 333 Loss : 2.876483201980591, 맞은 개수 : 47\nEpoch : 3, batch 334\n(Train) Batch 334 Loss : 3.102182626724243, 맞은 개수 : 37\nEpoch : 3, batch 335\n(Train) Batch 335 Loss : 2.808561086654663, 맞은 개수 : 45\nEpoch : 3, batch 336\n(Train) Batch 336 Loss : 2.9727225303649902, 맞은 개수 : 36\nEpoch : 3, batch 337\n(Train) Batch 337 Loss : 3.1295323371887207, 맞은 개수 : 33\nEpoch : 3, batch 338\n(Train) Batch 338 Loss : 3.009584665298462, 맞은 개수 : 33\nEpoch : 3, batch 339\n(Train) Batch 339 Loss : 3.341486930847168, 맞은 개수 : 36\nEpoch : 3, batch 340\n(Train) Batch 340 Loss : 3.0257983207702637, 맞은 개수 : 34\nEpoch : 3, batch 341\n(Train) Batch 341 Loss : 3.057974338531494, 맞은 개수 : 30\nEpoch : 3, batch 342\n(Train) Batch 342 Loss : 3.108968496322632, 맞은 개수 : 34\nEpoch : 3, batch 343\n(Train) Batch 343 Loss : 3.6167547702789307, 맞은 개수 : 28\nEpoch : 3, batch 344\n(Train) Batch 344 Loss : 3.036445379257202, 맞은 개수 : 41\nEpoch : 3, batch 345\n(Train) Batch 345 Loss : 3.0175514221191406, 맞은 개수 : 45\nEpoch : 3, batch 346\n(Train) Batch 346 Loss : 3.1284985542297363, 맞은 개수 : 41\nEpoch : 3, batch 347\n(Train) Batch 347 Loss : 2.812180280685425, 맞은 개수 : 44\nEpoch : 3, batch 348\n(Train) Batch 348 Loss : 2.9974992275238037, 맞은 개수 : 40\nEpoch : 3, batch 349\n(Train) Batch 349 Loss : 3.30456805229187, 맞은 개수 : 29\nEpoch : 3, batch 350\n(Train) Batch 350 Loss : 2.9592933654785156, 맞은 개수 : 40\nEpoch : 3, batch 351\n(Train) Batch 351 Loss : 3.2569994926452637, 맞은 개수 : 31\nEpoch : 3, batch 352\n(Train) Batch 352 Loss : 3.022228240966797, 맞은 개수 : 35\nEpoch : 3, batch 353\n(Train) Batch 353 Loss : 3.1914284229278564, 맞은 개수 : 39\nEpoch : 3, batch 354\n(Train) Batch 354 Loss : 3.1054680347442627, 맞은 개수 : 35\nEpoch : 3, batch 355\n(Train) Batch 355 Loss : 3.2852234840393066, 맞은 개수 : 32\nEpoch : 3, batch 356\n(Train) Batch 356 Loss : 2.956949472427368, 맞은 개수 : 45\nEpoch : 3, batch 357\n(Train) Batch 357 Loss : 3.048197031021118, 맞은 개수 : 37\nEpoch : 3, batch 358\n(Train) Batch 358 Loss : 3.3572330474853516, 맞은 개수 : 31\nEpoch : 3, batch 359\n(Train) Batch 359 Loss : 2.99263334274292, 맞은 개수 : 40\nEpoch : 3, batch 360\n(Train) Batch 360 Loss : 2.9506449699401855, 맞은 개수 : 45\nEpoch : 3, batch 361\n(Train) Batch 361 Loss : 3.320052146911621, 맞은 개수 : 31\nEpoch : 3, batch 362\n(Train) Batch 362 Loss : 2.953016519546509, 맞은 개수 : 38\nEpoch : 3, batch 363\n(Train) Batch 363 Loss : 3.288367509841919, 맞은 개수 : 35\nEpoch : 3, batch 364\n(Train) Batch 364 Loss : 3.1291158199310303, 맞은 개수 : 34\nEpoch : 3, batch 365\n(Train) Batch 365 Loss : 3.0152435302734375, 맞은 개수 : 35\nEpoch : 3, batch 366\n(Train) Batch 366 Loss : 3.061685085296631, 맞은 개수 : 45\nEpoch : 3, batch 367\n(Train) Batch 367 Loss : 3.1597342491149902, 맞은 개수 : 31\nEpoch : 3, batch 368\n(Train) Batch 368 Loss : 3.1598522663116455, 맞은 개수 : 37\nEpoch : 3, batch 369\n(Train) Batch 369 Loss : 3.251376152038574, 맞은 개수 : 33\nEpoch : 3, batch 370\n(Train) Batch 370 Loss : 2.9348011016845703, 맞은 개수 : 40\nEpoch : 3, batch 371\n(Train) Batch 371 Loss : 3.162165403366089, 맞은 개수 : 33\nEpoch : 3, batch 372\n(Train) Batch 372 Loss : 3.420107364654541, 맞은 개수 : 30\nEpoch : 3, batch 373\n(Train) Batch 373 Loss : 3.0189754962921143, 맞은 개수 : 39\nEpoch : 3, batch 374\n(Train) Batch 374 Loss : 3.101968765258789, 맞은 개수 : 29\nEpoch : 3, batch 375\n(Train) Batch 375 Loss : 2.980468988418579, 맞은 개수 : 35\nEpoch : 3, batch 376\n(Train) Batch 376 Loss : 2.922089099884033, 맞은 개수 : 41\nEpoch : 3, batch 377\n(Train) Batch 377 Loss : 3.1046509742736816, 맞은 개수 : 39\nEpoch : 3, batch 378\n(Train) Batch 378 Loss : 3.245497703552246, 맞은 개수 : 31\nEpoch : 3, batch 379\n(Train) Batch 379 Loss : 2.8776986598968506, 맞은 개수 : 46\nEpoch : 3, batch 380\n(Train) Batch 380 Loss : 3.26489520072937, 맞은 개수 : 33\nEpoch : 3, batch 381\n(Train) Batch 381 Loss : 2.993108034133911, 맞은 개수 : 37\nEpoch : 3, batch 382\n(Train) Batch 382 Loss : 2.900580406188965, 맞은 개수 : 40\nEpoch : 3, batch 383\n(Train) Batch 383 Loss : 2.866135358810425, 맞은 개수 : 41\nEpoch : 3, batch 384\n(Train) Batch 384 Loss : 3.1482162475585938, 맞은 개수 : 37\nEpoch : 3, batch 385\n(Train) Batch 385 Loss : 2.905146598815918, 맞은 개수 : 44\nEpoch : 3, batch 386\n(Train) Batch 386 Loss : 3.0465142726898193, 맞은 개수 : 37\nEpoch : 3, batch 387\n(Train) Batch 387 Loss : 3.0824830532073975, 맞은 개수 : 46\nEpoch : 3, batch 388\n(Train) Batch 388 Loss : 3.0739834308624268, 맞은 개수 : 36\nEpoch : 3, batch 389\n(Train) Batch 389 Loss : 3.1530425548553467, 맞은 개수 : 30\nEpoch : 3, batch 390\n(Train) Batch 390 Loss : 3.072568655014038, 맞은 개수 : 41\nEpoch : 3, batch 391\n(Train) Batch 391 Loss : 3.3033642768859863, 맞은 개수 : 29\nEpoch : 3, batch 392\n(Train) Batch 392 Loss : 2.8050734996795654, 맞은 개수 : 48\nEpoch : 3, batch 393\n(Train) Batch 393 Loss : 3.0156235694885254, 맞은 개수 : 45\nEpoch : 3, batch 394\n(Train) Batch 394 Loss : 3.075704336166382, 맞은 개수 : 39\nEpoch : 3, batch 395\n(Train) Batch 395 Loss : 3.376943349838257, 맞은 개수 : 31\nEpoch : 3, batch 396\n(Train) Batch 396 Loss : 3.1687135696411133, 맞은 개수 : 32\nEpoch : 3, batch 397\n(Train) Batch 397 Loss : 2.894146203994751, 맞은 개수 : 34\nEpoch : 3, batch 398\n(Train) Batch 398 Loss : 3.281456232070923, 맞은 개수 : 41\nEpoch : 3, batch 399\n(Train) Batch 399 Loss : 2.8316900730133057, 맞은 개수 : 43\nEpoch : 3, batch 400\n(Train) Batch 400 Loss : 2.9985268115997314, 맞은 개수 : 28\nEpoch : 3, batch 401\n(Train) Batch 401 Loss : 2.8863444328308105, 맞은 개수 : 46\nEpoch : 3, batch 402\n(Train) Batch 402 Loss : 3.0155704021453857, 맞은 개수 : 37\nEpoch : 3, batch 403\n(Train) Batch 403 Loss : 3.2242002487182617, 맞은 개수 : 37\nEpoch : 3, batch 404\n(Train) Batch 404 Loss : 2.8274691104888916, 맞은 개수 : 41\nEpoch : 3, batch 405\n(Train) Batch 405 Loss : 3.107139825820923, 맞은 개수 : 35\nEpoch : 3, batch 406\n(Train) Batch 406 Loss : 2.9978597164154053, 맞은 개수 : 38\nEpoch : 3, batch 407\n(Train) Batch 407 Loss : 3.141735076904297, 맞은 개수 : 29\nEpoch : 3, batch 408\n(Train) Batch 408 Loss : 3.230067729949951, 맞은 개수 : 34\nEpoch : 3, batch 409\n(Train) Batch 409 Loss : 3.0947000980377197, 맞은 개수 : 40\nEpoch : 3, batch 410\n(Train) Batch 410 Loss : 3.045362710952759, 맞은 개수 : 34\nEpoch : 3, batch 411\n(Train) Batch 411 Loss : 3.0255229473114014, 맞은 개수 : 32\nEpoch : 3, batch 412\n(Train) Batch 412 Loss : 2.968177080154419, 맞은 개수 : 33\nEpoch : 3, batch 413\n(Train) Batch 413 Loss : 3.072974443435669, 맞은 개수 : 36\nEpoch : 3, batch 414\n(Train) Batch 414 Loss : 2.8560092449188232, 맞은 개수 : 38\nEpoch : 3, batch 415\n(Train) Batch 415 Loss : 3.050199270248413, 맞은 개수 : 39\nEpoch : 3, batch 416\n(Train) Batch 416 Loss : 3.145860195159912, 맞은 개수 : 36\nEpoch : 3, batch 417\n(Train) Batch 417 Loss : 3.1473875045776367, 맞은 개수 : 35\nEpoch : 3, batch 418\n(Train) Batch 418 Loss : 2.9798638820648193, 맞은 개수 : 45\nEpoch : 3, batch 419\n(Train) Batch 419 Loss : 3.112215518951416, 맞은 개수 : 31\nEpoch : 3, batch 420\n(Train) Batch 420 Loss : 3.0072147846221924, 맞은 개수 : 37\nEpoch : 3, batch 421\n(Train) Batch 421 Loss : 3.0542540550231934, 맞은 개수 : 37\nEpoch : 3, batch 422\n(Train) Batch 422 Loss : 3.403104305267334, 맞은 개수 : 30\nEpoch : 3, batch 423\n(Train) Batch 423 Loss : 3.2463321685791016, 맞은 개수 : 37\nEpoch : 3, batch 424\n(Train) Batch 424 Loss : 3.067431688308716, 맞은 개수 : 40\nEpoch : 3, batch 425\n(Train) Batch 425 Loss : 2.834148406982422, 맞은 개수 : 46\nEpoch : 3, batch 426\n(Train) Batch 426 Loss : 3.0438437461853027, 맞은 개수 : 40\nEpoch : 3, batch 427\n(Train) Batch 427 Loss : 3.1625890731811523, 맞은 개수 : 38\nEpoch : 3, batch 428\n(Train) Batch 428 Loss : 3.0720064640045166, 맞은 개수 : 38\nEpoch : 3, batch 429\n(Train) Batch 429 Loss : 3.097745418548584, 맞은 개수 : 36\nEpoch : 3, batch 430\n(Train) Batch 430 Loss : 3.206127405166626, 맞은 개수 : 31\nEpoch : 3, batch 431\n(Train) Batch 431 Loss : 3.192173719406128, 맞은 개수 : 35\nEpoch : 3, batch 432\n(Train) Batch 432 Loss : 3.2485342025756836, 맞은 개수 : 30\nEpoch : 3, batch 433\n(Train) Batch 433 Loss : 2.948700189590454, 맞은 개수 : 46\nEpoch : 3, batch 434\n(Train) Batch 434 Loss : 3.127903461456299, 맞은 개수 : 31\nEpoch : 3, batch 435\n(Train) Batch 435 Loss : 2.9978184700012207, 맞은 개수 : 41\nEpoch : 3, batch 436\n(Train) Batch 436 Loss : 2.997020721435547, 맞은 개수 : 39\nEpoch : 3, batch 437\n(Train) Batch 437 Loss : 2.929445505142212, 맞은 개수 : 40\nEpoch : 3, batch 438\n(Train) Batch 438 Loss : 3.027745008468628, 맞은 개수 : 40\nEpoch : 3, batch 439\n(Train) Batch 439 Loss : 3.257410764694214, 맞은 개수 : 28\nEpoch : 3, batch 440\n(Train) Batch 440 Loss : 3.0898284912109375, 맞은 개수 : 37\nEpoch : 3, batch 441\n(Train) Batch 441 Loss : 3.154299736022949, 맞은 개수 : 43\nEpoch : 3, batch 442\n(Train) Batch 442 Loss : 2.9764368534088135, 맞은 개수 : 36\nEpoch : 3, batch 443\n(Train) Batch 443 Loss : 3.0928215980529785, 맞은 개수 : 36\nEpoch : 3, batch 444\n(Train) Batch 444 Loss : 2.8748271465301514, 맞은 개수 : 35\nEpoch : 3, batch 445\n(Train) Batch 445 Loss : 3.3552565574645996, 맞은 개수 : 35\nEpoch : 3, batch 446\n(Train) Batch 446 Loss : 3.0694167613983154, 맞은 개수 : 41\nEpoch : 3, batch 447\n(Train) Batch 447 Loss : 3.025919198989868, 맞은 개수 : 42\nEpoch : 3, batch 448\n(Train) Batch 448 Loss : 2.9546616077423096, 맞은 개수 : 42\nEpoch : 3, batch 449\n(Train) Batch 449 Loss : 3.143176317214966, 맞은 개수 : 43\nEpoch : 3, batch 450\n(Train) Batch 450 Loss : 2.995035171508789, 맞은 개수 : 41\nEpoch : 3, batch 451\n(Train) Batch 451 Loss : 3.059736490249634, 맞은 개수 : 39\nEpoch : 3, batch 452\n(Train) Batch 452 Loss : 2.946991443634033, 맞은 개수 : 52\nEpoch : 3, batch 453\n(Train) Batch 453 Loss : 3.0939109325408936, 맞은 개수 : 39\nEpoch : 3, batch 454\n(Train) Batch 454 Loss : 3.358499526977539, 맞은 개수 : 31\nEpoch : 3, batch 455\n(Train) Batch 455 Loss : 3.065659523010254, 맞은 개수 : 35\nEpoch : 3, batch 456\n(Train) Batch 456 Loss : 3.2052230834960938, 맞은 개수 : 35\nEpoch : 3, batch 457\n(Train) Batch 457 Loss : 3.1812045574188232, 맞은 개수 : 38\nEpoch : 3, batch 458\n(Train) Batch 458 Loss : 3.244410753250122, 맞은 개수 : 33\nEpoch : 3, batch 459\n(Train) Batch 459 Loss : 3.1891961097717285, 맞은 개수 : 36\nEpoch : 3, batch 460\n(Train) Batch 460 Loss : 3.124242067337036, 맞은 개수 : 32\nEpoch : 3, batch 461\n(Train) Batch 461 Loss : 2.965322494506836, 맞은 개수 : 43\nEpoch : 3, batch 462\n(Train) Batch 462 Loss : 3.0786244869232178, 맞은 개수 : 39\nEpoch : 3, batch 463\n(Train) Batch 463 Loss : 3.00538969039917, 맞은 개수 : 39\nEpoch : 3, batch 464\n(Train) Batch 464 Loss : 3.067302703857422, 맞은 개수 : 37\nEpoch : 3, batch 465\n(Train) Batch 465 Loss : 3.140547513961792, 맞은 개수 : 35\nEpoch : 3, batch 466\n(Train) Batch 466 Loss : 3.0632855892181396, 맞은 개수 : 37\nEpoch : 3, batch 467\n(Train) Batch 467 Loss : 3.1750848293304443, 맞은 개수 : 30\nEpoch : 3, batch 468\n(Train) Batch 468 Loss : 3.076500415802002, 맞은 개수 : 40\nEpoch : 3, batch 469\n(Train) Batch 469 Loss : 2.718510866165161, 맞은 개수 : 51\nEpoch : 3, batch 470\n(Train) Batch 470 Loss : 3.1338307857513428, 맞은 개수 : 34\nEpoch : 3, batch 471\n(Train) Batch 471 Loss : 3.2152764797210693, 맞은 개수 : 34\nEpoch : 3, batch 472\n(Train) Batch 472 Loss : 3.0047342777252197, 맞은 개수 : 37\nEpoch : 3, batch 473\n(Train) Batch 473 Loss : 3.1288304328918457, 맞은 개수 : 40\nEpoch : 3, batch 474\n(Train) Batch 474 Loss : 2.890897274017334, 맞은 개수 : 43\nEpoch : 3, batch 475\n(Train) Batch 475 Loss : 2.897799253463745, 맞은 개수 : 46\nEpoch : 3, batch 476\n(Train) Batch 476 Loss : 2.757662057876587, 맞은 개수 : 41\nEpoch : 3, batch 477\n(Train) Batch 477 Loss : 3.1303505897521973, 맞은 개수 : 35\nEpoch : 3, batch 478\n(Train) Batch 478 Loss : 3.033250093460083, 맞은 개수 : 38\nEpoch : 3, batch 479\n(Train) Batch 479 Loss : 3.2283358573913574, 맞은 개수 : 27\nEpoch : 3, batch 480\n(Train) Batch 480 Loss : 3.395123243331909, 맞은 개수 : 18\nEpoch : 3, batch 481\n(Train) Batch 481 Loss : 2.869656562805176, 맞은 개수 : 43\nEpoch : 3, batch 482\n(Train) Batch 482 Loss : 2.9944162368774414, 맞은 개수 : 45\nEpoch : 3, batch 483\n(Train) Batch 483 Loss : 3.2455220222473145, 맞은 개수 : 34\nEpoch : 3, batch 484\n(Train) Batch 484 Loss : 3.195237159729004, 맞은 개수 : 32\nEpoch : 3, batch 485\n(Train) Batch 485 Loss : 3.0886125564575195, 맞은 개수 : 39\nEpoch : 3, batch 486\n(Train) Batch 486 Loss : 3.2555124759674072, 맞은 개수 : 34\nEpoch : 3, batch 487\n(Train) Batch 487 Loss : 3.3117666244506836, 맞은 개수 : 31\nEpoch : 3, batch 488\n(Train) Batch 488 Loss : 2.8915042877197266, 맞은 개수 : 46\nEpoch : 3, batch 489\n(Train) Batch 489 Loss : 3.1956124305725098, 맞은 개수 : 39\nEpoch : 3, batch 490\n(Train) Batch 490 Loss : 3.1661572456359863, 맞은 개수 : 37\nEpoch : 3, batch 491\n(Train) Batch 491 Loss : 3.2327680587768555, 맞은 개수 : 29\nEpoch : 3, batch 492\n(Train) Batch 492 Loss : 3.068087339401245, 맞은 개수 : 41\nEpoch : 3, batch 493\n(Train) Batch 493 Loss : 3.285726308822632, 맞은 개수 : 33\nEpoch : 3, batch 494\n(Train) Batch 494 Loss : 2.934973955154419, 맞은 개수 : 43\nEpoch : 3, batch 495\n(Train) Batch 495 Loss : 3.0522408485412598, 맞은 개수 : 39\nEpoch : 3, batch 496\n(Train) Batch 496 Loss : 2.792236089706421, 맞은 개수 : 40\nEpoch : 3, batch 497\n(Train) Batch 497 Loss : 3.023444890975952, 맞은 개수 : 41\nEpoch : 3, batch 498\n(Train) Batch 498 Loss : 3.296558380126953, 맞은 개수 : 33\nEpoch : 3, batch 499\n(Train) Batch 499 Loss : 3.032712697982788, 맞은 개수 : 35\nEpoch : 3, batch 500\n(Train) Batch 500 Loss : 3.0188329219818115, 맞은 개수 : 31\nEpoch : 3, batch 501\n(Train) Batch 501 Loss : 2.771104335784912, 맞은 개수 : 42\nEpoch : 3, batch 502\n(Train) Batch 502 Loss : 3.236999034881592, 맞은 개수 : 36\nEpoch : 3, batch 503\n(Train) Batch 503 Loss : 2.732545852661133, 맞은 개수 : 44\nEpoch : 3, batch 504\n(Train) Batch 504 Loss : 3.2488980293273926, 맞은 개수 : 36\nEpoch : 3, batch 505\n(Train) Batch 505 Loss : 3.0789594650268555, 맞은 개수 : 35\nEpoch : 3, batch 506\n(Train) Batch 506 Loss : 3.3329885005950928, 맞은 개수 : 29\nEpoch : 3, batch 507\n(Train) Batch 507 Loss : 3.173556089401245, 맞은 개수 : 32\nEpoch : 3, batch 508\n(Train) Batch 508 Loss : 3.050736904144287, 맞은 개수 : 34\nEpoch : 3, batch 509\n(Train) Batch 509 Loss : 3.147421360015869, 맞은 개수 : 40\nEpoch : 3, batch 510\n(Train) Batch 510 Loss : 3.443850517272949, 맞은 개수 : 27\nEpoch : 3, batch 511\n(Train) Batch 511 Loss : 2.9121041297912598, 맞은 개수 : 38\nEpoch : 3, batch 512\n(Train) Batch 512 Loss : 3.0048282146453857, 맞은 개수 : 39\nEpoch : 3, batch 513\n(Train) Batch 513 Loss : 3.2507874965667725, 맞은 개수 : 32\nEpoch : 3, batch 514\n(Train) Batch 514 Loss : 3.0756120681762695, 맞은 개수 : 33\nEpoch : 3, batch 515\n(Train) Batch 515 Loss : 3.1020169258117676, 맞은 개수 : 33\nEpoch : 3, batch 516\n(Train) Batch 516 Loss : 3.098571538925171, 맞은 개수 : 42\nEpoch : 3, batch 517\n(Train) Batch 517 Loss : 2.9942750930786133, 맞은 개수 : 39\nEpoch : 3, batch 518\n(Train) Batch 518 Loss : 3.3212168216705322, 맞은 개수 : 32\nEpoch : 3, batch 519\n(Train) Batch 519 Loss : 3.035971164703369, 맞은 개수 : 36\nEpoch : 3, batch 520\n(Train) Batch 520 Loss : 3.2717788219451904, 맞은 개수 : 34\nEpoch : 3, batch 521\n(Train) Batch 521 Loss : 3.1701364517211914, 맞은 개수 : 33\nEpoch : 3, batch 522\n(Train) Batch 522 Loss : 3.2043957710266113, 맞은 개수 : 37\nEpoch : 3, batch 523\n(Train) Batch 523 Loss : 3.1372151374816895, 맞은 개수 : 33\nEpoch : 3, batch 524\n(Train) Batch 524 Loss : 3.1580803394317627, 맞은 개수 : 37\nEpoch : 3, batch 525\n(Train) Batch 525 Loss : 3.1106364727020264, 맞은 개수 : 31\nEpoch : 3, batch 526\n(Train) Batch 526 Loss : 2.999016523361206, 맞은 개수 : 35\nEpoch : 3, batch 527\n(Train) Batch 527 Loss : 2.910277843475342, 맞은 개수 : 37\nEpoch : 3, batch 528\n(Train) Batch 528 Loss : 3.0540711879730225, 맞은 개수 : 36\nEpoch : 3, batch 529\n(Train) Batch 529 Loss : 2.9635729789733887, 맞은 개수 : 37\nEpoch : 3, batch 530\n(Train) Batch 530 Loss : 3.253265380859375, 맞은 개수 : 38\nEpoch : 3, batch 531\n(Train) Batch 531 Loss : 2.9170215129852295, 맞은 개수 : 43\nEpoch : 3, batch 532\n(Train) Batch 532 Loss : 3.0732688903808594, 맞은 개수 : 32\nEpoch : 3, batch 533\n(Train) Batch 533 Loss : 2.879828453063965, 맞은 개수 : 41\nEpoch : 3, batch 534\n(Train) Batch 534 Loss : 3.0255823135375977, 맞은 개수 : 35\nEpoch : 3, batch 535\n(Train) Batch 535 Loss : 3.059569835662842, 맞은 개수 : 33\nEpoch : 3, batch 536\n(Train) Batch 536 Loss : 3.0799946784973145, 맞은 개수 : 40\nEpoch : 3, batch 537\n(Train) Batch 537 Loss : 3.0802054405212402, 맞은 개수 : 37\nEpoch : 3, batch 538\n(Train) Batch 538 Loss : 3.429647445678711, 맞은 개수 : 27\nEpoch : 3, batch 539\n(Train) Batch 539 Loss : 3.17974591255188, 맞은 개수 : 35\nEpoch : 3, batch 540\n(Train) Batch 540 Loss : 3.377269983291626, 맞은 개수 : 30\nEpoch : 3, batch 541\n(Train) Batch 541 Loss : 3.013230562210083, 맞은 개수 : 40\nEpoch : 3, batch 542\n(Train) Batch 542 Loss : 3.174312114715576, 맞은 개수 : 41\nEpoch : 3, batch 543\n(Train) Batch 543 Loss : 3.123307943344116, 맞은 개수 : 40\nEpoch : 3, batch 544\n(Train) Batch 544 Loss : 3.200432300567627, 맞은 개수 : 38\nEpoch : 3, batch 545\n(Train) Batch 545 Loss : 3.226546287536621, 맞은 개수 : 33\nEpoch : 3, batch 546\n(Train) Batch 546 Loss : 3.209724187850952, 맞은 개수 : 38\nEpoch : 3, batch 547\n(Train) Batch 547 Loss : 2.9157514572143555, 맞은 개수 : 35\nEpoch : 3, batch 548\n(Train) Batch 548 Loss : 3.147493600845337, 맞은 개수 : 30\nEpoch : 3, batch 549\n(Train) Batch 549 Loss : 2.9715845584869385, 맞은 개수 : 41\nEpoch : 3, batch 550\n(Train) Batch 550 Loss : 3.1558990478515625, 맞은 개수 : 37\nEpoch : 3, batch 551\n(Train) Batch 551 Loss : 2.6788330078125, 맞은 개수 : 44\nEpoch : 3, batch 552\n(Train) Batch 552 Loss : 3.268002510070801, 맞은 개수 : 35\nEpoch : 3, batch 553\n(Train) Batch 553 Loss : 3.195288896560669, 맞은 개수 : 38\nEpoch : 3, batch 554\n(Train) Batch 554 Loss : 3.1334524154663086, 맞은 개수 : 38\nEpoch : 3, batch 555\n(Train) Batch 555 Loss : 2.8544681072235107, 맞은 개수 : 44\nEpoch : 3, batch 556\n(Train) Batch 556 Loss : 3.0298335552215576, 맞은 개수 : 43\nEpoch : 3, batch 557\n(Train) Batch 557 Loss : 3.141658306121826, 맞은 개수 : 43\nEpoch : 3, batch 558\n(Train) Batch 558 Loss : 2.856904983520508, 맞은 개수 : 43\nEpoch : 3, batch 559\n(Train) Batch 559 Loss : 3.210446834564209, 맞은 개수 : 34\nEpoch : 3, batch 560\n(Train) Batch 560 Loss : 2.774998188018799, 맞은 개수 : 48\nEpoch : 3, batch 561\n(Train) Batch 561 Loss : 3.3530025482177734, 맞은 개수 : 28\nEpoch : 3, batch 562\n(Train) Batch 562 Loss : 3.3181943893432617, 맞은 개수 : 28\nEpoch : 3, batch 563\n(Train) Batch 563 Loss : 2.9399282932281494, 맞은 개수 : 38\nEpoch : 3, batch 564\n(Train) Batch 564 Loss : 3.1127569675445557, 맞은 개수 : 35\nEpoch : 3, batch 565\n(Train) Batch 565 Loss : 3.1001014709472656, 맞은 개수 : 39\nEpoch : 3, batch 566\n(Train) Batch 566 Loss : 2.7016310691833496, 맞은 개수 : 48\nEpoch : 3, batch 567\n(Train) Batch 567 Loss : 3.1488611698150635, 맞은 개수 : 35\nEpoch : 3, batch 568\n(Train) Batch 568 Loss : 3.039970636367798, 맞은 개수 : 40\nEpoch : 3, batch 569\n(Train) Batch 569 Loss : 2.652308702468872, 맞은 개수 : 49\nEpoch : 3, batch 570\n(Train) Batch 570 Loss : 3.0873167514801025, 맞은 개수 : 39\nEpoch : 3, batch 571\n(Train) Batch 571 Loss : 3.236524820327759, 맞은 개수 : 41\nEpoch : 3, batch 572\n(Train) Batch 572 Loss : 3.168935537338257, 맞은 개수 : 37\nEpoch : 3, batch 573\n(Train) Batch 573 Loss : 3.094970941543579, 맞은 개수 : 44\nEpoch : 3, batch 574\n(Train) Batch 574 Loss : 3.0271596908569336, 맞은 개수 : 42\nEpoch : 3, batch 575\n(Train) Batch 575 Loss : 2.999502420425415, 맞은 개수 : 34\nEpoch : 3, batch 576\n(Train) Batch 576 Loss : 3.195631742477417, 맞은 개수 : 38\nEpoch : 3, batch 577\n(Train) Batch 577 Loss : 3.5141372680664062, 맞은 개수 : 32\nEpoch : 3, batch 578\n(Train) Batch 578 Loss : 3.0473148822784424, 맞은 개수 : 44\nEpoch : 3, batch 579\n(Train) Batch 579 Loss : 2.797563314437866, 맞은 개수 : 39\nEpoch : 3, batch 580\n(Train) Batch 580 Loss : 3.12947940826416, 맞은 개수 : 24\nEpoch : 3, batch 581\n(Train) Batch 581 Loss : 2.8314433097839355, 맞은 개수 : 36\nEpoch : 3, batch 582\n(Train) Batch 582 Loss : 3.3659682273864746, 맞은 개수 : 25\nEpoch : 3, batch 583\n(Train) Batch 583 Loss : 3.102346658706665, 맞은 개수 : 42\nEpoch : 3, batch 584\n(Train) Batch 584 Loss : 2.7442264556884766, 맞은 개수 : 48\nEpoch : 3, batch 585\n(Train) Batch 585 Loss : 3.1399214267730713, 맞은 개수 : 37\nEpoch : 3, batch 586\n(Train) Batch 586 Loss : 3.1124868392944336, 맞은 개수 : 37\nEpoch : 3, batch 587\n(Train) Batch 587 Loss : 3.0593903064727783, 맞은 개수 : 34\nEpoch : 3, batch 588\n(Train) Batch 588 Loss : 3.2799596786499023, 맞은 개수 : 33\nEpoch : 3, batch 589\n(Train) Batch 589 Loss : 3.229785442352295, 맞은 개수 : 36\nEpoch : 3, batch 590\n(Train) Batch 590 Loss : 2.651228666305542, 맞은 개수 : 47\nEpoch : 3, batch 591\n(Train) Batch 591 Loss : 2.9183638095855713, 맞은 개수 : 45\nEpoch : 3, batch 592\n(Train) Batch 592 Loss : 3.02652907371521, 맞은 개수 : 34\nEpoch : 3, batch 593\n(Train) Batch 593 Loss : 3.0668718814849854, 맞은 개수 : 33\nEpoch : 3, batch 594\n(Train) Batch 594 Loss : 3.0365679264068604, 맞은 개수 : 43\nEpoch : 3, batch 595\n(Train) Batch 595 Loss : 2.910489797592163, 맞은 개수 : 38\nEpoch : 3, batch 596\n(Train) Batch 596 Loss : 3.04331374168396, 맞은 개수 : 36\nEpoch : 3, batch 597\n(Train) Batch 597 Loss : 2.892108201980591, 맞은 개수 : 35\nEpoch : 3, batch 598\n(Train) Batch 598 Loss : 3.059840440750122, 맞은 개수 : 39\nEpoch : 3, batch 599\n(Train) Batch 599 Loss : 2.7766480445861816, 맞은 개수 : 50\nEpoch : 3, batch 600\n(Train) Batch 600 Loss : 2.832209587097168, 맞은 개수 : 43\nEpoch : 3, batch 601\n(Train) Batch 601 Loss : 2.968250274658203, 맞은 개수 : 34\nEpoch : 3, batch 602\n(Train) Batch 602 Loss : 2.8876454830169678, 맞은 개수 : 40\nEpoch : 3, batch 603\n(Train) Batch 603 Loss : 2.963003635406494, 맞은 개수 : 41\nEpoch : 3, batch 604\n(Train) Batch 604 Loss : 3.001685857772827, 맞은 개수 : 36\nEpoch : 3, batch 605\n(Train) Batch 605 Loss : 2.980160713195801, 맞은 개수 : 42\nEpoch : 3, batch 606\n(Train) Batch 606 Loss : 3.150022506713867, 맞은 개수 : 32\nEpoch : 3, batch 607\n(Train) Batch 607 Loss : 3.0858254432678223, 맞은 개수 : 35\nEpoch : 3, batch 608\n(Train) Batch 608 Loss : 2.989457130432129, 맞은 개수 : 39\nEpoch : 3, batch 609\n(Train) Batch 609 Loss : 3.098045587539673, 맞은 개수 : 31\nEpoch : 3, batch 610\n(Train) Batch 610 Loss : 2.697662353515625, 맞은 개수 : 39\nEpoch : 3, batch 611\n(Train) Batch 611 Loss : 2.9522788524627686, 맞은 개수 : 47\nEpoch : 3, batch 612\n(Train) Batch 612 Loss : 2.916719436645508, 맞은 개수 : 46\nEpoch : 3, batch 613\n(Train) Batch 613 Loss : 3.1102612018585205, 맞은 개수 : 36\nEpoch : 3, batch 614\n(Train) Batch 614 Loss : 2.8286962509155273, 맞은 개수 : 41\nEpoch : 3, batch 615\n(Train) Batch 615 Loss : 2.79911732673645, 맞은 개수 : 46\nEpoch : 3, batch 616\n(Train) Batch 616 Loss : 3.2435998916625977, 맞은 개수 : 36\nEpoch : 3, batch 617\n(Train) Batch 617 Loss : 2.8657279014587402, 맞은 개수 : 44\nEpoch : 3, batch 618\n(Train) Batch 618 Loss : 2.7181642055511475, 맞은 개수 : 45\nEpoch : 3, batch 619\n(Train) Batch 619 Loss : 2.819253921508789, 맞은 개수 : 45\nEpoch : 3, batch 620\n(Train) Batch 620 Loss : 2.9812231063842773, 맞은 개수 : 41\nEpoch : 3, batch 621\n(Train) Batch 621 Loss : 2.8185033798217773, 맞은 개수 : 45\nEpoch : 3, batch 622\n(Train) Batch 622 Loss : 2.992659568786621, 맞은 개수 : 42\nEpoch : 3, batch 623\n(Train) Batch 623 Loss : 3.007936716079712, 맞은 개수 : 42\nEpoch : 3, batch 624\n(Train) Batch 624 Loss : 3.2053639888763428, 맞은 개수 : 30\nEpoch : 3, batch 625\n(Train) Batch 625 Loss : 3.0141048431396484, 맞은 개수 : 42\nEpoch : 3, batch 626\n(Train) Batch 626 Loss : 3.3021790981292725, 맞은 개수 : 30\nEpoch : 3, batch 627\n(Train) Batch 627 Loss : 2.990831136703491, 맞은 개수 : 40\nEpoch : 3, batch 628\n(Train) Batch 628 Loss : 3.196851968765259, 맞은 개수 : 36\nEpoch : 3, batch 629\n(Train) Batch 629 Loss : 3.060159921646118, 맞은 개수 : 37\nEpoch : 3, batch 630\n(Train) Batch 630 Loss : 2.916196346282959, 맞은 개수 : 47\nEpoch : 3, batch 631\n(Train) Batch 631 Loss : 3.3043019771575928, 맞은 개수 : 25\nEpoch : 3, batch 632\n(Train) Batch 632 Loss : 2.9585349559783936, 맞은 개수 : 37\nEpoch : 3, batch 633\n(Train) Batch 633 Loss : 3.047128915786743, 맞은 개수 : 35\nEpoch : 3, batch 634\n(Train) Batch 634 Loss : 2.9797868728637695, 맞은 개수 : 42\nEpoch : 3, batch 635\n(Train) Batch 635 Loss : 2.9823970794677734, 맞은 개수 : 41\nEpoch : 3, batch 636\n(Train) Batch 636 Loss : 2.8699703216552734, 맞은 개수 : 42\nEpoch : 3, batch 637\n(Train) Batch 637 Loss : 2.730797052383423, 맞은 개수 : 44\nEpoch : 3, batch 638\n(Train) Batch 638 Loss : 3.275477409362793, 맞은 개수 : 37\nEpoch : 3, batch 639\n(Train) Batch 639 Loss : 2.90590500831604, 맞은 개수 : 44\nEpoch : 3, batch 640\n(Train) Batch 640 Loss : 3.131420850753784, 맞은 개수 : 33\nEpoch : 3, batch 641\n(Train) Batch 641 Loss : 2.9096603393554688, 맞은 개수 : 43\nEpoch : 3, batch 642\n(Train) Batch 642 Loss : 3.2470502853393555, 맞은 개수 : 33\nEpoch : 3, batch 643\n(Train) Batch 643 Loss : 2.9750008583068848, 맞은 개수 : 34\nEpoch : 3, batch 644\n(Train) Batch 644 Loss : 3.008622169494629, 맞은 개수 : 39\nEpoch : 3, batch 645\n(Train) Batch 645 Loss : 2.965177297592163, 맞은 개수 : 40\nEpoch : 3, batch 646\n(Train) Batch 646 Loss : 2.9549832344055176, 맞은 개수 : 45\nEpoch : 3, batch 647\n(Train) Batch 647 Loss : 2.954615592956543, 맞은 개수 : 36\nEpoch : 3, batch 648\n(Train) Batch 648 Loss : 3.109829902648926, 맞은 개수 : 41\nEpoch : 3, batch 649\n(Train) Batch 649 Loss : 2.5763516426086426, 맞은 개수 : 50\nEpoch : 3, batch 650\n(Train) Batch 650 Loss : 3.099126100540161, 맞은 개수 : 35\nEpoch : 3, batch 651\n(Train) Batch 651 Loss : 3.014561414718628, 맞은 개수 : 37\nEpoch : 3, batch 652\n(Train) Batch 652 Loss : 2.9510228633880615, 맞은 개수 : 39\nEpoch : 3, batch 653\n(Train) Batch 653 Loss : 2.8198602199554443, 맞은 개수 : 41\nEpoch : 3, batch 654\n(Train) Batch 654 Loss : 2.881777048110962, 맞은 개수 : 39\nEpoch : 3, batch 655\n(Train) Batch 655 Loss : 2.9407265186309814, 맞은 개수 : 41\nEpoch : 3, batch 656\n(Train) Batch 656 Loss : 3.134540557861328, 맞은 개수 : 35\nEpoch : 3, batch 657\n(Train) Batch 657 Loss : 3.0833797454833984, 맞은 개수 : 32\nEpoch : 3, batch 658\n(Train) Batch 658 Loss : 2.7925453186035156, 맞은 개수 : 46\nEpoch : 3, batch 659\n(Train) Batch 659 Loss : 2.9546589851379395, 맞은 개수 : 40\nEpoch : 3, batch 660\n(Train) Batch 660 Loss : 3.1279749870300293, 맞은 개수 : 29\nEpoch : 3, batch 661\n(Train) Batch 661 Loss : 2.9390709400177, 맞은 개수 : 43\nEpoch : 3, batch 662\n(Train) Batch 662 Loss : 3.0602262020111084, 맞은 개수 : 33\nEpoch : 3, batch 663\n(Train) Batch 663 Loss : 3.0153965950012207, 맞은 개수 : 38\nEpoch : 3, batch 664\n(Train) Batch 664 Loss : 3.0305328369140625, 맞은 개수 : 30\nEpoch : 3, batch 665\n(Train) Batch 665 Loss : 2.977841377258301, 맞은 개수 : 45\nEpoch : 3, batch 666\n(Train) Batch 666 Loss : 2.9176037311553955, 맞은 개수 : 42\nEpoch : 3, batch 667\n(Train) Batch 667 Loss : 2.980623960494995, 맞은 개수 : 40\nEpoch : 3, batch 668\n(Train) Batch 668 Loss : 2.963578939437866, 맞은 개수 : 38\nEpoch : 3, batch 669\n(Train) Batch 669 Loss : 2.893557071685791, 맞은 개수 : 44\nEpoch : 3, batch 670\n(Train) Batch 670 Loss : 3.023468017578125, 맞은 개수 : 36\nEpoch : 3, batch 671\n(Train) Batch 671 Loss : 2.9200198650360107, 맞은 개수 : 38\nEpoch : 3, batch 672\n(Train) Batch 672 Loss : 3.080427646636963, 맞은 개수 : 42\nEpoch : 3, batch 673\n(Train) Batch 673 Loss : 3.305624008178711, 맞은 개수 : 34\nEpoch : 3, batch 674\n(Train) Batch 674 Loss : 2.973726987838745, 맞은 개수 : 44\nEpoch : 3, batch 675\n(Train) Batch 675 Loss : 3.038609027862549, 맞은 개수 : 36\nEpoch : 3, batch 676\n(Train) Batch 676 Loss : 2.8270697593688965, 맞은 개수 : 36\nEpoch : 3, batch 677\n(Train) Batch 677 Loss : 3.148054599761963, 맞은 개수 : 36\nEpoch : 3, batch 678\n(Train) Batch 678 Loss : 3.0483992099761963, 맞은 개수 : 35\nEpoch : 3, batch 679\n(Train) Batch 679 Loss : 3.217181444168091, 맞은 개수 : 34\nEpoch : 3, batch 680\n(Train) Batch 680 Loss : 3.0879290103912354, 맞은 개수 : 41\nEpoch : 3, batch 681\n(Train) Batch 681 Loss : 2.861900806427002, 맞은 개수 : 40\nEpoch : 3, batch 682\n(Train) Batch 682 Loss : 2.941399574279785, 맞은 개수 : 45\nEpoch : 3, batch 683\n(Train) Batch 683 Loss : 3.0431482791900635, 맞은 개수 : 44\nEpoch : 3, batch 684\n(Train) Batch 684 Loss : 3.0873992443084717, 맞은 개수 : 36\nEpoch : 3, batch 685\n(Train) Batch 685 Loss : 3.0568771362304688, 맞은 개수 : 32\nEpoch : 3, batch 686\n(Train) Batch 686 Loss : 2.988503932952881, 맞은 개수 : 39\nEpoch : 3, batch 687\n(Train) Batch 687 Loss : 3.144890546798706, 맞은 개수 : 38\nEpoch : 3, batch 688\n(Train) Batch 688 Loss : 3.2438035011291504, 맞은 개수 : 30\nEpoch : 3, batch 689\n(Train) Batch 689 Loss : 3.0787529945373535, 맞은 개수 : 41\nEpoch : 3, batch 690\n(Train) Batch 690 Loss : 3.2694907188415527, 맞은 개수 : 37\nEpoch : 3, batch 691\n(Train) Batch 691 Loss : 2.755077362060547, 맞은 개수 : 48\nEpoch : 3, batch 692\n(Train) Batch 692 Loss : 2.987532615661621, 맞은 개수 : 36\nEpoch : 3, batch 693\n(Train) Batch 693 Loss : 3.137751340866089, 맞은 개수 : 38\nEpoch : 3, batch 694\n(Train) Batch 694 Loss : 3.084784507751465, 맞은 개수 : 29\nEpoch : 3, batch 695\n(Train) Batch 695 Loss : 2.981841802597046, 맞은 개수 : 38\nEpoch : 3, batch 696\n(Train) Batch 696 Loss : 3.1148204803466797, 맞은 개수 : 35\nEpoch : 3, batch 697\n(Train) Batch 697 Loss : 3.068819522857666, 맞은 개수 : 31\nEpoch : 3, batch 698\n(Train) Batch 698 Loss : 3.244249105453491, 맞은 개수 : 30\nEpoch : 3, batch 699\n(Train) Batch 699 Loss : 2.9411988258361816, 맞은 개수 : 38\nEpoch : 3, batch 700\n(Train) Batch 700 Loss : 3.029917001724243, 맞은 개수 : 34\nEpoch : 3, batch 701\n(Train) Batch 701 Loss : 2.7857444286346436, 맞은 개수 : 46\nEpoch : 3, batch 702\n(Train) Batch 702 Loss : 3.044020891189575, 맞은 개수 : 42\nEpoch : 3, batch 703\n(Train) Batch 703 Loss : 2.880390167236328, 맞은 개수 : 41\nEpoch : 3, batch 704\n(Train) Batch 704 Loss : 3.098353147506714, 맞은 개수 : 32\nEpoch : 3, batch 705\n(Train) Batch 705 Loss : 3.3117599487304688, 맞은 개수 : 32\nEpoch : 3, batch 706\n(Train) Batch 706 Loss : 3.1270339488983154, 맞은 개수 : 37\nEpoch : 3, batch 707\n(Train) Batch 707 Loss : 3.0762522220611572, 맞은 개수 : 41\nEpoch : 3, batch 708\n(Train) Batch 708 Loss : 2.8543543815612793, 맞은 개수 : 40\nEpoch : 3, batch 709\n(Train) Batch 709 Loss : 2.9411559104919434, 맞은 개수 : 42\nEpoch : 3, batch 710\n(Train) Batch 710 Loss : 2.8173892498016357, 맞은 개수 : 45\nEpoch : 3, batch 711\n(Train) Batch 711 Loss : 3.0210788249969482, 맞은 개수 : 42\nEpoch : 3, batch 712\n(Train) Batch 712 Loss : 3.1696102619171143, 맞은 개수 : 34\nEpoch : 3, batch 713\n(Train) Batch 713 Loss : 2.992076873779297, 맞은 개수 : 36\nEpoch : 3, batch 714\n(Train) Batch 714 Loss : 3.039379596710205, 맞은 개수 : 34\nEpoch : 3, batch 715\n(Train) Batch 715 Loss : 3.2303683757781982, 맞은 개수 : 32\nEpoch : 3, batch 716\n(Train) Batch 716 Loss : 3.2043986320495605, 맞은 개수 : 39\nEpoch : 3, batch 717\n(Train) Batch 717 Loss : 3.022392988204956, 맞은 개수 : 32\nEpoch : 3, batch 718\n(Train) Batch 718 Loss : 2.96343994140625, 맞은 개수 : 38\nEpoch : 3, batch 719\n(Train) Batch 719 Loss : 3.172776460647583, 맞은 개수 : 38\nEpoch : 3, batch 720\n(Train) Batch 720 Loss : 2.9921693801879883, 맞은 개수 : 40\nEpoch : 3, batch 721\n(Train) Batch 721 Loss : 2.813720941543579, 맞은 개수 : 38\nEpoch : 3, batch 722\n(Train) Batch 722 Loss : 3.3027377128601074, 맞은 개수 : 35\nEpoch : 3, batch 723\n(Train) Batch 723 Loss : 3.242832899093628, 맞은 개수 : 38\nEpoch : 3, batch 724\n(Train) Batch 724 Loss : 2.9454615116119385, 맞은 개수 : 38\nEpoch : 3, batch 725\n(Train) Batch 725 Loss : 3.123786449432373, 맞은 개수 : 34\nEpoch : 3, batch 726\n(Train) Batch 726 Loss : 2.6742818355560303, 맞은 개수 : 54\nEpoch : 3, batch 727\n(Train) Batch 727 Loss : 2.8172249794006348, 맞은 개수 : 42\nEpoch : 3, batch 728\n(Train) Batch 728 Loss : 3.0283279418945312, 맞은 개수 : 33\nEpoch : 3, batch 729\n(Train) Batch 729 Loss : 3.108506441116333, 맞은 개수 : 37\nEpoch : 3, batch 730\n(Train) Batch 730 Loss : 3.112384557723999, 맞은 개수 : 33\nEpoch : 3, batch 731\n(Train) Batch 731 Loss : 2.893425703048706, 맞은 개수 : 42\nEpoch : 3, batch 732\n(Train) Batch 732 Loss : 2.79282808303833, 맞은 개수 : 44\nEpoch : 3, batch 733\n(Train) Batch 733 Loss : 3.2929859161376953, 맞은 개수 : 34\nEpoch : 3, batch 734\n(Train) Batch 734 Loss : 3.0668351650238037, 맞은 개수 : 41\nEpoch : 3, batch 735\n(Train) Batch 735 Loss : 2.7336530685424805, 맞은 개수 : 44\nEpoch : 3, batch 736\n(Train) Batch 736 Loss : 3.233046770095825, 맞은 개수 : 34\nEpoch : 3, batch 737\n(Train) Batch 737 Loss : 3.17862868309021, 맞은 개수 : 36\nEpoch : 3, batch 738\n(Train) Batch 738 Loss : 3.353271007537842, 맞은 개수 : 26\nEpoch : 3, batch 739\n(Train) Batch 739 Loss : 2.909205436706543, 맞은 개수 : 39\nEpoch : 3, batch 740\n(Train) Batch 740 Loss : 2.9053773880004883, 맞은 개수 : 39\nEpoch : 3, batch 741\n(Train) Batch 741 Loss : 3.194279193878174, 맞은 개수 : 34\nEpoch : 3, batch 742\n(Train) Batch 742 Loss : 3.352166175842285, 맞은 개수 : 35\nEpoch : 3, batch 743\n(Train) Batch 743 Loss : 2.9739773273468018, 맞은 개수 : 41\nEpoch : 3, batch 744\n(Train) Batch 744 Loss : 3.017022132873535, 맞은 개수 : 39\nEpoch : 3, batch 745\n(Train) Batch 745 Loss : 3.252206802368164, 맞은 개수 : 34\nEpoch : 3, batch 746\n(Train) Batch 746 Loss : 3.1217541694641113, 맞은 개수 : 33\nEpoch : 3, batch 747\n(Train) Batch 747 Loss : 2.749349594116211, 맞은 개수 : 44\nEpoch : 3, batch 748\n(Train) Batch 748 Loss : 3.245846748352051, 맞은 개수 : 32\nEpoch : 3, batch 749\n(Train) Batch 749 Loss : 3.1063790321350098, 맞은 개수 : 39\nEpoch : 3, batch 750\n(Train) Batch 750 Loss : 2.964493989944458, 맞은 개수 : 39\nEpoch : 3, batch 751\n(Train) Batch 751 Loss : 3.053499221801758, 맞은 개수 : 40\nEpoch : 3, batch 752\n(Train) Batch 752 Loss : 2.9940128326416016, 맞은 개수 : 42\nEpoch : 3, batch 753\n(Train) Batch 753 Loss : 2.8929762840270996, 맞은 개수 : 44\nEpoch : 3, batch 754\n(Train) Batch 754 Loss : 2.7457542419433594, 맞은 개수 : 45\nEpoch : 3, batch 755\n(Train) Batch 755 Loss : 2.9938530921936035, 맞은 개수 : 33\nEpoch : 3, batch 756\n(Train) Batch 756 Loss : 3.12605619430542, 맞은 개수 : 36\nEpoch : 3, batch 757\n(Train) Batch 757 Loss : 3.199463129043579, 맞은 개수 : 34\nEpoch : 3, batch 758\n(Train) Batch 758 Loss : 3.0207841396331787, 맞은 개수 : 40\nEpoch : 3, batch 759\n(Train) Batch 759 Loss : 3.105201005935669, 맞은 개수 : 32\nEpoch : 3, batch 760\n(Train) Batch 760 Loss : 2.923555612564087, 맞은 개수 : 42\nEpoch : 3, batch 761\n(Train) Batch 761 Loss : 2.8996706008911133, 맞은 개수 : 35\nEpoch : 3, batch 762\n(Train) Batch 762 Loss : 2.86372971534729, 맞은 개수 : 39\nEpoch : 3, batch 763\n(Train) Batch 763 Loss : 2.8812685012817383, 맞은 개수 : 39\nEpoch : 3, batch 764\n(Train) Batch 764 Loss : 2.9274466037750244, 맞은 개수 : 44\nEpoch : 3, batch 765\n(Train) Batch 765 Loss : 2.7982349395751953, 맞은 개수 : 44\nEpoch : 3, batch 766\n(Train) Batch 766 Loss : 3.2329461574554443, 맞은 개수 : 28\nEpoch : 3, batch 767\n(Train) Batch 767 Loss : 2.987330913543701, 맞은 개수 : 43\nEpoch : 3, batch 768\n(Train) Batch 768 Loss : 2.731822967529297, 맞은 개수 : 48\nEpoch : 3, batch 769\n(Train) Batch 769 Loss : 2.91789174079895, 맞은 개수 : 36\nEpoch : 3, batch 770\n(Train) Batch 770 Loss : 3.3551077842712402, 맞은 개수 : 32\nEpoch : 3, batch 771\n(Train) Batch 771 Loss : 2.9820961952209473, 맞은 개수 : 42\nEpoch : 3, batch 772\n(Train) Batch 772 Loss : 2.9641506671905518, 맞은 개수 : 35\nEpoch : 3, batch 773\n(Train) Batch 773 Loss : 3.3069865703582764, 맞은 개수 : 29\nEpoch : 3, batch 774\n(Train) Batch 774 Loss : 2.724691867828369, 맞은 개수 : 55\nEpoch : 3, batch 775\n(Train) Batch 775 Loss : 3.0779666900634766, 맞은 개수 : 43\nEpoch : 3, batch 776\n(Train) Batch 776 Loss : 3.2866156101226807, 맞은 개수 : 34\nEpoch : 3, batch 777\n(Train) Batch 777 Loss : 3.0874884128570557, 맞은 개수 : 38\nEpoch : 3, batch 778\n(Train) Batch 778 Loss : 2.900787115097046, 맞은 개수 : 37\nEpoch : 3, batch 779\n(Train) Batch 779 Loss : 2.9528634548187256, 맞은 개수 : 38\nEpoch : 3, batch 780\n(Train) Batch 780 Loss : 2.7402541637420654, 맞은 개수 : 38\nEpoch : 3, batch 781\n(Train) Batch 781 Loss : 2.9071357250213623, 맞은 개수 : 43\nEpoch : 3, batch 782\n(Train) Batch 782 Loss : 2.955109119415283, 맞은 개수 : 43\nEpoch : 3, batch 783\n(Train) Batch 783 Loss : 3.3441224098205566, 맞은 개수 : 29\nEpoch : 3, batch 784\n(Train) Batch 784 Loss : 2.6871910095214844, 맞은 개수 : 55\nEpoch : 3, batch 785\n(Train) Batch 785 Loss : 3.184488534927368, 맞은 개수 : 35\nEpoch : 3, batch 786\n(Train) Batch 786 Loss : 2.933259963989258, 맞은 개수 : 39\nEpoch : 3, batch 787\n(Train) Batch 787 Loss : 3.134220600128174, 맞은 개수 : 39\nEpoch : 3, batch 788\n(Train) Batch 788 Loss : 3.3498404026031494, 맞은 개수 : 35\nEpoch : 3, batch 789\n(Train) Batch 789 Loss : 2.9889965057373047, 맞은 개수 : 43\nEpoch : 3, batch 790\n(Train) Batch 790 Loss : 3.3218398094177246, 맞은 개수 : 28\nEpoch : 3, batch 791\n(Train) Batch 791 Loss : 3.084233522415161, 맞은 개수 : 31\nEpoch : 3, batch 792\n(Train) Batch 792 Loss : 2.8690757751464844, 맞은 개수 : 38\nEpoch : 3, batch 793\n(Train) Batch 793 Loss : 3.0868566036224365, 맞은 개수 : 39\nEpoch : 3, batch 794\n(Train) Batch 794 Loss : 2.7828242778778076, 맞은 개수 : 43\nEpoch : 3, batch 795\n(Train) Batch 795 Loss : 3.128492593765259, 맞은 개수 : 34\nEpoch : 3, batch 796\n(Train) Batch 796 Loss : 3.081254005432129, 맞은 개수 : 37\nEpoch : 3, batch 797\n(Train) Batch 797 Loss : 2.9847841262817383, 맞은 개수 : 38\nEpoch : 3, batch 798\n(Train) Batch 798 Loss : 3.075441360473633, 맞은 개수 : 41\nEpoch : 3, batch 799\n(Train) Batch 799 Loss : 3.110180616378784, 맞은 개수 : 34\nEpoch : 3, batch 800\n(Train) Batch 800 Loss : 2.961191415786743, 맞은 개수 : 42\nEpoch : 3, batch 801\n(Train) Batch 801 Loss : 3.095716714859009, 맞은 개수 : 40\nEpoch : 3, batch 802\n(Train) Batch 802 Loss : 3.0274791717529297, 맞은 개수 : 40\nEpoch : 3, batch 803\n(Train) Batch 803 Loss : 3.142467975616455, 맞은 개수 : 31\nEpoch : 3, batch 804\n(Train) Batch 804 Loss : 3.3414840698242188, 맞은 개수 : 32\nEpoch : 3, batch 805\n(Train) Batch 805 Loss : 2.6963350772857666, 맞은 개수 : 42\nEpoch : 3, batch 806\n(Train) Batch 806 Loss : 3.007997989654541, 맞은 개수 : 45\nEpoch : 3, batch 807\n(Train) Batch 807 Loss : 3.3434903621673584, 맞은 개수 : 36\nEpoch : 3, batch 808\n(Train) Batch 808 Loss : 2.753370523452759, 맞은 개수 : 44\nEpoch : 3, batch 809\n(Train) Batch 809 Loss : 2.721900463104248, 맞은 개수 : 46\nEpoch : 3, batch 810\n(Train) Batch 810 Loss : 3.098433256149292, 맞은 개수 : 36\nEpoch : 3, batch 811\n(Train) Batch 811 Loss : 2.6182456016540527, 맞은 개수 : 43\nEpoch : 3, batch 812\n(Train) Batch 812 Loss : 2.9084832668304443, 맞은 개수 : 41\nEpoch : 3, batch 813\n(Train) Batch 813 Loss : 3.1014041900634766, 맞은 개수 : 42\nEpoch : 3, batch 814\n(Train) Batch 814 Loss : 2.804217576980591, 맞은 개수 : 38\nEpoch : 3, batch 815\n(Train) Batch 815 Loss : 2.975611448287964, 맞은 개수 : 41\nEpoch : 3, batch 816\n(Train) Batch 816 Loss : 3.1789181232452393, 맞은 개수 : 34\nEpoch : 3, batch 817\n(Train) Batch 817 Loss : 3.166433811187744, 맞은 개수 : 30\nEpoch : 3, batch 818\n(Train) Batch 818 Loss : 3.191823720932007, 맞은 개수 : 38\nEpoch : 3, batch 819\n(Train) Batch 819 Loss : 2.8594138622283936, 맞은 개수 : 46\nEpoch : 3, batch 820\n(Train) Batch 820 Loss : 2.8490307331085205, 맞은 개수 : 40\nEpoch : 3, batch 821\n(Train) Batch 821 Loss : 3.183926820755005, 맞은 개수 : 33\nEpoch : 3, batch 822\n(Train) Batch 822 Loss : 3.031503677368164, 맞은 개수 : 35\nEpoch : 3, batch 823\n(Train) Batch 823 Loss : 2.8013336658477783, 맞은 개수 : 37\nEpoch : 3, batch 824\n(Train) Batch 824 Loss : 2.855252981185913, 맞은 개수 : 43\nEpoch : 3, batch 825\n(Train) Batch 825 Loss : 2.6464505195617676, 맞은 개수 : 44\nEpoch : 3, batch 826\n(Train) Batch 826 Loss : 3.099292039871216, 맞은 개수 : 36\nEpoch : 3, batch 827\n(Train) Batch 827 Loss : 3.1511964797973633, 맞은 개수 : 29\nEpoch : 3, batch 828\n(Train) Batch 828 Loss : 2.9774134159088135, 맞은 개수 : 42\nEpoch : 3, batch 829\n(Train) Batch 829 Loss : 3.3343722820281982, 맞은 개수 : 29\nEpoch : 3, batch 830\n(Train) Batch 830 Loss : 3.0810842514038086, 맞은 개수 : 33\nEpoch : 3, batch 831\n(Train) Batch 831 Loss : 3.248729705810547, 맞은 개수 : 38\nEpoch : 3, batch 832\n(Train) Batch 832 Loss : 3.282048225402832, 맞은 개수 : 31\nEpoch : 3, batch 833\n(Train) Batch 833 Loss : 2.866848945617676, 맞은 개수 : 45\nEpoch : 3, batch 834\n(Train) Batch 834 Loss : 2.9144532680511475, 맞은 개수 : 46\nEpoch : 3, batch 835\n(Train) Batch 835 Loss : 2.9185917377471924, 맞은 개수 : 43\nEpoch : 3, batch 836\n(Train) Batch 836 Loss : 2.962409257888794, 맞은 개수 : 45\nEpoch : 3, batch 837\n(Train) Batch 837 Loss : 3.28133487701416, 맞은 개수 : 30\nEpoch : 3, batch 838\n(Train) Batch 838 Loss : 2.9759979248046875, 맞은 개수 : 41\nEpoch : 3, batch 839\n(Train) Batch 839 Loss : 3.052856683731079, 맞은 개수 : 39\nEpoch : 3, batch 840\n(Train) Batch 840 Loss : 2.840547561645508, 맞은 개수 : 37\nEpoch : 3, batch 841\n(Train) Batch 841 Loss : 3.0290536880493164, 맞은 개수 : 40\nEpoch : 3, batch 842\n(Train) Batch 842 Loss : 3.056942939758301, 맞은 개수 : 37\nEpoch : 3, batch 843\n(Train) Batch 843 Loss : 3.1196422576904297, 맞은 개수 : 37\nEpoch : 3, batch 844\n(Train) Batch 844 Loss : 3.193099021911621, 맞은 개수 : 33\nEpoch : 3, batch 845\n(Train) Batch 845 Loss : 3.21895170211792, 맞은 개수 : 34\nEpoch : 3, batch 846\n(Train) Batch 846 Loss : 2.932462692260742, 맞은 개수 : 41\nEpoch : 3, batch 847\n(Train) Batch 847 Loss : 3.0106215476989746, 맞은 개수 : 34\nEpoch : 3, batch 848\n(Train) Batch 848 Loss : 3.0906319618225098, 맞은 개수 : 39\nEpoch : 3, batch 849\n(Train) Batch 849 Loss : 3.3136730194091797, 맞은 개수 : 31\nEpoch : 3, batch 850\n(Train) Batch 850 Loss : 3.047656297683716, 맞은 개수 : 32\nEpoch : 3, batch 851\n(Train) Batch 851 Loss : 3.041651725769043, 맞은 개수 : 33\nEpoch : 3, batch 852\n(Train) Batch 852 Loss : 2.9977893829345703, 맞은 개수 : 40\nEpoch : 3, batch 853\n(Train) Batch 853 Loss : 2.9268603324890137, 맞은 개수 : 32\nEpoch : 3, batch 854\n(Train) Batch 854 Loss : 3.3321001529693604, 맞은 개수 : 36\nEpoch : 3, batch 855\n(Train) Batch 855 Loss : 3.198516368865967, 맞은 개수 : 31\nEpoch : 3, batch 856\n(Train) Batch 856 Loss : 2.657510995864868, 맞은 개수 : 44\nEpoch : 3, batch 857\n(Train) Batch 857 Loss : 2.9960150718688965, 맞은 개수 : 36\nEpoch : 3, batch 858\n(Train) Batch 858 Loss : 3.021294116973877, 맞은 개수 : 35\nEpoch : 3, batch 859\n(Train) Batch 859 Loss : 2.9499340057373047, 맞은 개수 : 38\nEpoch : 3, batch 860\n(Train) Batch 860 Loss : 2.992208957672119, 맞은 개수 : 40\nEpoch : 3, batch 861\n(Train) Batch 861 Loss : 3.0894219875335693, 맞은 개수 : 41\nEpoch : 3, batch 862\n(Train) Batch 862 Loss : 3.285153865814209, 맞은 개수 : 29\nEpoch : 3, batch 863\n(Train) Batch 863 Loss : 2.974041223526001, 맞은 개수 : 40\nEpoch : 3, batch 864\n(Train) Batch 864 Loss : 3.142096519470215, 맞은 개수 : 40\nEpoch : 3, batch 865\n(Train) Batch 865 Loss : 2.8427793979644775, 맞은 개수 : 41\nEpoch : 3, batch 866\n(Train) Batch 866 Loss : 2.953453302383423, 맞은 개수 : 36\nEpoch : 3, batch 867\n(Train) Batch 867 Loss : 3.0753371715545654, 맞은 개수 : 44\nEpoch : 3, batch 868\n(Train) Batch 868 Loss : 2.669934034347534, 맞은 개수 : 50\nEpoch : 3, batch 869\n(Train) Batch 869 Loss : 3.050513505935669, 맞은 개수 : 39\nEpoch : 3, batch 870\n(Train) Batch 870 Loss : 2.8644227981567383, 맞은 개수 : 41\nEpoch : 3, batch 871\n(Train) Batch 871 Loss : 2.6214065551757812, 맞은 개수 : 47\nEpoch : 3, batch 872\n(Train) Batch 872 Loss : 3.0445127487182617, 맞은 개수 : 40\nEpoch : 3, batch 873\n(Train) Batch 873 Loss : 3.0369772911071777, 맞은 개수 : 38\nEpoch : 3, batch 874\n(Train) Batch 874 Loss : 2.747446298599243, 맞은 개수 : 44\nEpoch : 3, batch 875\n(Train) Batch 875 Loss : 2.8913681507110596, 맞은 개수 : 34\nEpoch : 3, batch 876\n(Train) Batch 876 Loss : 2.9849612712860107, 맞은 개수 : 44\nEpoch : 3, batch 877\n(Train) Batch 877 Loss : 3.2206051349639893, 맞은 개수 : 29\nEpoch : 3, batch 878\n(Train) Batch 878 Loss : 2.949620485305786, 맞은 개수 : 42\nEpoch : 3, batch 879\n(Train) Batch 879 Loss : 2.8414008617401123, 맞은 개수 : 47\nEpoch : 3, batch 880\n(Train) Batch 880 Loss : 3.4011456966400146, 맞은 개수 : 33\nEpoch : 3, batch 881\n(Train) Batch 881 Loss : 2.9582812786102295, 맞은 개수 : 43\nEpoch : 3, batch 882\n(Train) Batch 882 Loss : 2.9094014167785645, 맞은 개수 : 41\nEpoch : 3, batch 883\n(Train) Batch 883 Loss : 3.1093027591705322, 맞은 개수 : 35\nEpoch : 3, batch 884\n(Train) Batch 884 Loss : 2.8377554416656494, 맞은 개수 : 44\nEpoch : 3, batch 885\n(Train) Batch 885 Loss : 2.9450578689575195, 맞은 개수 : 45\nEpoch : 3, batch 886\n(Train) Batch 886 Loss : 2.9706366062164307, 맞은 개수 : 37\nEpoch : 3, batch 887\n(Train) Batch 887 Loss : 3.006044626235962, 맞은 개수 : 32\nEpoch : 3, batch 888\n(Train) Batch 888 Loss : 3.1302294731140137, 맞은 개수 : 38\nEpoch : 3, batch 889\n(Train) Batch 889 Loss : 2.976016044616699, 맞은 개수 : 41\nEpoch : 3, batch 890\n(Train) Batch 890 Loss : 3.127626419067383, 맞은 개수 : 34\nEpoch : 3, batch 891\n(Train) Batch 891 Loss : 3.0120580196380615, 맞은 개수 : 41\nEpoch : 3, batch 892\n(Train) Batch 892 Loss : 2.8779890537261963, 맞은 개수 : 40\nEpoch : 3, batch 893\n(Train) Batch 893 Loss : 2.8894474506378174, 맞은 개수 : 43\nEpoch : 3, batch 894\n(Train) Batch 894 Loss : 3.084933280944824, 맞은 개수 : 43\nEpoch : 3, batch 895\n(Train) Batch 895 Loss : 3.148475408554077, 맞은 개수 : 36\nEpoch : 3, batch 896\n(Train) Batch 896 Loss : 2.7540791034698486, 맞은 개수 : 41\nEpoch : 3, batch 897\n(Train) Batch 897 Loss : 3.076085329055786, 맞은 개수 : 37\nEpoch : 3, batch 898\n(Train) Batch 898 Loss : 3.451780080795288, 맞은 개수 : 31\nEpoch : 3, batch 899\n(Train) Batch 899 Loss : 3.2878072261810303, 맞은 개수 : 39\nEpoch : 3, batch 900\n(Train) Batch 900 Loss : 2.8742003440856934, 맞은 개수 : 40\nEpoch : 3, batch 901\n(Train) Batch 901 Loss : 3.091804027557373, 맞은 개수 : 30\nEpoch : 3, batch 902\n(Train) Batch 902 Loss : 3.347078561782837, 맞은 개수 : 34\nEpoch : 3, batch 903\n(Train) Batch 903 Loss : 2.8286449909210205, 맞은 개수 : 46\nEpoch : 3, batch 904\n(Train) Batch 904 Loss : 3.05194091796875, 맞은 개수 : 37\nEpoch : 3, batch 905\n(Train) Batch 905 Loss : 3.1199734210968018, 맞은 개수 : 40\nEpoch : 3, batch 906\n(Train) Batch 906 Loss : 3.1240923404693604, 맞은 개수 : 39\nEpoch : 3, batch 907\n(Train) Batch 907 Loss : 2.856597423553467, 맞은 개수 : 38\nEpoch : 3, batch 908\n(Train) Batch 908 Loss : 3.131068229675293, 맞은 개수 : 28\nEpoch : 3, batch 909\n(Train) Batch 909 Loss : 2.9172675609588623, 맞은 개수 : 40\nEpoch : 3, batch 910\n(Train) Batch 910 Loss : 3.111269474029541, 맞은 개수 : 39\nEpoch : 3, batch 911\n(Train) Batch 911 Loss : 2.9096710681915283, 맞은 개수 : 42\nEpoch : 3, batch 912\n(Train) Batch 912 Loss : 2.9299933910369873, 맞은 개수 : 40\nEpoch : 3, batch 913\n(Train) Batch 913 Loss : 3.0810980796813965, 맞은 개수 : 39\nEpoch : 3, batch 914\n(Train) Batch 914 Loss : 3.060396909713745, 맞은 개수 : 38\nEpoch : 3, batch 915\n(Train) Batch 915 Loss : 2.956535816192627, 맞은 개수 : 43\nEpoch : 3, batch 916\n(Train) Batch 916 Loss : 3.2544658184051514, 맞은 개수 : 32\nEpoch : 3, batch 917\n(Train) Batch 917 Loss : 3.042604684829712, 맞은 개수 : 42\nEpoch : 3, batch 918\n(Train) Batch 918 Loss : 3.2167060375213623, 맞은 개수 : 33\nEpoch : 3, batch 919\n(Train) Batch 919 Loss : 2.990602970123291, 맞은 개수 : 37\nEpoch : 3, batch 920\n(Train) Batch 920 Loss : 2.9854822158813477, 맞은 개수 : 41\nEpoch : 3, batch 921\n(Train) Batch 921 Loss : 3.104588031768799, 맞은 개수 : 38\nEpoch : 3, batch 922\n(Train) Batch 922 Loss : 2.8951284885406494, 맞은 개수 : 36\nEpoch : 3, batch 923\n(Train) Batch 923 Loss : 3.0489981174468994, 맞은 개수 : 35\nEpoch : 3, batch 924\n(Train) Batch 924 Loss : 2.9556705951690674, 맞은 개수 : 34\nEpoch : 3, batch 925\n(Train) Batch 925 Loss : 2.98543381690979, 맞은 개수 : 36\nEpoch : 3, batch 926\n(Train) Batch 926 Loss : 2.9941306114196777, 맞은 개수 : 35\nEpoch : 3, batch 927\n(Train) Batch 927 Loss : 3.0217092037200928, 맞은 개수 : 41\nEpoch : 3, batch 928\n(Train) Batch 928 Loss : 2.9734764099121094, 맞은 개수 : 32\nEpoch : 3, batch 929\n(Train) Batch 929 Loss : 2.8730010986328125, 맞은 개수 : 44\nEpoch : 3, batch 930\n(Train) Batch 930 Loss : 3.1832468509674072, 맞은 개수 : 31\nEpoch : 3, batch 931\n(Train) Batch 931 Loss : 2.9477336406707764, 맞은 개수 : 43\nEpoch : 3, batch 932\n(Train) Batch 932 Loss : 2.7832422256469727, 맞은 개수 : 37\nEpoch : 3, batch 933\n(Train) Batch 933 Loss : 2.8617048263549805, 맞은 개수 : 37\nEpoch : 3, batch 934\n(Train) Batch 934 Loss : 3.1777706146240234, 맞은 개수 : 40\nEpoch : 3, batch 935\n(Train) Batch 935 Loss : 2.9349563121795654, 맞은 개수 : 35\nEpoch : 3, batch 936\n(Train) Batch 936 Loss : 3.3589463233947754, 맞은 개수 : 31\nEpoch : 3, batch 937\n(Train) Batch 937 Loss : 3.073288917541504, 맞은 개수 : 41\nEpoch : 3, batch 938\n(Train) Batch 938 Loss : 3.0189902782440186, 맞은 개수 : 41\nEpoch : 3, batch 939\n(Train) Batch 939 Loss : 3.2177751064300537, 맞은 개수 : 35\nEpoch : 3, batch 940\n(Train) Batch 940 Loss : 3.0803349018096924, 맞은 개수 : 41\nEpoch : 3, batch 941\n(Train) Batch 941 Loss : 3.210360527038574, 맞은 개수 : 37\nEpoch : 3, batch 942\n(Train) Batch 942 Loss : 2.8909711837768555, 맞은 개수 : 39\nEpoch : 3, batch 943\n(Train) Batch 943 Loss : 2.7592897415161133, 맞은 개수 : 43\nEpoch : 3, batch 944\n(Train) Batch 944 Loss : 2.834350109100342, 맞은 개수 : 46\nEpoch : 3, batch 945\n(Train) Batch 945 Loss : 3.02063250541687, 맞은 개수 : 38\nEpoch : 3, batch 946\n(Train) Batch 946 Loss : 2.4950194358825684, 맞은 개수 : 57\nEpoch : 3, batch 947\n(Train) Batch 947 Loss : 2.928844690322876, 맞은 개수 : 46\nEpoch : 3, batch 948\n(Train) Batch 948 Loss : 2.8048253059387207, 맞은 개수 : 42\nEpoch : 3, batch 949\n(Train) Batch 949 Loss : 3.0142717361450195, 맞은 개수 : 34\nEpoch : 3, batch 950\n(Train) Batch 950 Loss : 3.2169244289398193, 맞은 개수 : 39\nEpoch : 3, batch 951\n(Train) Batch 951 Loss : 3.022298574447632, 맞은 개수 : 39\nEpoch : 3, batch 952\n(Train) Batch 952 Loss : 2.817404270172119, 맞은 개수 : 42\nEpoch : 3, batch 953\n(Train) Batch 953 Loss : 3.1471304893493652, 맞은 개수 : 36\nEpoch : 3, batch 954\n(Train) Batch 954 Loss : 3.0850675106048584, 맞은 개수 : 36\nEpoch : 3, batch 955\n(Train) Batch 955 Loss : 3.024087905883789, 맞은 개수 : 41\nEpoch : 3, batch 956\n(Train) Batch 956 Loss : 2.9030611515045166, 맞은 개수 : 39\nEpoch : 3, batch 957\n(Train) Batch 957 Loss : 2.866386651992798, 맞은 개수 : 38\nEpoch : 3, batch 958\n(Train) Batch 958 Loss : 3.272026538848877, 맞은 개수 : 31\nEpoch : 3, batch 959\n(Train) Batch 959 Loss : 2.913288116455078, 맞은 개수 : 36\nEpoch : 3, batch 960\n(Train) Batch 960 Loss : 3.0423152446746826, 맞은 개수 : 46\nEpoch : 3, batch 961\n(Train) Batch 961 Loss : 3.121795177459717, 맞은 개수 : 39\nEpoch : 3, batch 962\n(Train) Batch 962 Loss : 3.250711441040039, 맞은 개수 : 35\nEpoch : 3, batch 963\n(Train) Batch 963 Loss : 2.874171018600464, 맞은 개수 : 43\nEpoch : 3, batch 964\n(Train) Batch 964 Loss : 3.036658525466919, 맞은 개수 : 40\nEpoch : 3, batch 965\n(Train) Batch 965 Loss : 3.0324363708496094, 맞은 개수 : 38\nEpoch : 3, batch 966\n(Train) Batch 966 Loss : 3.1167941093444824, 맞은 개수 : 32\nEpoch : 3, batch 967\n(Train) Batch 967 Loss : 2.9265809059143066, 맞은 개수 : 33\nEpoch : 3, batch 968\n(Train) Batch 968 Loss : 3.0296390056610107, 맞은 개수 : 34\nEpoch : 3, batch 969\n(Train) Batch 969 Loss : 2.94856333732605, 맞은 개수 : 47\nEpoch : 3, batch 970\n(Train) Batch 970 Loss : 3.0825998783111572, 맞은 개수 : 38\nEpoch : 3, batch 971\n(Train) Batch 971 Loss : 3.146641254425049, 맞은 개수 : 34\nEpoch : 3, batch 972\n(Train) Batch 972 Loss : 2.8720037937164307, 맞은 개수 : 42\nEpoch : 3, batch 973\n(Train) Batch 973 Loss : 3.3013176918029785, 맞은 개수 : 32\nEpoch : 3, batch 974\n(Train) Batch 974 Loss : 2.9390640258789062, 맞은 개수 : 42\nEpoch : 3, batch 975\n(Train) Batch 975 Loss : 2.9935553073883057, 맞은 개수 : 44\nEpoch : 3, batch 976\n(Train) Batch 976 Loss : 2.886282205581665, 맞은 개수 : 41\nEpoch : 3, batch 977\n(Train) Batch 977 Loss : 2.9043331146240234, 맞은 개수 : 41\nEpoch : 3, batch 978\n(Train) Batch 978 Loss : 2.914707899093628, 맞은 개수 : 38\nEpoch : 3, batch 979\n(Train) Batch 979 Loss : 3.022745132446289, 맞은 개수 : 39\nEpoch : 3, batch 980\n(Train) Batch 980 Loss : 3.0833487510681152, 맞은 개수 : 35\nEpoch : 3, batch 981\n(Train) Batch 981 Loss : 3.1405720710754395, 맞은 개수 : 37\nEpoch : 3, batch 982\n(Train) Batch 982 Loss : 2.9020674228668213, 맞은 개수 : 46\nEpoch : 3, batch 983\n(Train) Batch 983 Loss : 2.8683764934539795, 맞은 개수 : 41\nEpoch : 3, batch 984\n(Train) Batch 984 Loss : 2.942744493484497, 맞은 개수 : 45\nEpoch : 3, batch 985\n(Train) Batch 985 Loss : 2.927330255508423, 맞은 개수 : 38\nEpoch : 3, batch 986\n(Train) Batch 986 Loss : 3.165254592895508, 맞은 개수 : 35\nEpoch : 3, batch 987\n(Train) Batch 987 Loss : 2.8484764099121094, 맞은 개수 : 42\nEpoch : 3, batch 988\n(Train) Batch 988 Loss : 2.9373655319213867, 맞은 개수 : 47\nEpoch : 3, batch 989\n(Train) Batch 989 Loss : 2.856045961380005, 맞은 개수 : 41\nEpoch : 3, batch 990\n(Train) Batch 990 Loss : 3.0854454040527344, 맞은 개수 : 41\nEpoch : 3, batch 991\n(Train) Batch 991 Loss : 2.935659646987915, 맞은 개수 : 39\nEpoch : 3, batch 992\n(Train) Batch 992 Loss : 2.8848071098327637, 맞은 개수 : 43\nEpoch : 3, batch 993\n(Train) Batch 993 Loss : 2.906642198562622, 맞은 개수 : 45\nEpoch : 3, batch 994\n(Train) Batch 994 Loss : 2.757458448410034, 맞은 개수 : 51\nEpoch : 3, batch 995\n(Train) Batch 995 Loss : 3.19952654838562, 맞은 개수 : 33\nEpoch : 3, batch 996\n(Train) Batch 996 Loss : 2.812307119369507, 맞은 개수 : 45\nEpoch : 3, batch 997\n(Train) Batch 997 Loss : 2.7001004219055176, 맞은 개수 : 50\nEpoch : 3, batch 998\n(Train) Batch 998 Loss : 2.937352418899536, 맞은 개수 : 46\nEpoch : 3, batch 999\n(Train) Batch 999 Loss : 3.1477692127227783, 맞은 개수 : 30\nEpoch : 3, batch 1000\n(Train) Batch 1000 Loss : 3.129241943359375, 맞은 개수 : 33\nEpoch : 3, batch 1001\n(Train) Batch 1001 Loss : 3.1793627738952637, 맞은 개수 : 32\nEpoch : 3, batch 1002\n(Train) Batch 1002 Loss : 3.289417028427124, 맞은 개수 : 27\nEpoch : 3, batch 1003\n(Train) Batch 1003 Loss : 2.9436981678009033, 맞은 개수 : 44\nEpoch : 3, batch 1004\n(Train) Batch 1004 Loss : 3.0849874019622803, 맞은 개수 : 36\nEpoch : 3, batch 1005\n(Train) Batch 1005 Loss : 2.8599653244018555, 맞은 개수 : 42\nEpoch : 3, batch 1006\n(Train) Batch 1006 Loss : 3.1058194637298584, 맞은 개수 : 36\nEpoch : 3, batch 1007\n(Train) Batch 1007 Loss : 2.8032824993133545, 맞은 개수 : 51\nEpoch : 3, batch 1008\n(Train) Batch 1008 Loss : 2.9952590465545654, 맞은 개수 : 44\nEpoch : 3, batch 1009\n(Train) Batch 1009 Loss : 3.276134967803955, 맞은 개수 : 32\nEpoch : 3, batch 1010\n(Train) Batch 1010 Loss : 3.192108631134033, 맞은 개수 : 34\nEpoch : 3, batch 1011\n(Train) Batch 1011 Loss : 3.0494749546051025, 맞은 개수 : 37\nEpoch : 3, batch 1012\n(Train) Batch 1012 Loss : 2.962705612182617, 맞은 개수 : 39\nEpoch : 3, batch 1013\n(Train) Batch 1013 Loss : 3.148129463195801, 맞은 개수 : 42\nEpoch : 3, batch 1014\n(Train) Batch 1014 Loss : 2.7244718074798584, 맞은 개수 : 48\nEpoch : 3, batch 1015\n(Train) Batch 1015 Loss : 3.0996882915496826, 맞은 개수 : 40\nEpoch : 3, batch 1016\n(Train) Batch 1016 Loss : 3.190972089767456, 맞은 개수 : 33\nEpoch : 3, batch 1017\n(Train) Batch 1017 Loss : 3.0477609634399414, 맞은 개수 : 34\nEpoch : 3, batch 1018\n(Train) Batch 1018 Loss : 3.2756474018096924, 맞은 개수 : 31\nEpoch : 3, batch 1019\n(Train) Batch 1019 Loss : 2.746114492416382, 맞은 개수 : 39\nEpoch : 3, batch 1020\n(Train) Batch 1020 Loss : 2.8592147827148438, 맞은 개수 : 50\nEpoch : 3, batch 1021\n(Train) Batch 1021 Loss : 3.0057878494262695, 맞은 개수 : 36\nEpoch : 3, batch 1022\n(Train) Batch 1022 Loss : 3.0483686923980713, 맞은 개수 : 34\nEpoch : 3, batch 1023\n(Train) Batch 1023 Loss : 2.961752414703369, 맞은 개수 : 33\nEpoch : 3, batch 1024\n(Train) Batch 1024 Loss : 3.0360641479492188, 맞은 개수 : 39\nEpoch : 3, batch 1025\n(Train) Batch 1025 Loss : 3.168814182281494, 맞은 개수 : 32\nEpoch : 3, batch 1026\n(Train) Batch 1026 Loss : 3.0199038982391357, 맞은 개수 : 37\nEpoch : 3, batch 1027\n(Train) Batch 1027 Loss : 3.2492809295654297, 맞은 개수 : 27\nEpoch : 3, batch 1028\n(Train) Batch 1028 Loss : 3.2063474655151367, 맞은 개수 : 36\nEpoch : 3, batch 1029\n(Train) Batch 1029 Loss : 2.7798662185668945, 맞은 개수 : 40\nEpoch : 3, batch 1030\n(Train) Batch 1030 Loss : 2.6996819972991943, 맞은 개수 : 42\nEpoch : 3, batch 1031\n(Train) Batch 1031 Loss : 3.0712616443634033, 맞은 개수 : 30\nEpoch : 3, batch 1032\n(Train) Batch 1032 Loss : 3.219850778579712, 맞은 개수 : 28\nEpoch : 3, batch 1033\n(Train) Batch 1033 Loss : 3.1423838138580322, 맞은 개수 : 39\nEpoch : 3, batch 1034\n(Train) Batch 1034 Loss : 2.8236491680145264, 맞은 개수 : 43\nEpoch : 3, batch 1035\n(Train) Batch 1035 Loss : 2.627643585205078, 맞은 개수 : 48\nEpoch : 3, batch 1036\n(Train) Batch 1036 Loss : 2.8500232696533203, 맞은 개수 : 45\nEpoch : 3, batch 1037\n(Train) Batch 1037 Loss : 3.2000811100006104, 맞은 개수 : 31\nEpoch : 3, batch 1038\n(Train) Batch 1038 Loss : 2.8272674083709717, 맞은 개수 : 41\nEpoch : 3, batch 1039\n(Train) Batch 1039 Loss : 3.1645758152008057, 맞은 개수 : 40\nEpoch : 3, batch 1040\n(Train) Batch 1040 Loss : 2.9665441513061523, 맞은 개수 : 39\nEpoch : 3, batch 1041\n(Train) Batch 1041 Loss : 2.912034511566162, 맞은 개수 : 42\nEpoch : 3, batch 1042\n(Train) Batch 1042 Loss : 3.2604806423187256, 맞은 개수 : 36\nEpoch : 3, batch 1043\n(Train) Batch 1043 Loss : 2.8668689727783203, 맞은 개수 : 33\nEpoch : 3, batch 1044\n(Train) Batch 1044 Loss : 2.6482183933258057, 맞은 개수 : 49\nEpoch : 3, batch 1045\n(Train) Batch 1045 Loss : 2.935535192489624, 맞은 개수 : 42\nEpoch : 3, batch 1046\n(Train) Batch 1046 Loss : 2.8123931884765625, 맞은 개수 : 46\nEpoch : 3, batch 1047\n(Train) Batch 1047 Loss : 3.0479860305786133, 맞은 개수 : 39\nEpoch : 3, batch 1048\n(Train) Batch 1048 Loss : 2.8396198749542236, 맞은 개수 : 43\nEpoch : 3, batch 1049\n(Train) Batch 1049 Loss : 3.0298843383789062, 맞은 개수 : 44\nEpoch : 3, batch 1050\n(Train) Batch 1050 Loss : 2.9877140522003174, 맞은 개수 : 35\nEpoch : 3, batch 1051\n(Train) Batch 1051 Loss : 3.15681791305542, 맞은 개수 : 31\nEpoch : 3, batch 1052\n(Train) Batch 1052 Loss : 2.8558762073516846, 맞은 개수 : 39\nEpoch : 3, batch 1053\n(Train) Batch 1053 Loss : 2.95894193649292, 맞은 개수 : 35\nEpoch : 3, batch 1054\n(Train) Batch 1054 Loss : 3.2544331550598145, 맞은 개수 : 29\nEpoch : 3, batch 1055\n(Train) Batch 1055 Loss : 2.9554054737091064, 맞은 개수 : 34\nEpoch : 3, batch 1056\n(Train) Batch 1056 Loss : 2.972550630569458, 맞은 개수 : 42\nEpoch : 3, batch 1057\n(Train) Batch 1057 Loss : 2.8934214115142822, 맞은 개수 : 43\nEpoch : 3, batch 1058\n(Train) Batch 1058 Loss : 2.7293307781219482, 맞은 개수 : 48\nEpoch : 3, batch 1059\n(Train) Batch 1059 Loss : 3.17144775390625, 맞은 개수 : 30\nEpoch : 3, batch 1060\n(Train) Batch 1060 Loss : 3.0502257347106934, 맞은 개수 : 41\nEpoch : 3, batch 1061\n(Train) Batch 1061 Loss : 2.6211600303649902, 맞은 개수 : 47\nEpoch : 3, batch 1062\n(Train) Batch 1062 Loss : 2.92297625541687, 맞은 개수 : 36\nEpoch : 3, batch 1063\n(Train) Batch 1063 Loss : 2.9111363887786865, 맞은 개수 : 43\nEpoch : 3, batch 1064\n(Train) Batch 1064 Loss : 3.0735390186309814, 맞은 개수 : 31\nEpoch : 3, batch 1065\n(Train) Batch 1065 Loss : 3.179733991622925, 맞은 개수 : 37\nEpoch : 3, batch 1066\n(Train) Batch 1066 Loss : 2.9273135662078857, 맞은 개수 : 36\nEpoch : 3, batch 1067\n(Train) Batch 1067 Loss : 2.9727065563201904, 맞은 개수 : 42\nEpoch : 3, batch 1068\n(Train) Batch 1068 Loss : 2.6074395179748535, 맞은 개수 : 44\nEpoch : 3, batch 1069\n(Train) Batch 1069 Loss : 3.1197304725646973, 맞은 개수 : 35\nEpoch : 3, batch 1070\n(Train) Batch 1070 Loss : 2.997429132461548, 맞은 개수 : 39\nEpoch : 3, batch 1071\n(Train) Batch 1071 Loss : 2.977923631668091, 맞은 개수 : 36\nEpoch : 3, batch 1072\n(Train) Batch 1072 Loss : 2.9440925121307373, 맞은 개수 : 46\nEpoch : 3, batch 1073\n(Train) Batch 1073 Loss : 2.933046340942383, 맞은 개수 : 39\nEpoch : 3, batch 1074\n(Train) Batch 1074 Loss : 2.997328519821167, 맞은 개수 : 40\nEpoch : 3, batch 1075\n(Train) Batch 1075 Loss : 3.0672430992126465, 맞은 개수 : 40\nEpoch : 3, batch 1076\n(Train) Batch 1076 Loss : 3.0304198265075684, 맞은 개수 : 37\nEpoch : 3, batch 1077\n(Train) Batch 1077 Loss : 2.973249912261963, 맞은 개수 : 44\nEpoch : 3, batch 1078\n(Train) Batch 1078 Loss : 3.0438830852508545, 맞은 개수 : 35\nEpoch : 3, batch 1079\n(Train) Batch 1079 Loss : 3.0239310264587402, 맞은 개수 : 39\nEpoch : 3, batch 1080\n(Train) Batch 1080 Loss : 3.3466055393218994, 맞은 개수 : 26\nEpoch : 3, batch 1081\n(Train) Batch 1081 Loss : 2.8994805812835693, 맞은 개수 : 56\nEpoch : 3, batch 1082\n(Train) Batch 1082 Loss : 3.2540042400360107, 맞은 개수 : 35\nEpoch : 3, batch 1083\n(Train) Batch 1083 Loss : 3.219696521759033, 맞은 개수 : 41\nEpoch : 3, batch 1084\n(Train) Batch 1084 Loss : 3.260061502456665, 맞은 개수 : 38\nEpoch : 3, batch 1085\n(Train) Batch 1085 Loss : 3.1101479530334473, 맞은 개수 : 38\nEpoch : 3, batch 1086\n(Train) Batch 1086 Loss : 2.9861490726470947, 맞은 개수 : 39\nEpoch : 3, batch 1087\n(Train) Batch 1087 Loss : 3.100893259048462, 맞은 개수 : 35\nEpoch : 3, batch 1088\n(Train) Batch 1088 Loss : 3.0179049968719482, 맞은 개수 : 39\nEpoch : 3, batch 1089\n(Train) Batch 1089 Loss : 3.0699994564056396, 맞은 개수 : 33\nEpoch : 3, batch 1090\n(Train) Batch 1090 Loss : 2.8245792388916016, 맞은 개수 : 45\nEpoch : 3, batch 1091\n(Train) Batch 1091 Loss : 2.936203718185425, 맞은 개수 : 44\nEpoch : 3, batch 1092\n(Train) Batch 1092 Loss : 3.0649757385253906, 맞은 개수 : 37\nEpoch : 3, batch 1093\n(Train) Batch 1093 Loss : 2.9376444816589355, 맞은 개수 : 40\nEpoch : 3, batch 1094\n(Train) Batch 1094 Loss : 3.1202402114868164, 맞은 개수 : 40\nEpoch : 3, batch 1095\n(Train) Batch 1095 Loss : 2.9139435291290283, 맞은 개수 : 39\nEpoch : 3, batch 1096\n(Train) Batch 1096 Loss : 2.9774107933044434, 맞은 개수 : 38\nEpoch : 3, batch 1097\n(Train) Batch 1097 Loss : 2.8462963104248047, 맞은 개수 : 45\nEpoch : 3, batch 1098\n(Train) Batch 1098 Loss : 3.0154051780700684, 맞은 개수 : 34\nEpoch : 3, batch 1099\n(Train) Batch 1099 Loss : 2.830519199371338, 맞은 개수 : 38\nEpoch : 3, batch 1100\n(Train) Batch 1100 Loss : 2.9405150413513184, 맞은 개수 : 40\nEpoch : 3, batch 1101\n(Train) Batch 1101 Loss : 2.966979503631592, 맞은 개수 : 38\nEpoch : 3, batch 1102\n(Train) Batch 1102 Loss : 2.866947889328003, 맞은 개수 : 40\nEpoch : 3, batch 1103\n(Train) Batch 1103 Loss : 2.975874900817871, 맞은 개수 : 40\nEpoch : 3, batch 1104\n(Train) Batch 1104 Loss : 2.9099321365356445, 맞은 개수 : 37\nEpoch : 3, batch 1105\n(Train) Batch 1105 Loss : 2.9420015811920166, 맞은 개수 : 39\nEpoch : 3, batch 1106\n(Train) Batch 1106 Loss : 3.036411762237549, 맞은 개수 : 41\nEpoch : 3, batch 1107\n(Train) Batch 1107 Loss : 2.8998188972473145, 맞은 개수 : 44\nEpoch : 3, batch 1108\n(Train) Batch 1108 Loss : 3.0465924739837646, 맞은 개수 : 42\nEpoch : 3, batch 1109\n(Train) Batch 1109 Loss : 3.100769281387329, 맞은 개수 : 39\nEpoch : 3, batch 1110\n(Train) Batch 1110 Loss : 2.9609832763671875, 맞은 개수 : 35\nEpoch : 3, batch 1111\n(Train) Batch 1111 Loss : 2.824584484100342, 맞은 개수 : 42\nEpoch : 3, batch 1112\n(Train) Batch 1112 Loss : 3.0674893856048584, 맞은 개수 : 30\nEpoch : 3, batch 1113\n(Train) Batch 1113 Loss : 3.2494900226593018, 맞은 개수 : 34\nEpoch : 3, batch 1114\n(Train) Batch 1114 Loss : 2.857081651687622, 맞은 개수 : 35\nEpoch : 3, batch 1115\n(Train) Batch 1115 Loss : 2.8372745513916016, 맞은 개수 : 36\nEpoch : 3, batch 1116\n(Train) Batch 1116 Loss : 3.006559133529663, 맞은 개수 : 46\nEpoch : 3, batch 1117\n(Train) Batch 1117 Loss : 2.8670670986175537, 맞은 개수 : 38\nEpoch : 3, batch 1118\n(Train) Batch 1118 Loss : 2.677398204803467, 맞은 개수 : 44\nEpoch : 3, batch 1119\n(Train) Batch 1119 Loss : 3.030905246734619, 맞은 개수 : 41\nEpoch : 3, batch 1120\n(Train) Batch 1120 Loss : 2.9032418727874756, 맞은 개수 : 39\nEpoch : 3, batch 1121\n(Train) Batch 1121 Loss : 2.7539637088775635, 맞은 개수 : 43\nEpoch : 3, batch 1122\n(Train) Batch 1122 Loss : 2.7098824977874756, 맞은 개수 : 51\nEpoch : 3, batch 1123\n(Train) Batch 1123 Loss : 3.324881076812744, 맞은 개수 : 29\nEpoch : 3, batch 1124\n(Train) Batch 1124 Loss : 2.961737632751465, 맞은 개수 : 42\nEpoch : 3, batch 1125\n(Train) Batch 1125 Loss : 3.1212477684020996, 맞은 개수 : 33\nEpoch : 3, batch 1126\n(Train) Batch 1126 Loss : 3.355354070663452, 맞은 개수 : 32\nEpoch : 3, batch 1127\n(Train) Batch 1127 Loss : 3.3057873249053955, 맞은 개수 : 36\nEpoch : 3, batch 1128\n(Train) Batch 1128 Loss : 2.811117649078369, 맞은 개수 : 43\nEpoch : 3, batch 1129\n(Train) Batch 1129 Loss : 3.055046796798706, 맞은 개수 : 41\nEpoch : 3, batch 1130\n(Train) Batch 1130 Loss : 3.200423240661621, 맞은 개수 : 36\nEpoch : 3, batch 1131\n(Train) Batch 1131 Loss : 2.9182608127593994, 맞은 개수 : 30\nEpoch : 3, batch 1132\n(Train) Batch 1132 Loss : 2.9125518798828125, 맞은 개수 : 42\nEpoch : 3, batch 1133\n(Train) Batch 1133 Loss : 2.983236789703369, 맞은 개수 : 43\nEpoch : 3, batch 1134\n(Train) Batch 1134 Loss : 2.8217194080352783, 맞은 개수 : 46\nEpoch : 3, batch 1135\n(Train) Batch 1135 Loss : 3.1086266040802, 맞은 개수 : 40\nEpoch : 3, batch 1136\n(Train) Batch 1136 Loss : 2.9021332263946533, 맞은 개수 : 41\nEpoch : 3, batch 1137\n(Train) Batch 1137 Loss : 3.0012056827545166, 맞은 개수 : 45\nEpoch : 3, batch 1138\n(Train) Batch 1138 Loss : 2.884969472885132, 맞은 개수 : 36\nEpoch : 3, batch 1139\n(Train) Batch 1139 Loss : 2.914918899536133, 맞은 개수 : 36\nEpoch : 3, batch 1140\n(Train) Batch 1140 Loss : 2.6826884746551514, 맞은 개수 : 50\nEpoch : 3, batch 1141\n(Train) Batch 1141 Loss : 3.1639859676361084, 맞은 개수 : 39\nEpoch : 3, batch 1142\n(Train) Batch 1142 Loss : 2.9850122928619385, 맞은 개수 : 42\nEpoch : 3, batch 1143\n(Train) Batch 1143 Loss : 2.985999345779419, 맞은 개수 : 45\nEpoch : 3, batch 1144\n(Train) Batch 1144 Loss : 2.8659496307373047, 맞은 개수 : 47\nEpoch : 3, batch 1145\n(Train) Batch 1145 Loss : 3.228687047958374, 맞은 개수 : 35\nEpoch : 3, batch 1146\n(Train) Batch 1146 Loss : 3.2054383754730225, 맞은 개수 : 33\nEpoch : 3, batch 1147\n(Train) Batch 1147 Loss : 3.0232348442077637, 맞은 개수 : 38\nEpoch : 3, batch 1148\n(Train) Batch 1148 Loss : 3.1634891033172607, 맞은 개수 : 36\nEpoch : 3, batch 1149\n(Train) Batch 1149 Loss : 3.0316216945648193, 맞은 개수 : 38\nEpoch : 3, batch 1150\n(Train) Batch 1150 Loss : 2.88143253326416, 맞은 개수 : 36\nEpoch : 3, batch 1151\n(Train) Batch 1151 Loss : 2.9802663326263428, 맞은 개수 : 40\nEpoch : 3, batch 1152\n(Train) Batch 1152 Loss : 2.904686450958252, 맞은 개수 : 45\nEpoch : 3, batch 1153\n(Train) Batch 1153 Loss : 3.0639383792877197, 맞은 개수 : 44\nEpoch : 3, batch 1154\n(Train) Batch 1154 Loss : 2.985886812210083, 맞은 개수 : 39\nEpoch : 3, batch 1155\n(Train) Batch 1155 Loss : 2.9608335494995117, 맞은 개수 : 40\nEpoch : 3, batch 1156\n(Train) Batch 1156 Loss : 2.911996603012085, 맞은 개수 : 38\nEpoch : 3, batch 1157\n(Train) Batch 1157 Loss : 3.1698222160339355, 맞은 개수 : 32\nEpoch : 3, batch 1158\n(Train) Batch 1158 Loss : 3.2079243659973145, 맞은 개수 : 30\nEpoch : 3, batch 1159\n(Train) Batch 1159 Loss : 2.6970436573028564, 맞은 개수 : 45\nEpoch : 3, batch 1160\n(Train) Batch 1160 Loss : 3.132411241531372, 맞은 개수 : 35\nEpoch : 3, batch 1161\n(Train) Batch 1161 Loss : 2.920314311981201, 맞은 개수 : 39\nEpoch : 3, batch 1162\n(Train) Batch 1162 Loss : 3.1532270908355713, 맞은 개수 : 34\nEpoch : 3, batch 1163\n(Train) Batch 1163 Loss : 3.0686686038970947, 맞은 개수 : 43\nEpoch : 3, batch 1164\n(Train) Batch 1164 Loss : 3.0813159942626953, 맞은 개수 : 35\nEpoch : 3, batch 1165\n(Train) Batch 1165 Loss : 2.9261701107025146, 맞은 개수 : 42\nEpoch : 3, batch 1166\n(Train) Batch 1166 Loss : 3.0478267669677734, 맞은 개수 : 38\nEpoch : 3, batch 1167\n(Train) Batch 1167 Loss : 2.784001111984253, 맞은 개수 : 47\nEpoch : 3, batch 1168\n(Train) Batch 1168 Loss : 3.103358745574951, 맞은 개수 : 42\nEpoch : 3, batch 1169\n(Train) Batch 1169 Loss : 3.0451955795288086, 맞은 개수 : 42\nEpoch : 3, batch 1170\n(Train) Batch 1170 Loss : 3.214897871017456, 맞은 개수 : 33\nEpoch : 3, batch 1171\n(Train) Batch 1171 Loss : 3.118551731109619, 맞은 개수 : 32\nEpoch : 3, batch 1172\n(Train) Batch 1172 Loss : 2.9969120025634766, 맞은 개수 : 38\nEpoch : 3, batch 1173\n(Train) Batch 1173 Loss : 2.8061158657073975, 맞은 개수 : 45\nEpoch : 3, batch 1174\n(Train) Batch 1174 Loss : 3.1508634090423584, 맞은 개수 : 33\nEpoch : 3, batch 1175\n(Train) Batch 1175 Loss : 2.9126665592193604, 맞은 개수 : 43\nEpoch : 3, batch 1176\n(Train) Batch 1176 Loss : 2.9107449054718018, 맞은 개수 : 40\nEpoch : 3, batch 1177\n(Train) Batch 1177 Loss : 3.062511682510376, 맞은 개수 : 39\nEpoch : 3, batch 1178\n(Train) Batch 1178 Loss : 2.890733242034912, 맞은 개수 : 45\nEpoch : 3, batch 1179\n(Train) Batch 1179 Loss : 2.947875499725342, 맞은 개수 : 42\nEpoch : 3, batch 1180\n(Train) Batch 1180 Loss : 2.9785256385803223, 맞은 개수 : 47\nEpoch : 3, batch 1181\n(Train) Batch 1181 Loss : 2.9460742473602295, 맞은 개수 : 36\nEpoch : 3, batch 1182\n(Train) Batch 1182 Loss : 3.2780139446258545, 맞은 개수 : 27\nEpoch : 3, batch 1183\n(Train) Batch 1183 Loss : 3.0480921268463135, 맞은 개수 : 41\nEpoch : 3, batch 1184\n(Train) Batch 1184 Loss : 2.9395058155059814, 맞은 개수 : 42\nEpoch : 3, batch 1185\n(Train) Batch 1185 Loss : 2.7626020908355713, 맞은 개수 : 45\nEpoch : 3, batch 1186\n(Train) Batch 1186 Loss : 2.862543821334839, 맞은 개수 : 41\nEpoch : 3, batch 1187\n(Train) Batch 1187 Loss : 2.943255662918091, 맞은 개수 : 43\nEpoch : 3, batch 1188\n(Train) Batch 1188 Loss : 2.999427080154419, 맞은 개수 : 40\nEpoch : 3, batch 1189\n(Train) Batch 1189 Loss : 3.0985124111175537, 맞은 개수 : 37\nEpoch : 3, batch 1190\n(Train) Batch 1190 Loss : 3.132519483566284, 맞은 개수 : 40\nEpoch : 3, batch 1191\n(Train) Batch 1191 Loss : 2.921937942504883, 맞은 개수 : 46\nEpoch : 3, batch 1192\n(Train) Batch 1192 Loss : 2.931825876235962, 맞은 개수 : 43\nEpoch : 3, batch 1193\n(Train) Batch 1193 Loss : 3.051372528076172, 맞은 개수 : 40\nEpoch : 3, batch 1194\n(Train) Batch 1194 Loss : 3.0892210006713867, 맞은 개수 : 40\nEpoch : 3, batch 1195\n(Train) Batch 1195 Loss : 2.8324902057647705, 맞은 개수 : 45\nEpoch : 3, batch 1196\n(Train) Batch 1196 Loss : 2.9105052947998047, 맞은 개수 : 44\nEpoch : 3, batch 1197\n(Train) Batch 1197 Loss : 3.1016805171966553, 맞은 개수 : 38\nEpoch : 3, batch 1198\n(Train) Batch 1198 Loss : 3.2104549407958984, 맞은 개수 : 38\nEpoch : 3, batch 1199\n(Train) Batch 1199 Loss : 2.932464361190796, 맞은 개수 : 40\nEpoch : 3, batch 1200\n(Train) Batch 1200 Loss : 3.128612756729126, 맞은 개수 : 36\nEpoch : 3, batch 1201\n(Train) Batch 1201 Loss : 2.993995189666748, 맞은 개수 : 39\nEpoch : 3, batch 1202\n(Train) Batch 1202 Loss : 2.4413061141967773, 맞은 개수 : 43\nEpoch : 3, batch 1203\n(Train) Batch 1203 Loss : 2.9299871921539307, 맞은 개수 : 42\nEpoch : 3, batch 1204\n(Train) Batch 1204 Loss : 3.0221030712127686, 맞은 개수 : 35\nEpoch : 3, batch 1205\n(Train) Batch 1205 Loss : 2.8475568294525146, 맞은 개수 : 48\nEpoch : 3, batch 1206\n(Train) Batch 1206 Loss : 2.8604347705841064, 맞은 개수 : 43\nEpoch : 3, batch 1207\n(Train) Batch 1207 Loss : 3.1873624324798584, 맞은 개수 : 34\nEpoch : 3, batch 1208\n(Train) Batch 1208 Loss : 2.870453119277954, 맞은 개수 : 38\nEpoch : 3, batch 1209\n(Train) Batch 1209 Loss : 3.1196112632751465, 맞은 개수 : 32\nEpoch : 3, batch 1210\n(Train) Batch 1210 Loss : 2.949312686920166, 맞은 개수 : 41\nEpoch : 3, batch 1211\n(Train) Batch 1211 Loss : 2.967960834503174, 맞은 개수 : 34\nEpoch : 3, batch 1212\n(Train) Batch 1212 Loss : 2.9168007373809814, 맞은 개수 : 44\nEpoch : 3, batch 1213\n(Train) Batch 1213 Loss : 2.9793200492858887, 맞은 개수 : 40\nEpoch : 3, batch 1214\n(Train) Batch 1214 Loss : 2.9759066104888916, 맞은 개수 : 40\nEpoch : 3, batch 1215\n(Train) Batch 1215 Loss : 2.6108181476593018, 맞은 개수 : 47\nEpoch : 3, batch 1216\n(Train) Batch 1216 Loss : 3.030311107635498, 맞은 개수 : 32\nEpoch : 3, batch 1217\n(Train) Batch 1217 Loss : 2.7216591835021973, 맞은 개수 : 45\nEpoch : 3, batch 1218\n(Train) Batch 1218 Loss : 2.837246894836426, 맞은 개수 : 47\nEpoch : 3, batch 1219\n(Train) Batch 1219 Loss : 3.1581521034240723, 맞은 개수 : 32\nEpoch : 3, batch 1220\n(Train) Batch 1220 Loss : 2.9755334854125977, 맞은 개수 : 39\nEpoch : 3, batch 1221\n(Train) Batch 1221 Loss : 2.7486531734466553, 맞은 개수 : 51\nEpoch : 3, batch 1222\n(Train) Batch 1222 Loss : 3.0987327098846436, 맞은 개수 : 39\nEpoch : 3, batch 1223\n(Train) Batch 1223 Loss : 2.9406421184539795, 맞은 개수 : 37\nEpoch : 3, batch 1224\n(Train) Batch 1224 Loss : 2.8508617877960205, 맞은 개수 : 38\nEpoch : 3, batch 1225\n(Train) Batch 1225 Loss : 2.9680099487304688, 맞은 개수 : 39\nEpoch : 3, batch 1226\n(Train) Batch 1226 Loss : 2.881035327911377, 맞은 개수 : 40\nEpoch : 3, batch 1227\n(Train) Batch 1227 Loss : 3.389620780944824, 맞은 개수 : 32\nEpoch : 3, batch 1228\n(Train) Batch 1228 Loss : 3.198822259902954, 맞은 개수 : 37\nEpoch : 3, batch 1229\n(Train) Batch 1229 Loss : 3.0148868560791016, 맞은 개수 : 36\nEpoch : 3, batch 1230\n(Train) Batch 1230 Loss : 3.0013527870178223, 맞은 개수 : 33\nEpoch : 3, batch 1231\n(Train) Batch 1231 Loss : 3.219435691833496, 맞은 개수 : 35\nEpoch : 3, batch 1232\n(Train) Batch 1232 Loss : 2.994710683822632, 맞은 개수 : 35\nEpoch : 3, batch 1233\n(Train) Batch 1233 Loss : 2.739696741104126, 맞은 개수 : 46\nEpoch : 3, batch 1234\n(Train) Batch 1234 Loss : 2.8954622745513916, 맞은 개수 : 40\nEpoch : 3, batch 1235\n(Train) Batch 1235 Loss : 3.2597413063049316, 맞은 개수 : 28\nEpoch : 3, batch 1236\n(Train) Batch 1236 Loss : 3.0795507431030273, 맞은 개수 : 39\nEpoch : 3, batch 1237\n(Train) Batch 1237 Loss : 3.294130802154541, 맞은 개수 : 34\nEpoch : 3, batch 1238\n(Train) Batch 1238 Loss : 3.03605318069458, 맞은 개수 : 36\nEpoch : 3, batch 1239\n(Train) Batch 1239 Loss : 3.3832972049713135, 맞은 개수 : 28\nEpoch : 3, batch 1240\n(Train) Batch 1240 Loss : 2.944884777069092, 맞은 개수 : 39\nEpoch : 3, batch 1241\n(Train) Batch 1241 Loss : 2.6832382678985596, 맞은 개수 : 46\nEpoch : 3, batch 1242\n(Train) Batch 1242 Loss : 2.9440484046936035, 맞은 개수 : 34\nEpoch : 3, batch 1243\n(Train) Batch 1243 Loss : 2.93768572807312, 맞은 개수 : 40\nEpoch : 3, batch 1244\n(Train) Batch 1244 Loss : 3.185886859893799, 맞은 개수 : 33\nEpoch : 3, batch 1245\n(Train) Batch 1245 Loss : 3.1682991981506348, 맞은 개수 : 32\nEpoch : 3, batch 1246\n(Train) Batch 1246 Loss : 3.023932456970215, 맞은 개수 : 30\nEpoch : 3, batch 1247\n(Train) Batch 1247 Loss : 3.2832086086273193, 맞은 개수 : 32\nEpoch : 3, batch 1248\n(Train) Batch 1248 Loss : 3.1931161880493164, 맞은 개수 : 37\nEpoch : 3, batch 1249\n(Train) Batch 1249 Loss : 3.0356767177581787, 맞은 개수 : 34\nEpoch : 3, batch 1250\n(Train) Batch 1250 Loss : 2.97652268409729, 맞은 개수 : 39\nEpoch : 3, batch 1251\n(Train) Batch 1251 Loss : 2.8455920219421387, 맞은 개수 : 47\nEpoch : 3, batch 1252\n(Train) Batch 1252 Loss : 2.8486180305480957, 맞은 개수 : 40\nEpoch : 3, batch 1253\n(Train) Batch 1253 Loss : 3.1210837364196777, 맞은 개수 : 35\nEpoch : 3, batch 1254\n(Train) Batch 1254 Loss : 3.1193792819976807, 맞은 개수 : 41\nEpoch : 3, batch 1255\n(Train) Batch 1255 Loss : 2.8065760135650635, 맞은 개수 : 40\nEpoch : 3, batch 1256\n(Train) Batch 1256 Loss : 2.77526593208313, 맞은 개수 : 42\nEpoch : 3, batch 1257\n(Train) Batch 1257 Loss : 2.883212089538574, 맞은 개수 : 39\nEpoch : 3, batch 1258\n(Train) Batch 1258 Loss : 3.011221170425415, 맞은 개수 : 39\nEpoch : 3, batch 1259\n(Train) Batch 1259 Loss : 3.0808677673339844, 맞은 개수 : 42\nEpoch : 3, batch 1260\n(Train) Batch 1260 Loss : 2.9510626792907715, 맞은 개수 : 42\nEpoch : 3, batch 1261\n(Train) Batch 1261 Loss : 3.0430831909179688, 맞은 개수 : 36\nEpoch : 3, batch 1262\n(Train) Batch 1262 Loss : 3.129941463470459, 맞은 개수 : 37\nEpoch : 3, batch 1263\n(Train) Batch 1263 Loss : 2.8485283851623535, 맞은 개수 : 40\nEpoch : 3, batch 1264\n(Train) Batch 1264 Loss : 2.9834985733032227, 맞은 개수 : 36\nEpoch : 3, batch 1265\n(Train) Batch 1265 Loss : 2.672166585922241, 맞은 개수 : 44\nEpoch : 3, batch 1266\n(Train) Batch 1266 Loss : 2.9305803775787354, 맞은 개수 : 43\nEpoch : 3, batch 1267\n(Train) Batch 1267 Loss : 2.655534267425537, 맞은 개수 : 48\nEpoch : 3, batch 1268\n(Train) Batch 1268 Loss : 2.751310348510742, 맞은 개수 : 50\nEpoch : 3, batch 1269\n(Train) Batch 1269 Loss : 3.03778076171875, 맞은 개수 : 34\nEpoch : 3, batch 1270\n(Train) Batch 1270 Loss : 3.205641269683838, 맞은 개수 : 31\nEpoch : 3, batch 1271\n(Train) Batch 1271 Loss : 2.712440252304077, 맞은 개수 : 48\nEpoch : 3, batch 1272\n(Train) Batch 1272 Loss : 2.6932387351989746, 맞은 개수 : 51\nEpoch : 3, batch 1273\n(Train) Batch 1273 Loss : 3.269075393676758, 맞은 개수 : 31\nEpoch : 3, batch 1274\n(Train) Batch 1274 Loss : 2.693721055984497, 맞은 개수 : 38\nEpoch : 3, batch 1275\n(Train) Batch 1275 Loss : 2.74245548248291, 맞은 개수 : 48\nEpoch : 3, batch 1276\n(Train) Batch 1276 Loss : 2.8066258430480957, 맞은 개수 : 35\nEpoch : 3, batch 1277\n(Train) Batch 1277 Loss : 2.724597215652466, 맞은 개수 : 41\nEpoch : 3, batch 1278\n(Train) Batch 1278 Loss : 2.8623430728912354, 맞은 개수 : 43\nEpoch : 3, batch 1279\n(Train) Batch 1279 Loss : 3.159558057785034, 맞은 개수 : 37\nEpoch : 3, batch 1280\n(Train) Batch 1280 Loss : 3.112597703933716, 맞은 개수 : 37\nEpoch : 3, batch 1281\n(Train) Batch 1281 Loss : 3.0798377990722656, 맞은 개수 : 31\nEpoch : 3, batch 1282\n(Train) Batch 1282 Loss : 3.089296340942383, 맞은 개수 : 35\nEpoch : 3, batch 1283\n(Train) Batch 1283 Loss : 3.072816848754883, 맞은 개수 : 41\nEpoch : 3, batch 1284\n(Train) Batch 1284 Loss : 2.933258056640625, 맞은 개수 : 37\nEpoch : 3, batch 1285\n(Train) Batch 1285 Loss : 2.8631885051727295, 맞은 개수 : 45\nEpoch : 3, batch 1286\n(Train) Batch 1286 Loss : 2.7249739170074463, 맞은 개수 : 51\nEpoch : 3, batch 1287\n(Train) Batch 1287 Loss : 2.8972127437591553, 맞은 개수 : 35\nEpoch : 3, batch 1288\n(Train) Batch 1288 Loss : 3.005082130432129, 맞은 개수 : 46\nEpoch : 3, batch 1289\n(Train) Batch 1289 Loss : 2.9660792350769043, 맞은 개수 : 44\nEpoch : 3, batch 1290\n(Train) Batch 1290 Loss : 2.939890146255493, 맞은 개수 : 40\nEpoch : 3, batch 1291\n(Train) Batch 1291 Loss : 2.836364984512329, 맞은 개수 : 47\nEpoch : 3, batch 1292\n(Train) Batch 1292 Loss : 3.093000650405884, 맞은 개수 : 43\nEpoch : 3, batch 1293\n(Train) Batch 1293 Loss : 3.189727544784546, 맞은 개수 : 34\nEpoch : 3, batch 1294\n(Train) Batch 1294 Loss : 3.2062315940856934, 맞은 개수 : 39\nEpoch : 3, batch 1295\n(Train) Batch 1295 Loss : 2.9392194747924805, 맞은 개수 : 38\nEpoch : 3, batch 1296\n(Train) Batch 1296 Loss : 2.888010025024414, 맞은 개수 : 40\nEpoch : 3, batch 1297\n(Train) Batch 1297 Loss : 2.99930477142334, 맞은 개수 : 37\nEpoch : 3, batch 1298\n(Train) Batch 1298 Loss : 2.70120906829834, 맞은 개수 : 52\nEpoch : 3, batch 1299\n(Train) Batch 1299 Loss : 2.824272632598877, 맞은 개수 : 42\nEpoch : 3, batch 1300\n(Train) Batch 1300 Loss : 3.0118303298950195, 맞은 개수 : 30\nEpoch : 3, batch 1301\n(Train) Batch 1301 Loss : 3.1817164421081543, 맞은 개수 : 34\nEpoch : 3, batch 1302\n(Train) Batch 1302 Loss : 2.8373067378997803, 맞은 개수 : 44\nEpoch : 3, batch 1303\n(Train) Batch 1303 Loss : 2.8905396461486816, 맞은 개수 : 38\nEpoch : 3, batch 1304\n(Train) Batch 1304 Loss : 2.906327962875366, 맞은 개수 : 39\nEpoch : 3, batch 1305\n(Train) Batch 1305 Loss : 2.7991981506347656, 맞은 개수 : 45\nEpoch : 3, batch 1306\n(Train) Batch 1306 Loss : 2.8318495750427246, 맞은 개수 : 41\nEpoch : 3, batch 1307\n(Train) Batch 1307 Loss : 3.2537178993225098, 맞은 개수 : 31\nEpoch : 3, batch 1308\n(Train) Batch 1308 Loss : 2.9634745121002197, 맞은 개수 : 40\nEpoch : 3, batch 1309\n(Train) Batch 1309 Loss : 2.9653797149658203, 맞은 개수 : 37\nEpoch : 3, batch 1310\n(Train) Batch 1310 Loss : 2.659367561340332, 맞은 개수 : 47\nEpoch : 3, batch 1311\n(Train) Batch 1311 Loss : 3.085134983062744, 맞은 개수 : 37\nEpoch : 3, batch 1312\n(Train) Batch 1312 Loss : 3.3046789169311523, 맞은 개수 : 33\nEpoch : 3, batch 1313\n(Train) Batch 1313 Loss : 3.392990827560425, 맞은 개수 : 26\nEpoch : 3, batch 1314\n(Train) Batch 1314 Loss : 2.9835903644561768, 맞은 개수 : 40\nEpoch : 3, batch 1315\n(Train) Batch 1315 Loss : 3.023592948913574, 맞은 개수 : 40\nEpoch : 3, batch 1316\n(Train) Batch 1316 Loss : 3.147228956222534, 맞은 개수 : 40\nEpoch : 3, batch 1317\n(Train) Batch 1317 Loss : 3.241307020187378, 맞은 개수 : 41\nEpoch : 3, batch 1318\n(Train) Batch 1318 Loss : 3.1260502338409424, 맞은 개수 : 31\nEpoch : 3, batch 1319\n(Train) Batch 1319 Loss : 3.1707046031951904, 맞은 개수 : 32\nEpoch : 3, batch 1320\n(Train) Batch 1320 Loss : 2.8786985874176025, 맞은 개수 : 40\nEpoch : 3, batch 1321\n(Train) Batch 1321 Loss : 2.907113552093506, 맞은 개수 : 44\nEpoch : 3, batch 1322\n(Train) Batch 1322 Loss : 2.9871633052825928, 맞은 개수 : 39\nEpoch : 3, batch 1323\n(Train) Batch 1323 Loss : 3.225562810897827, 맞은 개수 : 31\nEpoch : 3, batch 1324\n(Train) Batch 1324 Loss : 2.910553455352783, 맞은 개수 : 43\nEpoch : 3, batch 1325\n(Train) Batch 1325 Loss : 2.834627389907837, 맞은 개수 : 41\nEpoch : 3, batch 1326\n(Train) Batch 1326 Loss : 2.95709490776062, 맞은 개수 : 39\nEpoch : 3, batch 1327\n(Train) Batch 1327 Loss : 2.8479244709014893, 맞은 개수 : 41\nEpoch : 3, batch 1328\n(Train) Batch 1328 Loss : 2.881643772125244, 맞은 개수 : 44\nEpoch : 3, batch 1329\n(Train) Batch 1329 Loss : 3.2552695274353027, 맞은 개수 : 35\nEpoch : 3, batch 1330\n(Train) Batch 1330 Loss : 3.0742151737213135, 맞은 개수 : 38\nEpoch : 3, batch 1331\n(Train) Batch 1331 Loss : 2.8005762100219727, 맞은 개수 : 36\nEpoch : 3, batch 1332\n(Train) Batch 1332 Loss : 2.783320426940918, 맞은 개수 : 49\nEpoch : 3, batch 1333\n(Train) Batch 1333 Loss : 3.1008529663085938, 맞은 개수 : 31\nEpoch : 3, batch 1334\n(Train) Batch 1334 Loss : 2.8646092414855957, 맞은 개수 : 34\nEpoch : 3, batch 1335\n(Train) Batch 1335 Loss : 2.744112253189087, 맞은 개수 : 51\nEpoch : 3, batch 1336\n(Train) Batch 1336 Loss : 2.8023416996002197, 맞은 개수 : 46\nEpoch : 3, batch 1337\n(Train) Batch 1337 Loss : 2.4874777793884277, 맞은 개수 : 54\nEpoch : 3, batch 1338\n(Train) Batch 1338 Loss : 2.8937296867370605, 맞은 개수 : 40\nEpoch : 3, batch 1339\n(Train) Batch 1339 Loss : 2.733694076538086, 맞은 개수 : 47\nEpoch : 3, batch 1340\n(Train) Batch 1340 Loss : 2.730672836303711, 맞은 개수 : 40\nEpoch : 3, batch 1341\n(Train) Batch 1341 Loss : 3.003830671310425, 맞은 개수 : 39\nEpoch : 3, batch 1342\n(Train) Batch 1342 Loss : 2.9064393043518066, 맞은 개수 : 38\nEpoch : 3, batch 1343\n(Train) Batch 1343 Loss : 2.9452457427978516, 맞은 개수 : 39\nEpoch : 3, batch 1344\n(Train) Batch 1344 Loss : 2.890115976333618, 맞은 개수 : 46\nEpoch : 3, batch 1345\n(Train) Batch 1345 Loss : 2.7239625453948975, 맞은 개수 : 47\nEpoch : 3, batch 1346\n(Train) Batch 1346 Loss : 2.5833325386047363, 맞은 개수 : 52\nEpoch : 3, batch 1347\n(Train) Batch 1347 Loss : 2.8485116958618164, 맞은 개수 : 38\nEpoch : 3, batch 1348\n(Train) Batch 1348 Loss : 2.6937174797058105, 맞은 개수 : 43\nEpoch : 3, batch 1349\n(Train) Batch 1349 Loss : 2.9178130626678467, 맞은 개수 : 39\nEpoch : 3, batch 1350\n(Train) Batch 1350 Loss : 2.9200806617736816, 맞은 개수 : 41\nEpoch : 3, batch 1351\n(Train) Batch 1351 Loss : 2.855518341064453, 맞은 개수 : 40\nEpoch : 3, batch 1352\n(Train) Batch 1352 Loss : 2.9614529609680176, 맞은 개수 : 38\nEpoch : 3, batch 1353\n(Train) Batch 1353 Loss : 2.969959259033203, 맞은 개수 : 47\nEpoch : 3, batch 1354\n(Train) Batch 1354 Loss : 2.69893741607666, 맞은 개수 : 48\nEpoch : 3, batch 1355\n(Train) Batch 1355 Loss : 3.061893939971924, 맞은 개수 : 39\nEpoch : 3, batch 1356\n(Train) Batch 1356 Loss : 2.7147891521453857, 맞은 개수 : 49\nEpoch : 3, batch 1357\n(Train) Batch 1357 Loss : 3.0273120403289795, 맞은 개수 : 44\nEpoch : 3, batch 1358\n(Train) Batch 1358 Loss : 3.003650188446045, 맞은 개수 : 46\nEpoch : 3, batch 1359\n(Train) Batch 1359 Loss : 3.2708282470703125, 맞은 개수 : 30\nEpoch : 3, batch 1360\n(Train) Batch 1360 Loss : 2.8729312419891357, 맞은 개수 : 42\nEpoch : 3, batch 1361\n(Train) Batch 1361 Loss : 2.8258469104766846, 맞은 개수 : 47\nEpoch : 3, batch 1362\n(Train) Batch 1362 Loss : 3.2188079357147217, 맞은 개수 : 37\nEpoch : 3, batch 1363\n(Train) Batch 1363 Loss : 3.3858160972595215, 맞은 개수 : 28\nEpoch : 3, batch 1364\n(Train) Batch 1364 Loss : 2.6609647274017334, 맞은 개수 : 45\nEpoch : 3, batch 1365\n(Train) Batch 1365 Loss : 3.1727378368377686, 맞은 개수 : 33\nEpoch : 3, batch 1366\n(Train) Batch 1366 Loss : 2.858212471008301, 맞은 개수 : 45\nEpoch : 3, batch 1367\n(Train) Batch 1367 Loss : 3.1634438037872314, 맞은 개수 : 37\nEpoch : 3, batch 1368\n(Train) Batch 1368 Loss : 2.7461018562316895, 맞은 개수 : 37\nEpoch : 3, batch 1369\n(Train) Batch 1369 Loss : 2.9562907218933105, 맞은 개수 : 49\nEpoch : 3, batch 1370\n(Train) Batch 1370 Loss : 2.9414000511169434, 맞은 개수 : 40\nEpoch : 3, batch 1371\n(Train) Batch 1371 Loss : 2.7883639335632324, 맞은 개수 : 43\nEpoch : 3, batch 1372\n(Train) Batch 1372 Loss : 2.8443093299865723, 맞은 개수 : 45\nEpoch : 3, batch 1373\n(Train) Batch 1373 Loss : 3.3219425678253174, 맞은 개수 : 36\nEpoch : 3, batch 1374\n(Train) Batch 1374 Loss : 2.7293553352355957, 맞은 개수 : 47\nEpoch : 3, batch 1375\n(Train) Batch 1375 Loss : 2.9000184535980225, 맞은 개수 : 39\nEpoch : 3, batch 1376\n(Train) Batch 1376 Loss : 3.023923397064209, 맞은 개수 : 43\nEpoch : 3, batch 1377\n(Train) Batch 1377 Loss : 2.947111129760742, 맞은 개수 : 39\nEpoch : 3, batch 1378\n(Train) Batch 1378 Loss : 2.8602631092071533, 맞은 개수 : 45\nEpoch : 3, batch 1379\n(Train) Batch 1379 Loss : 3.1212122440338135, 맞은 개수 : 34\nEpoch : 3, batch 1380\n(Train) Batch 1380 Loss : 3.052213191986084, 맞은 개수 : 38\nEpoch : 3, batch 1381\n(Train) Batch 1381 Loss : 2.9251339435577393, 맞은 개수 : 35\nEpoch : 3, batch 1382\n(Train) Batch 1382 Loss : 3.1705939769744873, 맞은 개수 : 32\nEpoch : 3, batch 1383\n(Train) Batch 1383 Loss : 3.063416004180908, 맞은 개수 : 39\nEpoch : 3, batch 1384\n(Train) Batch 1384 Loss : 3.134767770767212, 맞은 개수 : 34\nEpoch : 3, batch 1385\n(Train) Batch 1385 Loss : 2.736341953277588, 맞은 개수 : 45\nEpoch : 3, batch 1386\n(Train) Batch 1386 Loss : 3.1178736686706543, 맞은 개수 : 34\nEpoch : 3, batch 1387\n(Train) Batch 1387 Loss : 2.8336551189422607, 맞은 개수 : 44\nEpoch : 3, batch 1388\n(Train) Batch 1388 Loss : 2.740147352218628, 맞은 개수 : 53\nEpoch : 3, batch 1389\n(Train) Batch 1389 Loss : 2.793375015258789, 맞은 개수 : 41\nEpoch : 3, batch 1390\n(Train) Batch 1390 Loss : 3.3109583854675293, 맞은 개수 : 36\nEpoch : 3, batch 1391\n(Train) Batch 1391 Loss : 2.741692543029785, 맞은 개수 : 43\nEpoch : 3, batch 1392\n(Train) Batch 1392 Loss : 2.9916322231292725, 맞은 개수 : 41\nEpoch : 3, batch 1393\n(Train) Batch 1393 Loss : 2.7222983837127686, 맞은 개수 : 44\nEpoch : 3, batch 1394\n(Train) Batch 1394 Loss : 3.1845552921295166, 맞은 개수 : 30\nEpoch : 3, batch 1395\n(Train) Batch 1395 Loss : 3.0952632427215576, 맞은 개수 : 43\nEpoch : 3, batch 1396\n(Train) Batch 1396 Loss : 2.9126338958740234, 맞은 개수 : 42\nEpoch : 3, batch 1397\n(Train) Batch 1397 Loss : 2.9393720626831055, 맞은 개수 : 41\nEpoch : 3, batch 1398\n(Train) Batch 1398 Loss : 2.9737915992736816, 맞은 개수 : 33\nEpoch : 3, batch 1399\n(Train) Batch 1399 Loss : 2.8661088943481445, 맞은 개수 : 45\nEpoch : 3, batch 1400\n(Train) Batch 1400 Loss : 3.089372158050537, 맞은 개수 : 34\nEpoch : 3, batch 1401\n(Train) Batch 1401 Loss : 3.126150608062744, 맞은 개수 : 39\nEpoch : 3, batch 1402\n(Train) Batch 1402 Loss : 2.8673954010009766, 맞은 개수 : 45\nEpoch : 3, batch 1403\n(Train) Batch 1403 Loss : 2.871507167816162, 맞은 개수 : 46\nEpoch : 3, batch 1404\n(Train) Batch 1404 Loss : 3.223438262939453, 맞은 개수 : 40\nEpoch : 3, batch 1405\n(Train) Batch 1405 Loss : 2.920429229736328, 맞은 개수 : 41\nEpoch : 3, batch 1406\n(Train) Batch 1406 Loss : 2.915168523788452, 맞은 개수 : 35\nEpoch : 3, batch 1407\n(Train) Batch 1407 Loss : 2.87969708442688, 맞은 개수 : 45\nEpoch : 3, batch 1408\n(Train) Batch 1408 Loss : 2.986778497695923, 맞은 개수 : 35\nEpoch : 3, batch 1409\n(Train) Batch 1409 Loss : 3.272113800048828, 맞은 개수 : 33\nEpoch : 3, batch 1410\n(Train) Batch 1410 Loss : 3.1390323638916016, 맞은 개수 : 34\nEpoch : 3, batch 1411\n(Train) Batch 1411 Loss : 2.5726354122161865, 맞은 개수 : 44\nEpoch : 3, batch 1412\n(Train) Batch 1412 Loss : 2.7784805297851562, 맞은 개수 : 42\nEpoch : 3, batch 1413\n(Train) Batch 1413 Loss : 2.881463050842285, 맞은 개수 : 38\nEpoch : 3, batch 1414\n(Train) Batch 1414 Loss : 2.8177177906036377, 맞은 개수 : 47\nEpoch : 3, batch 1415\n(Train) Batch 1415 Loss : 3.0847439765930176, 맞은 개수 : 34\nEpoch : 3, batch 1416\n(Train) Batch 1416 Loss : 2.92026948928833, 맞은 개수 : 42\nEpoch : 3, batch 1417\n(Train) Batch 1417 Loss : 2.840343713760376, 맞은 개수 : 40\nEpoch : 3, batch 1418\n(Train) Batch 1418 Loss : 2.9471848011016846, 맞은 개수 : 45\nEpoch : 3, batch 1419\n(Train) Batch 1419 Loss : 3.1788225173950195, 맞은 개수 : 35\nEpoch : 3, batch 1420\n(Train) Batch 1420 Loss : 2.7800774574279785, 맞은 개수 : 40\nEpoch : 3, batch 1421\n(Train) Batch 1421 Loss : 2.9347219467163086, 맞은 개수 : 41\nEpoch : 3, batch 1422\n(Train) Batch 1422 Loss : 2.927860736846924, 맞은 개수 : 45\nEpoch : 3, batch 1423\n(Train) Batch 1423 Loss : 2.8591790199279785, 맞은 개수 : 40\nEpoch : 3, batch 1424\n(Train) Batch 1424 Loss : 2.7653989791870117, 맞은 개수 : 37\nEpoch : 3, batch 1425\n(Train) Batch 1425 Loss : 2.9141271114349365, 맞은 개수 : 42\nEpoch : 3, batch 1426\n(Train) Batch 1426 Loss : 2.9000539779663086, 맞은 개수 : 43\nEpoch : 3, batch 1427\n(Train) Batch 1427 Loss : 2.8023674488067627, 맞은 개수 : 49\nEpoch : 3, batch 1428\n(Train) Batch 1428 Loss : 3.313884735107422, 맞은 개수 : 35\nEpoch : 3, batch 1429\n(Train) Batch 1429 Loss : 2.895559787750244, 맞은 개수 : 37\nEpoch : 3, batch 1430\n(Train) Batch 1430 Loss : 2.6200802326202393, 맞은 개수 : 56\nEpoch : 3, batch 1431\n(Train) Batch 1431 Loss : 2.8665359020233154, 맞은 개수 : 43\nEpoch : 3, batch 1432\n(Train) Batch 1432 Loss : 3.053476572036743, 맞은 개수 : 37\nEpoch : 3, batch 1433\n(Train) Batch 1433 Loss : 2.995857000350952, 맞은 개수 : 37\nEpoch : 3, batch 1434\n(Train) Batch 1434 Loss : 3.154167890548706, 맞은 개수 : 38\nEpoch : 3, batch 1435\n(Train) Batch 1435 Loss : 3.0956459045410156, 맞은 개수 : 35\nEpoch : 3, batch 1436\n(Train) Batch 1436 Loss : 2.7224435806274414, 맞은 개수 : 50\nEpoch : 3, batch 1437\n(Train) Batch 1437 Loss : 2.9051129817962646, 맞은 개수 : 37\nEpoch : 3, batch 1438\n(Train) Batch 1438 Loss : 2.7318503856658936, 맞은 개수 : 47\nEpoch : 3, batch 1439\n(Train) Batch 1439 Loss : 2.8481175899505615, 맞은 개수 : 45\nEpoch : 3, batch 1440\n(Train) Batch 1440 Loss : 2.8359086513519287, 맞은 개수 : 36\nEpoch : 3, batch 1441\n(Train) Batch 1441 Loss : 2.9799647331237793, 맞은 개수 : 41\nEpoch : 3, batch 1442\n(Train) Batch 1442 Loss : 2.7008678913116455, 맞은 개수 : 44\nEpoch : 3, batch 1443\n(Train) Batch 1443 Loss : 2.903979778289795, 맞은 개수 : 38\nEpoch : 3, batch 1444\n(Train) Batch 1444 Loss : 2.894266366958618, 맞은 개수 : 35\nEpoch : 3, batch 1445\n(Train) Batch 1445 Loss : 3.0442070960998535, 맞은 개수 : 44\nEpoch : 3, batch 1446\n(Train) Batch 1446 Loss : 3.2826273441314697, 맞은 개수 : 35\nEpoch : 3, batch 1447\n(Train) Batch 1447 Loss : 3.1832942962646484, 맞은 개수 : 36\nEpoch : 3, batch 1448\n(Train) Batch 1448 Loss : 2.7619540691375732, 맞은 개수 : 38\nEpoch : 3, batch 1449\n(Train) Batch 1449 Loss : 2.768942356109619, 맞은 개수 : 36\nEpoch : 3, batch 1450\n(Train) Batch 1450 Loss : 2.9248411655426025, 맞은 개수 : 39\nEpoch : 3, batch 1451\n(Train) Batch 1451 Loss : 2.9294416904449463, 맞은 개수 : 40\nEpoch : 3, batch 1452\n(Train) Batch 1452 Loss : 2.9003827571868896, 맞은 개수 : 38\nEpoch : 3, batch 1453\n(Train) Batch 1453 Loss : 2.9186699390411377, 맞은 개수 : 40\nEpoch : 3, batch 1454\n(Train) Batch 1454 Loss : 2.869703769683838, 맞은 개수 : 45\nEpoch : 3, batch 1455\n(Train) Batch 1455 Loss : 2.9918923377990723, 맞은 개수 : 37\nEpoch : 3, batch 1456\n(Train) Batch 1456 Loss : 2.958015203475952, 맞은 개수 : 36\nEpoch : 3, batch 1457\n(Train) Batch 1457 Loss : 2.79711651802063, 맞은 개수 : 39\nEpoch : 3, batch 1458\n(Train) Batch 1458 Loss : 3.1021320819854736, 맞은 개수 : 36\nEpoch : 3, batch 1459\n(Train) Batch 1459 Loss : 3.218269109725952, 맞은 개수 : 31\nEpoch : 3, batch 1460\n(Train) Batch 1460 Loss : 2.85676908493042, 맞은 개수 : 31\nEpoch : 3, batch 1461\n(Train) Batch 1461 Loss : 3.100231409072876, 맞은 개수 : 32\nEpoch : 3, batch 1462\n(Train) Batch 1462 Loss : 2.9069974422454834, 맞은 개수 : 44\nEpoch : 3, batch 1463\n(Train) Batch 1463 Loss : 2.9259982109069824, 맞은 개수 : 35\nEpoch : 3, batch 1464\n(Train) Batch 1464 Loss : 2.8710708618164062, 맞은 개수 : 43\nEpoch : 3, batch 1465\n(Train) Batch 1465 Loss : 2.985769510269165, 맞은 개수 : 38\nEpoch : 3, batch 1466\n(Train) Batch 1466 Loss : 2.9361374378204346, 맞은 개수 : 40\nEpoch : 3, batch 1467\n(Train) Batch 1467 Loss : 2.8430752754211426, 맞은 개수 : 45\nEpoch : 3, batch 1468\n(Train) Batch 1468 Loss : 2.8019537925720215, 맞은 개수 : 43\nEpoch : 3, batch 1469\n(Train) Batch 1469 Loss : 2.8880436420440674, 맞은 개수 : 45\nEpoch : 3, batch 1470\n(Train) Batch 1470 Loss : 2.8025426864624023, 맞은 개수 : 46\nEpoch : 3, batch 1471\n(Train) Batch 1471 Loss : 3.0086443424224854, 맞은 개수 : 46\nEpoch : 3, batch 1472\n(Train) Batch 1472 Loss : 2.752556562423706, 맞은 개수 : 35\nEpoch : 3, batch 1473\n(Train) Batch 1473 Loss : 3.1684703826904297, 맞은 개수 : 35\nEpoch : 3, batch 1474\n(Train) Batch 1474 Loss : 2.4998068809509277, 맞은 개수 : 56\nEpoch : 3, batch 1475\n(Train) Batch 1475 Loss : 3.179663896560669, 맞은 개수 : 39\nEpoch : 3, batch 1476\n(Train) Batch 1476 Loss : 3.2514450550079346, 맞은 개수 : 36\nEpoch : 3, batch 1477\n(Train) Batch 1477 Loss : 2.8008906841278076, 맞은 개수 : 50\nEpoch : 3, batch 1478\n(Train) Batch 1478 Loss : 2.782581329345703, 맞은 개수 : 50\nEpoch : 3, batch 1479\n(Train) Batch 1479 Loss : 2.490954637527466, 맞은 개수 : 49\nEpoch : 3, batch 1480\n(Train) Batch 1480 Loss : 2.757859945297241, 맞은 개수 : 48\nEpoch : 3, batch 1481\n(Train) Batch 1481 Loss : 2.8689966201782227, 맞은 개수 : 40\nEpoch : 3, batch 1482\n(Train) Batch 1482 Loss : 2.8484292030334473, 맞은 개수 : 45\nEpoch : 3, batch 1483\n(Train) Batch 1483 Loss : 3.0492677688598633, 맞은 개수 : 40\nEpoch : 3, batch 1484\n(Train) Batch 1484 Loss : 3.0668110847473145, 맞은 개수 : 37\nEpoch : 3, batch 1485\n(Train) Batch 1485 Loss : 2.90187931060791, 맞은 개수 : 44\nEpoch : 3, batch 1486\n(Train) Batch 1486 Loss : 2.9512972831726074, 맞은 개수 : 35\nEpoch : 3, batch 1487\n(Train) Batch 1487 Loss : 3.0478062629699707, 맞은 개수 : 40\nEpoch : 3, batch 1488\n(Train) Batch 1488 Loss : 3.2063305377960205, 맞은 개수 : 35\nEpoch : 3, batch 1489\n(Train) Batch 1489 Loss : 2.964263439178467, 맞은 개수 : 44\nEpoch : 3, batch 1490\n(Train) Batch 1490 Loss : 2.893826723098755, 맞은 개수 : 37\nEpoch : 3, batch 1491\n(Train) Batch 1491 Loss : 2.735950469970703, 맞은 개수 : 44\nEpoch : 3, batch 1492\n(Train) Batch 1492 Loss : 3.111492872238159, 맞은 개수 : 36\nEpoch : 3, batch 1493\n(Train) Batch 1493 Loss : 2.8790595531463623, 맞은 개수 : 39\nEpoch : 3, batch 1494\n(Train) Batch 1494 Loss : 2.9897964000701904, 맞은 개수 : 43\nEpoch : 3, batch 1495\n(Train) Batch 1495 Loss : 2.861272096633911, 맞은 개수 : 44\nEpoch : 3, batch 1496\n(Train) Batch 1496 Loss : 3.301764726638794, 맞은 개수 : 34\nEpoch : 3, batch 1497\n(Train) Batch 1497 Loss : 3.0736536979675293, 맞은 개수 : 39\nEpoch : 3, batch 1498\n(Train) Batch 1498 Loss : 2.9902305603027344, 맞은 개수 : 44\nEpoch : 3, batch 1499\n(Train) Batch 1499 Loss : 2.862147569656372, 맞은 개수 : 46\nEpoch : 3, batch 1500\n(Train) Batch 1500 Loss : 3.0116255283355713, 맞은 개수 : 41\nEpoch : 3, batch 1501\n(Train) Batch 1501 Loss : 3.187685012817383, 맞은 개수 : 35\nEpoch : 3, batch 1502\n(Train) Batch 1502 Loss : 3.348392963409424, 맞은 개수 : 32\nEpoch : 3, batch 1503\n(Train) Batch 1503 Loss : 3.009204626083374, 맞은 개수 : 41\nEpoch : 3, batch 1504\n(Train) Batch 1504 Loss : 2.8601462841033936, 맞은 개수 : 48\nEpoch : 3, batch 1505\n(Train) Batch 1505 Loss : 3.0384998321533203, 맞은 개수 : 37\nEpoch : 3, batch 1506\n(Train) Batch 1506 Loss : 2.8583688735961914, 맞은 개수 : 39\nEpoch : 3, batch 1507\n(Train) Batch 1507 Loss : 2.9134340286254883, 맞은 개수 : 39\nEpoch : 3, batch 1508\n(Train) Batch 1508 Loss : 3.0529167652130127, 맞은 개수 : 38\nEpoch : 3, batch 1509\n(Train) Batch 1509 Loss : 2.8184726238250732, 맞은 개수 : 38\nEpoch : 3, batch 1510\n(Train) Batch 1510 Loss : 2.951841354370117, 맞은 개수 : 36\nEpoch : 3, batch 1511\n(Train) Batch 1511 Loss : 3.2648768424987793, 맞은 개수 : 29\nEpoch : 3, batch 1512\n(Train) Batch 1512 Loss : 3.05248761177063, 맞은 개수 : 32\nEpoch : 3, batch 1513\n(Train) Batch 1513 Loss : 3.0297112464904785, 맞은 개수 : 36\nEpoch : 3, batch 1514\n(Train) Batch 1514 Loss : 2.9842119216918945, 맞은 개수 : 39\nEpoch : 3, batch 1515\n(Train) Batch 1515 Loss : 3.232935905456543, 맞은 개수 : 33\nEpoch : 3, batch 1516\n(Train) Batch 1516 Loss : 2.967118978500366, 맞은 개수 : 43\nEpoch : 3, batch 1517\n(Train) Batch 1517 Loss : 3.036919355392456, 맞은 개수 : 35\nEpoch : 3, batch 1518\n(Train) Batch 1518 Loss : 2.8931734561920166, 맞은 개수 : 47\nEpoch : 3, batch 1519\n(Train) Batch 1519 Loss : 3.0692572593688965, 맞은 개수 : 39\nEpoch : 3, batch 1520\n(Train) Batch 1520 Loss : 2.6143834590911865, 맞은 개수 : 51\nEpoch : 3, batch 1521\n(Train) Batch 1521 Loss : 2.4968197345733643, 맞은 개수 : 57\nEpoch : 3, batch 1522\n(Train) Batch 1522 Loss : 2.5695242881774902, 맞은 개수 : 56\nEpoch : 3, batch 1523\n(Train) Batch 1523 Loss : 2.712797164916992, 맞은 개수 : 40\nEpoch : 3, batch 1524\n(Train) Batch 1524 Loss : 2.87903094291687, 맞은 개수 : 46\nEpoch : 3, batch 1525\n(Train) Batch 1525 Loss : 2.9590530395507812, 맞은 개수 : 39\nEpoch : 3, batch 1526\n(Train) Batch 1526 Loss : 3.0149130821228027, 맞은 개수 : 42\nEpoch : 3, batch 1527\n(Train) Batch 1527 Loss : 2.979539155960083, 맞은 개수 : 36\nEpoch : 3, batch 1528\n(Train) Batch 1528 Loss : 3.067056894302368, 맞은 개수 : 40\nEpoch : 3, batch 1529\n(Train) Batch 1529 Loss : 2.8713886737823486, 맞은 개수 : 44\nEpoch : 3, batch 1530\n(Train) Batch 1530 Loss : 3.3128247261047363, 맞은 개수 : 34\nEpoch : 3, batch 1531\n(Train) Batch 1531 Loss : 2.7432966232299805, 맞은 개수 : 48\nEpoch : 3, batch 1532\n(Train) Batch 1532 Loss : 3.070169687271118, 맞은 개수 : 30\nEpoch : 3, batch 1533\n(Train) Batch 1533 Loss : 2.8188228607177734, 맞은 개수 : 36\nEpoch : 3, batch 1534\n(Train) Batch 1534 Loss : 3.002283811569214, 맞은 개수 : 35\nEpoch : 3, batch 1535\n(Train) Batch 1535 Loss : 2.9647552967071533, 맞은 개수 : 37\nEpoch : 3, batch 1536\n(Train) Batch 1536 Loss : 3.003140926361084, 맞은 개수 : 41\nEpoch : 3, batch 1537\n(Train) Batch 1537 Loss : 2.985416889190674, 맞은 개수 : 38\nEpoch : 3, batch 1538\n(Train) Batch 1538 Loss : 2.854454278945923, 맞은 개수 : 38\nEpoch : 3, batch 1539\n(Train) Batch 1539 Loss : 2.881535053253174, 맞은 개수 : 45\nEpoch : 3, batch 1540\n(Train) Batch 1540 Loss : 2.8533241748809814, 맞은 개수 : 43\nEpoch : 3, batch 1541\n(Train) Batch 1541 Loss : 2.999307870864868, 맞은 개수 : 39\nEpoch : 3, batch 1542\n(Train) Batch 1542 Loss : 2.549777030944824, 맞은 개수 : 49\nEpoch : 3, batch 1543\n(Train) Batch 1543 Loss : 2.666240692138672, 맞은 개수 : 56\nEpoch : 3, batch 1544\n(Train) Batch 1544 Loss : 3.0615997314453125, 맞은 개수 : 40\nEpoch : 3, batch 1545\n(Train) Batch 1545 Loss : 2.9605979919433594, 맞은 개수 : 43\nEpoch : 3, batch 1546\n(Train) Batch 1546 Loss : 2.977710008621216, 맞은 개수 : 40\nEpoch : 3, batch 1547\n(Train) Batch 1547 Loss : 3.015777349472046, 맞은 개수 : 41\nEpoch : 3, batch 1548\n(Train) Batch 1548 Loss : 2.9619297981262207, 맞은 개수 : 40\nEpoch : 3, batch 1549\n(Train) Batch 1549 Loss : 2.8739869594573975, 맞은 개수 : 51\nEpoch : 3, batch 1550\n(Train) Batch 1550 Loss : 2.8171751499176025, 맞은 개수 : 45\nEpoch : 3, batch 1551\n(Train) Batch 1551 Loss : 3.0923187732696533, 맞은 개수 : 37\nEpoch : 3, batch 1552\n(Train) Batch 1552 Loss : 2.837164878845215, 맞은 개수 : 46\nEpoch : 3, batch 1553\n(Train) Batch 1553 Loss : 3.0308423042297363, 맞은 개수 : 42\nEpoch : 3, batch 1554\n(Train) Batch 1554 Loss : 2.876476526260376, 맞은 개수 : 44\nEpoch : 3, batch 1555\n(Train) Batch 1555 Loss : 2.7629902362823486, 맞은 개수 : 37\nEpoch : 3, batch 1556\n(Train) Batch 1556 Loss : 3.2763681411743164, 맞은 개수 : 31\nEpoch : 3, batch 1557\n(Train) Batch 1557 Loss : 2.8761115074157715, 맞은 개수 : 39\nEpoch : 3, batch 1558\n(Train) Batch 1558 Loss : 2.5461339950561523, 맞은 개수 : 53\nEpoch : 3, batch 1559\n(Train) Batch 1559 Loss : 2.9050800800323486, 맞은 개수 : 39\nEpoch : 3, batch 1560\n(Train) Batch 1560 Loss : 2.613431453704834, 맞은 개수 : 50\nEpoch : 3, batch 1561\n(Train) Batch 1561 Loss : 3.0061702728271484, 맞은 개수 : 36\nEpoch : 3, batch 1562\n(Train) Batch 1562 Loss : 2.9826064109802246, 맞은 개수 : 20\nepoch 3 Loss/Train :3.030884069886943 \nepoch 3 Accuracy/Train : 0.298725\nVAL : 예측라벨 : [  0   0   0   0   0   0 148   0   0   0   0  18 180   0  13  45  45   0\n 183 149  76  36  73 192  13   0   0   0 180 186   0   0], 정답 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n(VAL) Batch 0 Loss : 2.0473756790161133, accuracy: 0.53125\nVAL : 예측라벨 : [  0   0   0 196  69 180 180   0   0  47   0   0  45   0   0  47  42  36\n   9   1  16   1  42   1  10  19   1   1 139   1   1 118], 정답 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n(VAL) Batch 1 Loss : 2.1681315898895264, accuracy: 0.5\nVAL : 예측라벨 : [174   2   1  15   1 199  20  81 197 118   1   1 113  37  10   1  19   1\n  10   1   8 152   1   1  12   1   1   2   1 126   1   1], 정답 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n(VAL) Batch 2 Loss : 2.360682964324951, accuracy: 0.4375\nVAL : 예측라벨 : [  1 118   1  19  16   2   2   2 162 199   1   2  42  14  31   2   2 183\n 199  12 194   2   4   6   2   2 173  15   2   2   2   3], 정답 [1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n(VAL) Batch 3 Loss : 2.3470094203948975, accuracy: 0.4375\nVAL : 예측라벨 : [ 93   2   2  16   2   2   5 129   2   2  46  42   2 183  14  85   2  42\n  34   6   2   2 185  46 185  24   5 191   5  52   3   2], 정답 [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3]\n(VAL) Batch 4 Loss : 2.695683240890503, accuracy: 0.34375\nVAL : 예측라벨 : [183  93   2  12 192  30  40  89  10  35 192 178  30   2   6  61   6   2\n  89   2  46   6 190   7 185 199   2  90   3 191   2   7], 정답 [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n(VAL) Batch 5 Loss : 3.3753867149353027, accuracy: 0.03125\nVAL : 예측라벨 : [  3   3  93 199   0  39  16  15  52  81  10   4   2   4 197   4   2   4\n  42   4  33 162   2 196  40  69   4  96 129   4   2   4], 정답 [3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n(VAL) Batch 6 Loss : 3.1706690788269043, accuracy: 0.3125\nVAL : 예측라벨 : [ 56  14   4   4  23   2 174 154   4   2 152   4  10   4  10   4  72 134\n  19 182  78 140   4   4   4   4  46   4 150 104  77   3], 정답 [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5]\n(VAL) Batch 7 Loss : 3.0932576656341553, accuracy: 0.3125\nVAL : 예측라벨 : [136  93  10  57  12  26   5   6  46 126 154 123  12  46 100  32 105  52\n  35 118 144  32   3  35  50  48   7  53  10 152   2  36], 정답 [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n(VAL) Batch 8 Loss : 4.472317695617676, accuracy: 0.03125\nVAL : 예측라벨 : [ 28   7  52   4  19 102  41 111  89 105  35   2 195   6 149   4   6   6\n   6   6   6   6 162  14   6   6   6   6 178 105 169  52], 정답 [5 5 5 5 5 5 5 5 5 5 5 5 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n(VAL) Batch 9 Loss : 3.0209403038024902, accuracy: 0.34375\nVAL : 예측라벨 : [  6  46   6   6   6   6 174   6   6   6   6  31 117   6   6   8  26  19\n 192 119 183   6   6 170  66  46  32   6  21   6 122   3], 정답 [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 7 7]\n(VAL) Batch 10 Loss : 2.4347591400146484, accuracy: 0.46875\nVAL : 예측라벨 : [  7  91   7  10 181   9   7   9  14   6 169  91  13   7   3   8 104  10\n   7   3  17   9 177   4   6  41  52 152 154   8  10 183], 정답 [7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n(VAL) Batch 11 Loss : 3.423410415649414, accuracy: 0.15625\nVAL : 예측라벨 : [  9   7 181  10   9  52  58   6  14 125   7  42  13  10  52   7   8  36\n  44   8  37   9   8   8   8   8   8  10 135   7 119 125], 정답 [7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n(VAL) Batch 12 Loss : 2.607496500015259, accuracy: 0.3125\nVAL : 예측라벨 : [  8   8   8   8   8   1  55   9 161   8   8 132  53   8   8  37   8   8\n   8  37   8  11   8   8  38   8   8 139   8   9  37   8], 정답 [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n(VAL) Batch 13 Loss : 1.8932677507400513, accuracy: 0.59375\nVAL : 예측라벨 : [  8  10  32  96  53   9   9 119  37   9   2  19  39 106 177 197   7  19\n   6   3   5   6   9  17  10   9   5   8  21   9   9   9], 정답 [8 8 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n(VAL) Batch 14 Loss : 3.3429172039031982, accuracy: 0.28125\nVAL : 예측라벨 : [ 37   9  33  66   8 138   9  46   7   9  34  34  33   9   9 129   9  18\n   7   9  36 152  52 166 118  40  19   8  10  10 109   1], 정답 [ 9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9 10 10 10 10\n 10 10 10 10 10 10 10 10]\n(VAL) Batch 15 Loss : 3.5220043659210205, accuracy: 0.28125\nVAL : 예측라벨 : [162 177  10   7  91  36  10  36 181  10 117  46  42  40  10 179  10 152\n  10  52   7  19 139  10  30  10 177  52  42 111  91  10], 정답 [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n 10 10 10 10 10 10 10 10]\n(VAL) Batch 16 Loss : 3.306234359741211, accuracy: 0.28125\nVAL : 예측라벨 : [ 10  99 139  10   1  12  20  11  87  48  96  20  11  57  38 151  78  51\n  11  22   6  52  21  11   5  11 102  20  56  11  21  21], 정답 [10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n 11 11 11 11 11 11 11 11]\n(VAL) Batch 17 Loss : 3.183774948120117, accuracy: 0.25\nVAL : 예측라벨 : [195  11  22 118  52  11  35  11 139  11  78  11  76  37  52 139  11  84\n  84 144  11  71  69  15  12  12  12  12  27  12  12  12], 정답 [11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n 12 12 12 12 12 12 12 12]\n(VAL) Batch 18 Loss : 2.808314085006714, accuracy: 0.4375\nVAL : 예측라벨 : [ 31  19  53  12  12  12 143  12  12  12  12 105  12  71  12 118  47  54\n  12  12 105  12  12  52  57 183  24  85  12  12  12  57], 정답 [12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n 12 12 12 12 12 12 12 12]\n(VAL) Batch 19 Loss : 2.387209892272949, accuracy: 0.5\nVAL : 예측라벨 : [ 12  30  35  12 105  33 105  12 136 121  13  46  13 134  23  13  13  13\n  23 196 104 183  13  23  13  12  13  13  13  13  13  85], 정답 [12 12 12 12 12 12 12 12 12 12 13 13 13 13 13 13 13 13 13 13 13 13 13 13\n 13 13 13 13 13 13 13 13]\n(VAL) Batch 20 Loss : 2.2575418949127197, accuracy: 0.46875\nVAL : 예측라벨 : [ 13  13  13  13  13  13  13  13  92  23  13 183  23  13  13  13  13  13\n  48 148  13  13  13  23  13  13  13  13  88  14  14  14], 정답 [13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13\n 13 13 13 13 14 14 14 14]\n(VAL) Batch 21 Loss : 1.268017292022705, accuracy: 0.75\nVAL : 예측라벨 : [ 14  46  14 196  14  34 196 196  14  14 183 183 194  61  14 196  14 183\n  14  62 183  19  14  14 183  23  14  14 196  14  30 183], 정답 [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n 14 14 14 14 14 14 14 14]\n(VAL) Batch 22 Loss : 2.142892360687256, accuracy: 0.40625\nVAL : 예측라벨 : [183   6  76  14  14  14  14  46  14  14  14  14 196  14 183 117 192  42\n  92  15  16 185 107  15 156  99  35 199  22  23   6  81], 정답 [14 14 14 14 14 14 14 14 14 14 14 14 14 14 15 15 15 15 15 15 15 15 15 15\n 15 15 15 15 15 15 15 15]\n(VAL) Batch 23 Loss : 2.931025266647339, accuracy: 0.34375\nVAL : 예측라벨 : [ 41  93 192  32  39   7   6 105  12  33  13 185   3  80  15 157   4  15\n 156   6  15   2  37   7 185   4  36  56  41  17 183  36], 정답 [15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n 15 15 15 15 15 15 15 15]\n(VAL) Batch 24 Loss : 3.9623184204101562, accuracy: 0.09375\nVAL : 예측라벨 : [  4  52   2   8  10  16  76 152  37  17 176  80  62 183 178  16 192  12\n  28  32  17  36   0  39 192  15  10  58 163  16  16 180], 정답 [16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16\n 16 16 16 16 16 16 16 16]\n(VAL) Batch 25 Loss : 3.66351318359375, accuracy: 0.125\nVAL : 예측라벨 : [  4   2 185 174   2  40  12  15   3 122  15 197  22 185  55  17   4  13\n  17  17  17  46  33  31  17  61  17  17  17  19  17  17], 정답 [16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 17 17 17 17 17 17\n 17 17 17 17 17 17 17 17]\n(VAL) Batch 26 Loss : 3.1222939491271973, accuracy: 0.28125\nVAL : 예측라벨 : [ 46  17  17  17 182 176  17  29 190 182  17  85 185  19 185  17  17  17\n 190  17 182  17  71  17  18 134  14 183  59  17  62  17], 정답 [17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17\n 17 17 17 17 17 17 17 17]\n(VAL) Batch 27 Loss : 2.622368574142456, accuracy: 0.40625\nVAL : 예측라벨 : [ 17  17  46  17 189 191 181  18 106  18  82 163 107 150 191 181  25  45\n 189 180 186 189  93  18 158  18 189 190 189 189 106 177], 정답 [17 17 17 17 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18\n 18 18 18 18 18 18 18 18]\n(VAL) Batch 28 Loss : 3.051020622253418, accuracy: 0.21875\nVAL : 예측라벨 : [191 115   5 189  14  24 189  18  18  82 153  77 190  18 180  18 104 163\n 112  18 150 150  19  91  19  19   6 161  19  10  48  19], 정답 [18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 19 19\n 19 19 19 19 19 19 19 19]\n(VAL) Batch 29 Loss : 2.8664655685424805, accuracy: 0.3125\nVAL : 예측라벨 : [  9  19  93 196   2 191  19  19  19 191  10 176  19  19  91  14  17  19\n  19   9  19 195  19  46  19  19  62 182  19 134  41 196], 정답 [19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19\n 19 19 19 19 19 19 19 19]\n(VAL) Batch 30 Loss : 2.451307535171509, accuracy: 0.40625\nVAL : 예측라벨 : [ 19 105  19  19  19  94  19  19 183  20 199  12  20 122 144  20  58  52\n  20  29  22 117  20  11  46  55  55  20 157 155 170  20], 정답 [19 19 19 19 19 19 19 19 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20\n 20 20 20 20 20 20 20 20]\n(VAL) Batch 31 Loss : 2.9330999851226807, accuracy: 0.40625\nVAL : 예측라벨 : [ 56 143  22  95 148  43  75  20  50 170  20  21   8  20  20 106  20  35\n  16  52   8  29  37  84  42  20 171  15  21  23  77  21], 정답 [20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20\n 20 20 21 21 21 21 21 21]\n(VAL) Batch 32 Loss : 3.296294689178467, accuracy: 0.25\nVAL : 예측라벨 : [ 42 128  21 198  23  21 170 187 131  21  21 106  21  21 105  21  77  23\n  60  21  55  21 105  21  21  21  21  21  21  21 154  21], 정답 [21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21 21\n 21 21 21 21 21 21 21 21]\n(VAL) Batch 33 Loss : 2.549150228500366, accuracy: 0.53125\nVAL : 예측라벨 : [ 43  60  40  21 141 100 122  21  21  21  91  21  33  22  52  21  22  23\n  22  22  22 197  22  22  22  22  22 100 122  22  22  22], 정답 [21 21 21 21 21 21 21 21 21 21 21 21 22 22 22 22 22 22 22 22 22 22 22 22\n 22 22 22 22 22 22 22 22]\n(VAL) Batch 34 Loss : 2.354555606842041, accuracy: 0.5625\nVAL : 예측라벨 : [ 22  96  22  22  22  75 101  21 100   8  22  40  22 156 156   2 101  22\n  22  22  46  22  56  42  11  22  22  11  22  22  23  23], 정답 [22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22\n 22 22 22 22 22 22 23 23]\n(VAL) Batch 35 Loss : 2.1043312549591064, accuracy: 0.5\nVAL : 예측라벨 : [ 23  23  23  22  23  23 194  23  23  23  31  23  13 148  23  23  23 196\n  23  23  23  23  23  23  23  23  23  23  55  22  22  21], 정답 [23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23\n 23 23 23 23 23 23 23 23]\n(VAL) Batch 36 Loss : 1.1374592781066895, accuracy: 0.6875\nVAL : 예측라벨 : [ 23  23  22  13  48  23  13  23  23  23 194 196  23  23  23  23  48  26\n  30  27  31 100  32  31 100  90  29 106  60 125 123 163], 정답 [23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 23 24 24 24 24 24 24 24 24\n 24 24 24 24 24 24 24 24]\n(VAL) Batch 37 Loss : 2.601996660232544, accuracy: 0.3125\nVAL : 예측라벨 : [ 47  10  54  31 111  24  24  31  31  90  24  28 181  31  29 156  52  26\n  60  28  48  69 105  28  25  20 127  68  21  27  56  18], 정답 [24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24 24\n 24 24 24 24 24 24 24 24]\n(VAL) Batch 38 Loss : 4.152841091156006, accuracy: 0.09375\nVAL : 예측라벨 : [ 24  96  28  63  25  25  19  48  25  56  26 161 182  93  25 105  26 105\n  25  25  31 182  25  25  52  25  35  35 144  34  56  30], 정답 [24 24 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25\n 25 25 25 25 25 25 25 25]\n(VAL) Batch 39 Loss : 3.0554702281951904, accuracy: 0.3125\nVAL : 예측라벨 : [ 76  18  58  25 161  33  26  48  17  25  30  90  25  31  28  24 119  53\n  26 150  34  34  26  26  52  25  26 190  26  96  34 144], 정답 [25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 26 26 26 26\n 26 26 26 26 26 26 26 26]\n(VAL) Batch 40 Loss : 3.087475538253784, accuracy: 0.21875\nVAL : 예측라벨 : [ 14  27  52  41  53  53  26  31  25  25  53  12  53  26  25 148  46 142\n  26  31 183  12  26  29 144  26 144  19 105  52  33 100], 정답 [26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26\n 26 26 26 26 26 26 26 26]\n(VAL) Batch 41 Loss : 3.4570744037628174, accuracy: 0.15625\nVAL : 예측라벨 : [144  56  26  27  52  52 106  29  53 106  24  56  50 144  74  52 144 106\n  29  85 105  35  55  26 122  20  52  24  29  27  25 147], 정답 [26 26 26 26 26 26 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27\n 27 27 27 27 27 27 27 27]\n(VAL) Batch 42 Loss : 3.5499911308288574, accuracy: 0.0625\nVAL : 예측라벨 : [114  20  52 106  55  12  22 152  26  55 183  55  52  57  30  56 114  26\n  75  52  26  27  26  57 105  58  75  53  33  25  71  28], 정답 [27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27\n 28 28 28 28 28 28 28 28]\n(VAL) Batch 43 Loss : 3.5315380096435547, accuracy: 0.0625\nVAL : 예측라벨 : [ 28  28 105 191  20 118  27  28  60  52 143  11 114 105 118 114  37  28\n  25 107 176  28  52 147 180  28  24  53  56  34   7  56], 정답 [28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28\n 28 28 28 28 28 28 28 28]\n(VAL) Batch 44 Loss : 3.8468058109283447, accuracy: 0.1875\nVAL : 예측라벨 : [ 28  26  57  28  28  53  25  28  52  33 125 120  17  63  52  29 105  11\n 157  11   3 107  91 105 140  55  26 185  20  27  29  58], 정답 [28 28 28 28 28 28 28 28 28 28 29 29 29 29 29 29 29 29 29 29 29 29 29 29\n 29 29 29 29 29 29 29 29]\n(VAL) Batch 45 Loss : 3.2333409786224365, accuracy: 0.1875\nVAL : 예측라벨 : [ 11  27  43  55  20  50 156 139  53  29  26  12 127 106  22  57  54  13\n  31  53  35 118  56  29  26  30  34  52 195  91   5   6], 정답 [29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29\n 29 29 29 29 30 30 30 30]\n(VAL) Batch 46 Loss : 3.455444812774658, accuracy: 0.0625\nVAL : 예측라벨 : [144  51  24  30 150 106  32  60 160  30  30  31  29  30   9 189  33  62\n  32  32  30  32 150 144  52 169 119  31  32  32  32 151], 정답 [30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n 30 30 30 30 30 30 30 30]\n(VAL) Batch 47 Loss : 3.599151372909546, accuracy: 0.15625\nVAL : 예측라벨 : [149  98  34  12   5  32 144  12  53   3  32  32 190   6 141  31  25  32\n  31   6  40  31 105  31  31 144 105  47  31 123  80 195], 정답 [30 30 30 30 30 30 30 30 30 30 30 30 30 30 31 31 31 31 31 31 31 31 31 31\n 31 31 31 31 31 31 31 31]\n(VAL) Batch 48 Loss : 3.4613187313079834, accuracy: 0.1875\nVAL : 예측라벨 : [105  29  34  31  31  32  31  13  31   9  31 119  31  25  25  31  31 150\n  31  31 185  31  31  31  29 161  31  24 174  31  31  29], 정답 [31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31\n 31 31 31 31 31 31 31 31]\n(VAL) Batch 49 Loss : 2.593571186065674, accuracy: 0.5\nVAL : 예측라벨 : [125  32 105  10  40 147  90 102 147  98 101  29 100  30 141  32 105   8\n  11 144  32   4 165  41  52  96  33  12  32  33  32  52], 정답 [32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32\n 32 32 32 32 32 32 32 32]\n(VAL) Batch 50 Loss : 3.8343725204467773, accuracy: 0.15625\nVAL : 예측라벨 : [105 106 169  32  58 125 106 105 161  62  32 120  30  22  32  32 131  31\n  69  34  52  12  53  33  33  57  11  34  33 105  53  32], 정답 [32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 33 33 33 33 33 33\n 33 33 33 33 33 33 33 33]\n(VAL) Batch 51 Loss : 3.318974733352661, accuracy: 0.21875\nVAL : 예측라벨 : [ 12  33  26  91  52  12  91  53  52  32 183   9 183  33  91  53  51  33\n  33  31  52  19  33 162  51  32  52  32  96  52  52 162], 정답 [33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33\n 33 33 33 33 33 33 33 33]\n(VAL) Batch 52 Loss : 3.0112264156341553, accuracy: 0.15625\nVAL : 예측라벨 : [ 56  57  33  33  33  34  31  34  52  52 183  34  34  23  53  14  57  50\n  34  52  34  52  34  35  34  34  37  34  57  34  29  32], 정답 [33 33 33 33 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n 34 34 34 34 34 34 34 34]\n(VAL) Batch 53 Loss : 2.5639495849609375, accuracy: 0.40625\nVAL : 예측라벨 : [ 34  34  35  34  34  34  34  34  34  31  52  34  17 162  91   6 183  30\n  29  34  33  34  35  35  25 153  15  35  56  52  35  76], 정답 [34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 35 35\n 35 35 35 35 35 35 35 35]\n(VAL) Batch 54 Loss : 2.6414685249328613, accuracy: 0.46875\nVAL : 예측라벨 : [ 55 185  35  35  52  35  35  20  26   6  35  35  52  50  48  35  35  35\n  35  35  35  31 107  35  35 162  35  35 185   6  56  31], 정답 [35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35\n 35 35 35 35 35 35 35 35]\n(VAL) Batch 55 Loss : 2.2605247497558594, accuracy: 0.5\nVAL : 예측라벨 : [ 35  50  58 105  48  35  34  35  36  36  36  36  36  36  36  44  36  36\n 188  38  17  36  36  61 199  36  41  36  43  36  36  36], 정답 [35 35 35 35 35 35 35 35 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n 36 36 36 36 36 36 36 36]\n(VAL) Batch 56 Loss : 1.5563405752182007, accuracy: 0.59375\nVAL : 예측라벨 : [168  36  36  37  77  36  36 118  36  36  36  38  59 183 199  73  36  36\n  38  36  69  36  11  38  36  58 106  10   8   1  37   9], 정답 [36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n 36 36 37 37 37 37 37 37]\n(VAL) Batch 57 Loss : 2.751251220703125, accuracy: 0.40625\nVAL : 예측라벨 : [ 42 192  37  37   9  37  36  37  37 199 199  37  38  38  37  71   8 117\n  37  36   8 180   8   4  37  45 115  38  25  37  44  37], 정답 [37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37\n 37 37 37 37 37 37 37 37]\n(VAL) Batch 58 Loss : 2.643019676208496, accuracy: 0.34375\nVAL : 예측라벨 : [ 39   8 199  15  37  42  37 179   9  41  37  10 196  36  38  38  38  15\n  36   7   2  38  38  75  38  38  38  38  38 182  37  38], 정답 [37 37 37 37 37 37 37 37 37 37 37 37 38 38 38 38 38 38 38 38 38 38 38 38\n 38 38 38 38 38 38 38 38]\n(VAL) Batch 59 Loss : 2.4119303226470947, accuracy: 0.4375\nVAL : 예측라벨 : [ 17  38  36  32  38  38  43  38  36  38  44  38  38  38  48  37  38  38\n  38  38 169  38  45  44  38  38  52  44  45  42  37  37], 정답 [38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n 38 38 38 38 38 38 39 39]\n(VAL) Batch 60 Loss : 2.669374942779541, accuracy: 0.46875\nVAL : 예측라벨 : [ 39 149  44 179   2  42 198  39  39  42  44   2 178  39 122  37  42 186\n   5  40  40  40  38 199  42   2   2  42  42  42  42  43], 정답 [39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39\n 39 39 39 39 39 39 39 39]\n(VAL) Batch 61 Loss : 3.2553255558013916, accuracy: 0.125\nVAL : 예측라벨 : [117  42  39  15  61  40  39  39  42  37  39 122 184 105  42  42  42  42\n  89  45  39  74  83  42 199  19  40  23   2  40 184  40], 정답 [39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 39 40 40 40 40 40 40 40 40\n 40 40 40 40 40 40 40 40]\n(VAL) Batch 62 Loss : 2.936413526535034, accuracy: 0.21875\nVAL : 예측라벨 : [ 24 122 199  85 180   2 156 157  42   8 173 109 186  69  43 199  75 169\n  48  40  95  42  52  40  40  42  36 184 152  54 183 118], 정답 [40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40\n 40 40 40 40 40 40 40 40]\n(VAL) Batch 63 Loss : 3.620178461074829, accuracy: 0.09375\nVAL : 예측라벨 : [129 185   8  43   8  10   8 159   3  41 111 115 162  61 190  10  79   7\n  15 105  41  25  37   8 182  37  41   8 101 107  41  41], 정답 [40 40 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41\n 41 41 41 41 41 41 41 41]\n(VAL) Batch 64 Loss : 3.4983372688293457, accuracy: 0.15625\nVAL : 예측라벨 : [182  37 167   9   8 182  92  44  41   8  37  89 144  10  42  41  10  54\n   2  75  36  42  42   3 188 139  15 171  45 183  15  42], 정답 [41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 42 42 42 42\n 42 42 42 42 42 42 42 42]\n(VAL) Batch 65 Loss : 3.516753673553467, accuracy: 0.15625\nVAL : 예측라벨 : [ 40  42  42 171 178  90 144 131  55 178 129  42  42 199  40  24  52  42\n   2  42 144  42  40  42 125  52 144 184  26  42  42  37], 정답 [42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42 42\n 42 42 42 42 42 42 42 42]\n(VAL) Batch 66 Loss : 2.6708035469055176, accuracy: 0.3125\nVAL : 예측라벨 : [122 117   8  42  28 183  42  38  43  39 118   2 105  43  37   8  43  37\n  10  44  42  62  43  43  36  37  13  36 144 127  14  15], 정답 [42 42 42 42 42 42 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43\n 43 43 43 43 43 43 43 43]\n(VAL) Batch 67 Loss : 3.1480815410614014, accuracy: 0.1875\nVAL : 예측라벨 : [ 40   2  42  43 184   2 184  43  43  36  43  43 199  44 163 113 152  42\n 199 199  40  43  39  10  44  44  44 152  44  37  44  44], 정답 [43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43\n 44 44 44 44 44 44 44 44]\n(VAL) Batch 68 Loss : 2.4828805923461914, accuracy: 0.375\nVAL : 예측라벨 : [ 44  19  90  44  44  45  44  44  44  44  44  95  44  44  44 190 181  44\n  44  44  37 199  44  44  44  44   2 199  93  44 126  44], 정답 [44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44 44\n 44 44 44 44 44 44 44 44]\n(VAL) Batch 69 Loss : 1.6724563837051392, accuracy: 0.625\nVAL : 예측라벨 : [ 44  44 106  44  44  44 101  44  44  19 183  45 188  52  45 199  45 184\n  45 178  45  45 187  45  45  45  45  45 187  45  61  44], 정답 [44 44 44 44 44 44 44 44 44 44 45 45 45 45 45 45 45 45 45 45 45 45 45 45\n 45 45 45 45 45 45 45 45]\n(VAL) Batch 70 Loss : 1.5155874490737915, accuracy: 0.59375\nVAL : 예측라벨 : [179  45 187 187  45  36  45  45  45  45  45  45  45 176 161  45  45  45\n   2  45  44  45  45  45 199  45  45 183  14 148  14  14], 정답 [45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45 45\n 45 45 45 45 46 46 46 46]\n(VAL) Batch 71 Loss : 1.6055258512496948, accuracy: 0.5625\nVAL : 예측라벨 : [ 46 190   2  46  50   4  46  46 174  42 154  46  46  46  46  30  46 134\n 196  46  14  39  46  14   2  48  46  46  14  55  46  46], 정답 [46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46\n 46 46 46 46 46 46 46 46]\n(VAL) Batch 72 Loss : 2.532966375350952, accuracy: 0.46875\nVAL : 예측라벨 : [196   6  46  55 144  14   4  46  18  14   2 183  19  46  31  31  29  58\n  47  32  47 183  47  46  32  47  47  56  47  48  33  34], 정답 [46 46 46 46 46 46 46 46 46 46 46 46 46 46 47 47 47 47 47 47 47 47 47 47\n 47 47 47 47 47 47 47 47]\n(VAL) Batch 73 Loss : 2.8500101566314697, accuracy: 0.28125\nVAL : 예측라벨 : [136   7 180 134   6  30 177  60 190  53  47 193  48  32 177 181  31  24\n  30  31  29 192  47   6   6  47  47 129  31  52  99  24], 정답 [47 47 47 47 47 47 47 47 47 47 47 47 47 47 47 47 47 47 47 47 47 47 47 47\n 47 47 47 47 47 47 47 47]\n(VAL) Batch 74 Loss : 3.7747373580932617, accuracy: 0.125\nVAL : 예측라벨 : [ 48 114  48  14  74  55 151 158  35 119 162  52  31  56  50 180 162  54\n 164  46  31  50  48  48  55 162 162  57  52  48 176  13], 정답 [48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48\n 48 48 48 48 48 48 48 48]\n(VAL) Batch 75 Loss : 3.4995110034942627, accuracy: 0.15625\nVAL : 예측라벨 : [150  48 144  48  94  48  48  48  48  57   4  51  98  48  57  51 162   6\n  56  52 162  55  55 118 152  50 102 171  22  74  52 155], 정답 [48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 49 49 49 49 49 49\n 49 49 49 49 49 49 49 49]\n(VAL) Batch 76 Loss : 3.8330109119415283, accuracy: 0.21875\nVAL : 예측라벨 : [ 49  57  49 119  50  49  57 119  35  53  49  53  53 111  85 105  50 165\n  26  50  55  34 111 105  51  66  75  52 145  55  56  23], 정답 [49 49 49 49 49 49 49 49 49 49 49 49 49 49 49 49 49 49 49 49 49 49 49 49\n 49 49 49 49 49 49 49 49]\n(VAL) Batch 77 Loss : 3.8070602416992188, accuracy: 0.125\nVAL : 예측라벨 : [ 12  48 140  49  50  50  52  50  50  53 154  85  56  56 143  50  85  57\n  35  50  85  50  50   6  50  50  50  54  50  50  48  28], 정답 [49 49 49 49 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50\n 50 50 50 50 50 50 50 50]\n(VAL) Batch 78 Loss : 2.196437120437622, accuracy: 0.4375\nVAL : 예측라벨 : [ 57  66 195  50  57  57  50  35  50  32  57  50 170  57  52  50  50  26\n  57  53  27  50  53  33  48  33  56  51 156 170 161  53], 정답 [50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 51 51\n 51 51 51 51 51 51 51 51]\n(VAL) Batch 79 Loss : 2.5538265705108643, accuracy: 0.25\nVAL : 예측라벨 : [ 12  84  32  14  57  84  56  52  21  56 162  91  48  35  75  34  33   9\n 194  26 111 132 134  57  52  20   6  34   2  33  57  51], 정답 [51 51 51 51 51 51 51 51 51 51 51 51 51 51 51 51 51 51 51 51 51 51 51 51\n 51 51 51 51 51 51 51 51]\n(VAL) Batch 80 Loss : 3.67435622215271, accuracy: 0.03125\nVAL : 예측라벨 : [162  56  50 148  51  33  51  91 136 170  52  47  52  24  24  46  28  52\n  52  52  52  52  29  52  52  52  52  52 113  52  52  57], 정답 [51 51 51 51 51 51 51 51 52 52 52 52 52 52 52 52 52 52 52 52 52 52 52 52\n 52 52 52 52 52 52 52 52]\n(VAL) Batch 81 Loss : 2.134531021118164, accuracy: 0.5\nVAL : 예측라벨 : [ 53  76  52  52  52  52 105  52  52  52  52  74  52  52 198  52   8 173\n  52  52 185  52  52  52 118  52  33  52  52  28  57 171], 정답 [52 52 52 52 52 52 52 52 52 52 52 52 52 52 52 52 52 52 52 52 52 52 52 52\n 52 52 53 53 53 53 53 53]\n(VAL) Batch 82 Loss : 2.217825174331665, accuracy: 0.53125\nVAL : 예측라벨 : [ 53 170 165  53 165  29 143  53 158  57 171  57 137  33  53  52 101  52\n  53  10 195  33 143  60  53  53  53  53  53  57 163  75], 정답 [53 53 53 53 53 53 53 53 53 53 53 53 53 53 53 53 53 53 53 53 53 53 53 53\n 53 53 53 53 53 53 53 53]\n(VAL) Batch 83 Loss : 2.7648749351501465, accuracy: 0.3125\nVAL : 예측라벨 : [105  52  53 107  57  53  53  53 105  53  53  26  46  12  34  62  54  35\n  54  33  54   9  56  46  54  33  55  12  82  34  54  54], 정답 [53 53 53 53 53 53 53 53 53 53 53 53 54 54 54 54 54 54 54 54 54 54 54 54\n 54 54 54 54 54 54 54 54]\n(VAL) Batch 84 Loss : 2.532064199447632, accuracy: 0.375\nVAL : 예측라벨 : [ 54  42  26  23  65  56  76  52  75  54  54  58  25  52  56 105  56  55\n  75  56  81  95  48  54  25  50  55  48  12  54  55  55], 정답 [54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54\n 54 54 54 54 54 54 55 55]\n(VAL) Batch 85 Loss : 3.7706611156463623, accuracy: 0.21875\nVAL : 예측라벨 : [ 55  55  55  55 114  55  32  56  55  55  55  99  12   3  12  56  55  55\n 127  20  30  55  55  55  55 162  55 106  60  55  12 105], 정답 [55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55\n 55 55 55 55 55 55 55 55]\n(VAL) Batch 86 Loss : 2.5834691524505615, accuracy: 0.5\nVAL : 예측라벨 : [ 55 167  54  55  55 140 183  55  55 107 122  55 121  55  55  55  34  55\n  55 106 198  53  56  56  81  56  31  56  12  52  22  56], 정답 [55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 55 56 56 56 56 56 56 56 56\n 56 56 56 56 56 56 56 56]\n(VAL) Batch 87 Loss : 3.150876760482788, accuracy: 0.4375\nVAL : 예측라벨 : [ 55  12   9  56  23  93  31  56 199  48  53   6  16 157  52  48  52  55\n  36  12  57   2  56 132  56  34  56   3   2  52  56  34], 정답 [56 56 56 56 56 56 56 56 56 56 56 56 56 56 56 56 56 56 56 56 56 56 56 56\n 56 56 56 56 56 56 56 56]\n(VAL) Batch 88 Loss : 3.099989414215088, accuracy: 0.1875\nVAL : 예측라벨 : [ 56 102  96  91  57  57   4  50 170  63  50  57  53  57  85  56  57 108\n  57 162  57  57  57 102 169  57  57  57 144  57  53  57], 정답 [56 56 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57\n 57 57 57 57 57 57 57 57]\n(VAL) Batch 89 Loss : 2.3580973148345947, accuracy: 0.46875\nVAL : 예측라벨 : [ 57  52  57  57  57   6  52  57  57 129  57  49  35  52  57  57  57  57\n  66  57 111  24  58  35  58  58  75  67  58  19  58  58], 정답 [57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 57 58 58 58 58\n 58 58 58 58 58 58 58 58]\n(VAL) Batch 90 Loss : 2.0427393913269043, accuracy: 0.5625\nVAL : 예측라벨 : [ 58 119  55  58  58  49  58 144  58  58 162  60 105  98  58  24  50  58\n  12  55  50  58  58  58  58  58 190  58  48  58 181  11], 정답 [58 58 58 58 58 58 58 58 58 58 58 58 58 58 58 58 58 58 58 58 58 58 58 58\n 58 58 58 58 58 58 58 58]\n(VAL) Batch 91 Loss : 2.595046043395996, accuracy: 0.46875\nVAL : 예측라벨 : [ 58  46  58  58  58  58 146 126  59  76 179 176 176 148  93  90 106  73\n 144 164 184  90 180 169  18 154 105  59 147   9  59 188], 정답 [58 58 58 58 58 58 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59\n 59 59 59 59 59 59 59 59]\n(VAL) Batch 92 Loss : 3.4188833236694336, accuracy: 0.25\nVAL : 예측라벨 : [150 171 169 191 156  62  36  68 147  78  73  62  62  96  59  64 132  59\n  59  98  70 144 126  93  60  60  63  60 167  60  60 120], 정답 [59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59\n 60 60 60 60 60 60 60 60]\n(VAL) Batch 93 Loss : 3.965088367462158, accuracy: 0.25\nVAL : 예측라벨 : [106  60  60  29 118 150  60  60  60 106  60  60  60  63 156 144  60  60\n 100  60 141  60  60  60  60  60 106  60 123  60 105 105], 정답 [60 60 60 60 60 60 60 60 60 60 60 60 60 60 60 60 60 60 60 60 60 60 60 60\n 60 60 60 60 60 60 60 60]\n(VAL) Batch 94 Loss : 2.265711784362793, accuracy: 0.5625\nVAL : 예측라벨 : [ 63  65  60  60  60 119 156  60 106  60  61 152 142  61  61  61  61  61\n 158  82 129  61  61  61 126 128  61  61  61 176  61  78], 정답 [60 60 60 60 60 60 60 60 60 60 61 61 61 61 61 61 61 61 61 61 61 61 61 61\n 61 61 61 61 61 61 61 61]\n(VAL) Batch 95 Loss : 2.0986571311950684, accuracy: 0.5625\nVAL : 예측라벨 : [142 169  61  65  93  78 126  61  61 126  61  61 129  61  61  61 142 176\n 146  61  61 102  61 126 126  61  61  61  90  17  62 169], 정답 [61 61 61 61 61 61 61 61 61 61 61 61 61 61 61 61 61 61 61 61 61 61 61 61\n 61 61 61 61 62 62 62 62]\n(VAL) Batch 96 Loss : 1.9310688972473145, accuracy: 0.46875\nVAL : 예측라벨 : [134  59  90  12  90  62 109  24  73  62 134  62  62  62  85  90 142 134\n  63 169 135  62  90  62  62 112  62  62  62  62 134  90], 정답 [62 62 62 62 62 62 62 62 62 62 62 62 62 62 62 62 62 62 62 62 62 62 62 62\n 62 62 62 62 62 62 62 62]\n(VAL) Batch 97 Loss : 2.5168328285217285, accuracy: 0.375\nVAL : 예측라벨 : [ 62 129 134  74 120  62  12 144  85  62 169 134  63 173  63 100  63  89\n 173 111  63  90 158 153 120  63 134 107  63  87  28  90], 정답 [62 62 62 62 62 62 62 62 62 62 62 62 62 62 63 63 63 63 63 63 63 63 63 63\n 63 63 63 63 63 63 63 63]\n(VAL) Batch 98 Loss : 2.870518445968628, accuracy: 0.25\nVAL : 예측라벨 : [134 134  62 127 169  60 179  60 190 119  60  29  78  63  63  63 161  60\n 127  57  63  89 168 170 127 143 169 105 121 173  89 142], 정답 [63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63 63\n 63 63 63 63 63 63 63 63]\n(VAL) Batch 99 Loss : 3.3872506618499756, accuracy: 0.125\nVAL : 예측라벨 : [ 74 142  40 129 169 136 129  98  89 169 134 106 140 102  81 173  72 129\n 100 194  38  21   6  89  82 125  31  64 126 136  96  67], 정답 [64 64 64 64 64 64 64 64 64 64 64 64 64 64 64 64 64 64 64 64 64 64 64 64\n 64 64 64 64 64 64 64 64]\n(VAL) Batch 100 Loss : 4.5029730796813965, accuracy: 0.03125\nVAL : 예측라벨 : [ 42  21 111  42 160  87 167  95  20 176 185 140  77 150  61 121 118  74\n  65  61  60  82  82  18  78 119 111 105 128 169 119  65], 정답 [64 64 64 64 64 64 64 64 64 64 64 64 64 64 64 64 64 64 65 65 65 65 65 65\n 65 65 65 65 65 65 65 65]\n(VAL) Batch 101 Loss : 4.653968811035156, accuracy: 0.0625\nVAL : 예측라벨 : [ 65 108 150 134  97 167 176  86  87  73 167 105 119 147 111 156 190  84\n 140 167  65  60  98  65 136  62 112 167  28 129  65  65], 정답 [65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65\n 65 65 65 65 65 65 65 65]\n(VAL) Batch 102 Loss : 3.7178964614868164, accuracy: 0.15625\nVAL : 예측라벨 : [128 123 146 119 170  66  66 156 171  53 144 154 164 115 116 170 146  66\n  53  66 158 118  66 152  66   4 170 162 162  91 170 170], 정답 [65 65 65 65 66 66 66 66 66 66 66 66 66 66 66 66 66 66 66 66 66 66 66 66\n 66 66 66 66 66 66 66 66]\n(VAL) Batch 103 Loss : 3.3493831157684326, accuracy: 0.1875\nVAL : 예측라벨 : [ 66 165  44 162 170 152 104  98 128  66 157  66  87 165 194 170 165 178\n 164  66  70 170  13  85 154  89 162  33 105 198  75 153], 정답 [66 66 66 66 66 66 66 66 66 66 66 66 66 66 66 66 66 66 66 66 66 66 67 67\n 67 67 67 67 67 67 67 67]\n(VAL) Batch 104 Loss : 3.21355938911438, accuracy: 0.125\nVAL : 예측라벨 : [127  67 105  89 172  62 112  67 165  32 162 107  77  67 129  91  13 105\n 142 114  89 134 140 154 102  67   6  63  87 153 167  12], 정답 [67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67 67\n 67 67 67 67 67 67 67 67]\n(VAL) Batch 105 Loss : 4.068583011627197, accuracy: 0.125\nVAL : 예측라벨 : [106 146  83 140 161  85  92 176 163  68  19  68 156  61 169 143  97 128\n 171 171  68 171  68 163 112 147  68 171  68 118  31 189], 정답 [67 67 67 67 67 67 67 67 68 68 68 68 68 68 68 68 68 68 68 68 68 68 68 68\n 68 68 68 68 68 68 68 68]\n(VAL) Batch 106 Loss : 3.3256096839904785, accuracy: 0.1875\nVAL : 예측라벨 : [ 60  77  82  61 143 112 112  68 105 171  68 113  68 171 171  68  98 119\n 143 129  68  89 143  68 163  93  69  69  69  29  69 144], 정답 [68 68 68 68 68 68 68 68 68 68 68 68 68 68 68 68 68 68 68 68 68 68 68 68\n 68 68 69 69 69 69 69 69]\n(VAL) Batch 107 Loss : 3.0512490272521973, accuracy: 0.3125\nVAL : 예측라벨 : [ 92  69 120 142  26  94 163 144 141  69 180  69  42 144 100 120 100  29\n  79 148 132  98  69  86  69 119  18 140 122 144  83 144], 정답 [69 69 69 69 69 69 69 69 69 69 69 69 69 69 69 69 69 69 69 69 69 69 69 69\n 69 69 69 69 69 69 69 69]\n(VAL) Batch 108 Loss : 3.921560764312744, accuracy: 0.15625\nVAL : 예측라벨 : [159  72  98  94  91  85  69  69  71 124  23  31  70 194  70 153  70 133\n  63  70  70 116 162  70  94  70  70  87  70 116 145 116], 정답 [69 69 69 69 69 69 69 69 69 69 69 69 70 70 70 70 70 70 70 70 70 70 70 70\n 70 70 70 70 70 70 70 70]\n(VAL) Batch 109 Loss : 3.133099317550659, accuracy: 0.34375\nVAL : 예측라벨 : [ 94 154  70 153 166  94  70  94 133  94  70  70 153 153  94  94 162  94\n 144  82 116 154  81 166  95 140  87  98  94  94  71  71], 정답 [70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70\n 70 70 70 70 70 70 71 71]\n(VAL) Batch 110 Loss : 2.8139030933380127, accuracy: 0.1875\nVAL : 예측라벨 : [106 170 140  71  71  71  71 101  95 118  71  71 124  71 132 101  95  71\n 157  71 124  71 124 173  71  71  71 157 173  71 124  71], 정답 [71 71 71 71 71 71 71 71 71 71 71 71 71 71 71 71 71 71 71 71 71 71 71 71\n 71 71 71 71 71 71 71 71]\n(VAL) Batch 111 Loss : 2.0201008319854736, accuracy: 0.46875\nVAL : 예측라벨 : [ 71  95 197 195  71  71  71 124 101 198  66 124  71  22  71 154  72  72\n  91 183  72  72  90  72 144 184  90 125 182 180 123 127], 정답 [71 71 71 71 71 71 71 71 71 71 71 71 71 71 71 71 72 72 72 72 72 72 72 72\n 72 72 72 72 72 72 72 72]\n(VAL) Batch 112 Loss : 3.386235237121582, accuracy: 0.34375\nVAL : 예측라벨 : [ 40  90 180 169 149  63  72  72 109 183  72 128 141  72  72 109  28  72\n 151 175  98  31  90 108 163 138 186  72 151 151  89 172], 정답 [72 72 72 72 72 72 72 72 72 72 72 72 72 72 72 72 72 72 72 72 72 72 72 72\n 72 72 72 72 72 72 72 72]\n(VAL) Batch 113 Loss : 3.348158836364746, accuracy: 0.21875\nVAL : 예측라벨 : [127  90 112 131  73 101  62 106  73  62  73 135 163 135  73  90  73 180\n  73  53  63 111  76 184 178 138 169 120 135   8  73  98], 정답 [72 72 73 73 73 73 73 73 73 73 73 73 73 73 73 73 73 73 73 73 73 73 73 73\n 73 73 73 73 73 73 73 73]\n(VAL) Batch 114 Loss : 3.5661284923553467, accuracy: 0.21875\nVAL : 예측라벨 : [ 73 142  60  62  13  52  82  73  73  73 155  90 179 112  73  73  76 129\n  32  73  60  74 158 158 156  52 106 158  74  25 179  74], 정답 [73 73 73 73 73 73 73 73 73 73 73 73 73 73 73 73 73 73 73 73 74 74 74 74\n 74 74 74 74 74 74 74 74]\n(VAL) Batch 115 Loss : 3.2044496536254883, accuracy: 0.3125\nVAL : 예측라벨 : [180 109 198  53  60 148  54 171  74 105 171  74 158  12 125  74 120 158\n  74 156 158 120  74  18 142  74  68  74  74  74 124 198], 정답 [74 74 74 74 74 74 74 74 74 74 74 74 74 74 74 74 74 74 74 74 74 74 74 74\n 74 74 74 74 74 74 74 74]\n(VAL) Batch 116 Loss : 2.7738196849823, accuracy: 0.28125\nVAL : 예측라벨 : [ 74  74 156  12  69 180 170 100  75  70 105  75 169 160 119 124 137 106\n 119  60 170 163  31 129 156 156 153 121  75 154  75 155], 정답 [74 74 74 74 74 74 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75\n 75 75 75 75 75 75 75 75]\n(VAL) Batch 117 Loss : 3.4169538021087646, accuracy: 0.1875\nVAL : 예측라벨 : [177   2  75 198 139  73  61  76 156   2  63  75  77  24  42  60 154  64\n 170 132 170 154  61 180 176 162  14  29  76 137  58 135], 정답 [75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75\n 76 76 76 76 76 76 76 76]\n(VAL) Batch 118 Loss : 3.9792613983154297, accuracy: 0.09375\nVAL : 예측라벨 : [173 129  98  90  91 163 120  61  12 173  52 121 151  53  74 118  76  76\n 149  76  29  16 128  29   4 132 129 114 162 106   2 121], 정답 [76 76 76 76 76 76 76 76 76 76 76 76 76 76 76 76 76 76 76 76 76 76 76 76\n 76 76 76 76 76 76 76 76]\n(VAL) Batch 119 Loss : 3.898383855819702, accuracy: 0.09375\nVAL : 예측라벨 : [165  54 102  18  85 195 169 111  76 173 179  60  86  60 128  60 123 169\n 131  24  60  63 106 172 106  29  75 123  22 106 111 169], 정답 [76 76 76 76 76 76 76 76 76 76 77 77 77 77 77 77 77 77 77 77 77 77 77 77\n 77 77 77 77 77 77 77 77]\n(VAL) Batch 120 Loss : 3.7494699954986572, accuracy: 0.03125\nVAL : 예측라벨 : [110 112 189   7  28  60 119 156  77  77 150  90  63  77  85 169 156 180\n 169 151  62 129 174 158 181 132 144 156  78  12  78  78], 정답 [77 77 77 77 77 77 77 77 77 77 77 77 77 77 77 77 77 77 77 77 77 77 77 77\n 77 77 77 77 78 78 78 78]\n(VAL) Batch 121 Loss : 3.842338800430298, accuracy: 0.1875\nVAL : 예측라벨 : [ 78  78 162  78  78 167  85  78  78  78  78 155  78  85 157  78  78  78\n  78   6  78  78  78  80  78  85  78  78  78  78  78  78], 정답 [78 78 78 78 78 78 78 78 78 78 78 78 78 78 78 78 78 78 78 78 78 78 78 78\n 78 78 78 78 78 78 78 78]\n(VAL) Batch 122 Loss : 1.863061547279358, accuracy: 0.71875\nVAL : 예측라벨 : [ 78 165 155  85  78  78  78  86  78  78 104  78  78  78   1 122 138  79\n  62   2 138 168 130 120 139 118  36  63 107 115  79   8], 정답 [78 78 78 78 78 78 78 78 78 78 78 78 78 78 79 79 79 79 79 79 79 79 79 79\n 79 79 79 79 79 79 79 79]\n(VAL) Batch 123 Loss : 3.045536756515503, accuracy: 0.34375\nVAL : 예측라벨 : [  1 100 151  79 134  33  79 124 100 157 157  82   6 134   0 190 129 122\n  90 162  40 122  64  21 190  79 132  27  79 113  90  79], 정답 [79 79 79 79 79 79 79 79 79 79 79 79 79 79 79 79 79 79 79 79 79 79 79 79\n 79 79 79 79 79 79 79 79]\n(VAL) Batch 124 Loss : 3.85510516166687, accuracy: 0.15625\nVAL : 예측라벨 : [ 62 156  63  86  72  31  65  89 122 153  80 136  90 106  82  76  71  36\n 180 110 190 135  22 136  79  23  89 157 121 137 163 194], 정답 [80 80 80 80 80 80 80 80 80 80 80 80 80 80 80 80 80 80 80 80 80 80 80 80\n 80 80 80 80 80 80 80 80]\n(VAL) Batch 125 Loss : 4.57781457901001, accuracy: 0.03125\nVAL : 예측라벨 : [140 179 134 122  52 167  62  80  17  69  89 160  76 183  73  55 160 149\n  81  98  81  81 121 136  81 133  81  81  81  81  81 119], 정답 [80 80 80 80 80 80 80 80 80 80 80 80 80 80 80 80 80 80 81 81 81 81 81 81\n 81 81 81 81 81 81 81 81]\n(VAL) Batch 126 Loss : 3.3584694862365723, accuracy: 0.3125\nVAL : 예측라벨 : [ 81 194  81  81 141  81 120  23  81  81  81  81  81 185  81  81  81  81\n  81  81  75  81  81 129 108 121 134 120  81  81  81  81], 정답 [81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81\n 81 81 81 81 81 81 81 81]\n(VAL) Batch 127 Loss : 2.1153953075408936, accuracy: 0.65625\nVAL : 예측라벨 : [ 81  81  81 142 189 181 134  82  82  82  93 181  82  93  82  93 169  62\n 108 191  98  82 115  91  82 140 124 142 169  82  82  82], 정답 [81 81 81 81 82 82 82 82 82 82 82 82 82 82 82 82 82 82 82 82 82 82 82 82\n 82 82 82 82 82 82 82 82]\n(VAL) Batch 128 Loss : 2.5327048301696777, accuracy: 0.40625\nVAL : 예측라벨 : [ 82 146 103  82  61 111  93 191 105  82 120  93  82 123 142  93 189  82\n  93  82 192  82  98  90  18  32 174 160  71  62 186  90], 정답 [82 82 82 82 82 82 82 82 82 82 82 82 82 82 82 82 82 82 82 82 82 82 83 83\n 83 83 83 83 83 83 83 83]\n(VAL) Batch 129 Loss : 3.593877077102661, accuracy: 0.21875\nVAL : 예측라벨 : [149 119 144  93 158  83  73  74 128 113 136  18 123 180 123  99  83 191\n 186 156 180  83 104  24  83  89 161  83 124 187  62 163], 정답 [83 83 83 83 83 83 83 83 83 83 83 83 83 83 83 83 83 83 83 83 83 83 83 83\n 83 83 83 83 83 83 83 83]\n(VAL) Batch 130 Loss : 4.0858588218688965, accuracy: 0.15625\nVAL : 예측라벨 : [ 83 131 142 123   0  83  93  34 147  84  84  27 101 129 119  84 194 157\n 118  75  66   4  84  52  63 157  84 113 137  81  96 117], 정답 [83 83 83 83 83 83 83 83 84 84 84 84 84 84 84 84 84 84 84 84 84 84 84 84\n 84 84 84 84 84 84 84 84]\n(VAL) Batch 131 Loss : 4.012938499450684, accuracy: 0.21875\nVAL : 예측라벨 : [ 84  12 194  84  50 111 108 102  84   5 146   5 119  98 157  32 170  21\n  55  84  84 170 158  52 171 144  82 150   6 105  85 123], 정답 [84 84 84 84 84 84 84 84 84 84 84 84 84 84 84 84 84 84 84 84 84 84 84 84\n 84 84 85 85 85 85 85 85]\n(VAL) Batch 132 Loss : 3.6788177490234375, accuracy: 0.1875\nVAL : 예측라벨 : [ 85 105 134 118 144  85  85 105  85  90   6  63 169  60  85  63  85  85\n 134  62 158  85 104 105  90  85 134  85 105 129  62  85], 정답 [85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85\n 85 85 85 85 85 85 85 85]\n(VAL) Batch 133 Loss : 2.418865442276001, accuracy: 0.34375\nVAL : 예측라벨 : [105 119  85  85  85 134 120  63  85  85  85 162  86  86  24  63  87 128\n  90  86  86 129  86   8 140  60 140  90 106  60 110 146], 정답 [85 85 85 85 85 85 85 85 85 85 85 85 86 86 86 86 86 86 86 86 86 86 86 86\n 86 86 86 86 86 86 86 86]\n(VAL) Batch 134 Loss : 3.1494979858398438, accuracy: 0.34375\nVAL : 예측라벨 : [ 87 147 128 127  86 142 117  86 167 110  60 121 128 140  73  63  78 142\n 128 128  86  86  86 128  86  80 100 120  72  86  97 147], 정답 [86 86 86 86 86 86 86 86 86 86 86 86 86 86 86 86 86 86 86 86 86 86 86 86\n 86 86 86 86 86 86 87 87]\n(VAL) Batch 135 Loss : 3.065627336502075, accuracy: 0.21875\nVAL : 예측라벨 : [ 87   8 146  60  87 102 142  63  87 106  90 146  87 139  97  87 151 146\n  89  87 154  84  87 106 101  87  87  92  97 106  70 174], 정답 [87 87 87 87 87 87 87 87 87 87 87 87 87 87 87 87 87 87 87 87 87 87 87 87\n 87 87 87 87 87 87 87 87]\n(VAL) Batch 136 Loss : 3.288597345352173, accuracy: 0.28125\nVAL : 예측라벨 : [150 153  87  87 131  89  92 155 146  63 167  87  87  63  98 146  42 148\n 140  78  70 123 174 140 143 119 104  37  31 163   9 173], 정답 [87 87 87 87 87 87 87 87 87 87 87 87 87 87 87 87 88 88 88 88 88 88 88 88\n 88 88 88 88 88 88 88 88]\n(VAL) Batch 137 Loss : 3.861802816390991, accuracy: 0.125\nVAL : 예측라벨 : [ 19   5 183  99 105 193 140 111  25  14  10  82 144 101  82 144 141   8\n  72 146 146 163 132  63 157 103 120  19 122  22 125 115], 정답 [88 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88 88\n 88 88 88 88 88 88 88 88]\n(VAL) Batch 138 Loss : 4.571132659912109, accuracy: 0.0\nVAL : 예측라벨 : [144  32  89  89 183  89  89  89  98 171  89 104 151 147  78  53  61  89\n  13 100  52  89  85   6 140 110  89 123   6  89 162  91], 정답 [88 88 89 89 89 89 89 89 89 89 89 89 89 89 89 89 89 89 89 89 89 89 89 89\n 89 89 89 89 89 89 89 89]\n(VAL) Batch 139 Loss : 3.4450531005859375, accuracy: 0.3125\nVAL : 예측라벨 : [ 89  52 139  89  89 144 167 193  89  89  93   6   4  89  86  89  89  89\n 152 161 171  60  18  90 186  90  62  90  90  90  90 112], 정답 [89 89 89 89 89 89 89 89 89 89 89 89 89 89 89 89 89 89 89 89 90 90 90 90\n 90 90 90 90 90 90 90 90]\n(VAL) Batch 140 Loss : 2.4213459491729736, accuracy: 0.46875\nVAL : 예측라벨 : [ 90  90  90  62  90 149 112 128  90 163 134 149  90  90 134 190   6  90\n 134  90  90  90  62  68  24  90 169 169  90  18  90  62], 정답 [90 90 90 90 90 90 90 90 90 90 90 90 90 90 90 90 90 90 90 90 90 90 90 90\n 90 90 90 90 90 90 90 90]\n(VAL) Batch 141 Loss : 2.2537708282470703, accuracy: 0.4375\nVAL : 예측라벨 : [ 90  90  41  90 163 149 185  91  91  91   8  91  96  91  91 195  30  34\n  70  96  91  91  56 183 165  91  91  14 119  91  61  91], 정답 [90 90 90 90 90 90 91 91 91 91 91 91 91 91 91 91 91 91 91 91 91 91 91 91\n 91 91 91 91 91 91 91 91]\n(VAL) Batch 142 Loss : 2.496894121170044, accuracy: 0.46875\nVAL : 예측라벨 : [165  91  91  91 162  53  91  57  91 119  91  91  91  78  56  14  91  91\n  34  91  53 169   6  91 136  99  87 147  24 104  99  97], 정답 [91 91 91 91 91 91 91 91 91 91 91 91 91 91 91 91 91 91 91 91 91 91 91 91\n 92 92 92 92 92 92 92 92]\n(VAL) Batch 143 Loss : 2.9576542377471924, accuracy: 0.375\nVAL : 예측라벨 : [182 145   4  21 110 167  87 184  67  96  99  70 128 147 160  86  45  61\n  16   5  52  81 147 198  92  58 134  31  74  40  98 188], 정답 [92 92 92 92 92 92 92 92 92 92 92 92 92 92 92 92 92 92 92 92 92 92 92 92\n 92 92 92 92 92 92 92 92]\n(VAL) Batch 144 Loss : 4.810606956481934, accuracy: 0.03125\nVAL : 예측라벨 : [116 173 102 157 171 103 127 139  92 152  62 134  93 191  93  93  82 196\n  93  82  93  93  93 146  93 176  93  93   6  93  93 171], 정답 [92 92 92 92 92 92 92 92 92 92 93 93 93 93 93 93 93 93 93 93 93 93 93 93\n 93 93 93 93 93 93 93 93]\n(VAL) Batch 145 Loss : 2.589181661605835, accuracy: 0.40625\nVAL : 예측라벨 : [ 65 134  93  93 114  93 184  93  93 176  90 163  93  93  93 150  25 191\n  61 146  52  19  93  93  30  93  93  93  70  70 160 198], 정답 [93 93 93 93 93 93 93 93 93 93 93 93 93 93 93 93 93 93 93 93 93 93 93 93\n 93 93 93 93 94 94 94 94]\n(VAL) Batch 146 Loss : 2.550173759460449, accuracy: 0.40625\nVAL : 예측라벨 : [ 94  94  94 153 121  70  70  94 153  94  94  94  70  70  94 145  94  94\n  94 166  94 153  70  70  94 116 133  70  70  94  70  94], 정답 [94 94 94 94 94 94 94 94 94 94 94 94 94 94 94 94 94 94 94 94 94 94 94 94\n 94 94 94 94 94 94 94 94]\n(VAL) Batch 147 Loss : 1.6178772449493408, accuracy: 0.46875\nVAL : 예측라벨 : [180  87  94 116 162 147  87 140 153  70  70  94 153 153 157  95  95 116\n  66 113  95  95 141  11  95 132  95 173  95  71  40 142], 정답 [94 94 94 94 94 94 94 94 94 94 94 94 94 94 95 95 95 95 95 95 95 95 95 95\n 95 95 95 95 95 95 95 95]\n(VAL) Batch 148 Loss : 2.9439857006073, accuracy: 0.28125\nVAL : 예측라벨 : [122 124 154 132  71  71 118 101  95  95 132  71 165 132 149 154 145 194\n 132 166 124 100  95  95 147 154 112 146 103  95 113 154], 정답 [95 95 95 95 95 95 95 95 95 95 95 95 95 95 95 95 95 95 95 95 95 95 95 95\n 95 95 95 95 95 95 95 95]\n(VAL) Batch 149 Loss : 3.1272785663604736, accuracy: 0.15625\nVAL : 예측라벨 : [ 58  78 108  96  96  96 197 170 154  22  96  62  96 195 158 157 198  75\n 102 157 198 194 170 162 198  96  55 165  96  12  84  32], 정답 [96 96 96 96 96 96 96 96 96 96 96 96 96 96 96 96 96 96 96 96 96 96 96 96\n 96 96 96 96 96 96 96 96]\n(VAL) Batch 150 Loss : 2.8440957069396973, accuracy: 0.21875\nVAL : 예측라벨 : [162 167 195 197  41  29 198 170 198 154  96  96 156  96  96  84 154  96\n 113  97 171 118  87  98  52 136 146 121 142  69 121 140], 정답 [96 96 96 96 96 96 96 96 96 96 96 96 96 96 96 96 96 96 97 97 97 97 97 97\n 97 97 97 97 97 97 97 97]\n(VAL) Batch 151 Loss : 3.6212122440338135, accuracy: 0.1875\nVAL : 예측라벨 : [166 145  89 157 121  97  62 140  80  98  97 147 136 155  89  97  97  93\n  89 140 181  98  55   2  89 100  97  97  98 144  97 100], 정답 [97 97 97 97 97 97 97 97 97 97 97 97 97 97 97 97 97 97 97 97 97 97 97 97\n 97 97 97 97 97 97 97 97]\n(VAL) Batch 152 Loss : 3.220198154449463, accuracy: 0.21875\nVAL : 예측라벨 : [146 147 136  98  61  12  94  98  98 183  98  98  98  98 157  98 106  63\n  89  98 192  48  98 128 147  98  97 142 167 146  98  98], 정답 [97 97 97 97 98 98 98 98 98 98 98 98 98 98 98 98 98 98 98 98 98 98 98 98\n 98 98 98 98 98 98 98 98]\n(VAL) Batch 153 Loss : 3.3023533821105957, accuracy: 0.375\nVAL : 예측라벨 : [ 84  97  98  98 171  98 142 142  98 142 103 111 126  98 147  61  98 100\n  89  89  98  98  58  99 167  55 142 161 116  40   2 123], 정답 [98 98 98 98 98 98 98 98 98 98 98 98 98 98 98 98 98 98 98 98 98 98 99 99\n 99 99 99 99 99 99 99 99]\n(VAL) Batch 154 Loss : 3.051771640777588, accuracy: 0.28125\nVAL : 예측라벨 : [147  60  40 119 163  82 156 125 113 168 100  93 122 156  60 124 146  87\n 150  51 120 124 157 111  87 119 153   2  99 132 169 185], 정답 [99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99\n 99 99 99 99 99 99 99 99]\n(VAL) Batch 155 Loss : 4.446988105773926, accuracy: 0.03125\nVAL : 예측라벨 : [ 99  73  27 188 156  61  16  82  60 100 105  60 100 120  21 100 120  50\n 155 123 121 120 193 156  77  24 163 195  24 100 136 144], 정답 [ 99  99  99  99  99  99  99  99 100 100 100 100 100 100 100 100 100 100\n 100 100 100 100 100 100 100 100 100 100 100 100 100 100]\n(VAL) Batch 156 Loss : 3.882783889770508, accuracy: 0.15625\nVAL : 예측라벨 : [ 75 100  86 113 125 111  63 140  68 106 100 110 106  73 119 119 150 144\n 174 119 100 108 187 131 100  60 197 101 157  66 101  97], 정답 [100 100 100 100 100 100 100 100 100 100 100 100 100 100 100 100 100 100\n 100 100 100 100 100 100 100 100 101 101 101 101 101 101]\n(VAL) Batch 157 Loss : 3.393028736114502, accuracy: 0.1875\nVAL : 예측라벨 : [132 101 101 101 101 132 101 124 101 101  79  22 132 100 124 173 101 101\n 101 173 165 101 101 113 101 101 101 101 146 101 132  90], 정답 [101 101 101 101 101 101 101 101 101 101 101 101 101 101 101 101 101 101\n 101 101 101 101 101 101 101 101 101 101 101 101 101 101]\n(VAL) Batch 158 Loss : 1.8076131343841553, accuracy: 0.53125\nVAL : 예측라벨 : [101 118 166 137 101 101 132 132 101 132 198 101 103  90 129 154 162 102\n 102  72 185 154  75 102  17 157 129 157 188 165 126 148], 정답 [101 101 101 101 101 101 101 101 101 101 101 101 102 102 102 102 102 102\n 102 102 102 102 102 102 102 102 102 102 102 102 102 102]\n(VAL) Batch 159 Loss : 3.2311904430389404, accuracy: 0.25\nVAL : 예측라벨 : [ 13  61 102  78  84  65 155 124  83 105 102  96 102 102 170 157  85 119\n 191 102 102 157 137 105  61 102 165 162  90  75  65  70], 정답 [102 102 102 102 102 102 102 102 102 102 102 102 102 102 102 102 102 102\n 102 102 102 102 102 102 102 102 102 102 102 102 103 103]\n(VAL) Batch 160 Loss : 3.4123218059539795, accuracy: 0.21875\nVAL : 예측라벨 : [162 103  78 170 103 103 107 103 103 103 197 103 103 103 103 103 103   1\n   5 116 166  98 103 103 103  76 157 103 103  61 103 103], 정답 [103 103 103 103 103 103 103 103 103 103 103 103 103 103 103 103 103 103\n 103 103 103 103 103 103 103 103 103 103 103 103 103 103]\n(VAL) Batch 161 Loss : 1.8194853067398071, accuracy: 0.59375\nVAL : 예측라벨 : [103 103 103 154 103 103 103 103 154 165 103 173  84 116 115 103  21 190\n 174 106 174 104 104 192  89 188 174  71 123 140 191 193], 정답 [103 103 103 103 103 103 103 103 103 103 103 103 103 103 103 103 104 104\n 104 104 104 104 104 104 104 104 104 104 104 104 104 104]\n(VAL) Batch 162 Loss : 2.7521941661834717, accuracy: 0.34375\nVAL : 예측라벨 : [ 48 191 192 104 104  87 123 122  17  30 104 104  42  21 191  77 189 186\n 191 104  12 123 104 156 182  14 183 193 174 104 136 192], 정답 [104 104 104 104 104 104 104 104 104 104 104 104 104 104 104 104 104 104\n 104 104 104 104 104 104 104 104 104 104 104 104 104 104]\n(VAL) Batch 163 Loss : 3.1617307662963867, accuracy: 0.21875\nVAL : 예측라벨 : [ 18 146 105 119 106   6 129  85 105 105 105 105 106  89 140 106 105  30\n  82  74 105  90 106 169  82 105  77 144 119 120  74 119], 정답 [104 104 105 105 105 105 105 105 105 105 105 105 105 105 105 105 105 105\n 105 105 105 105 105 105 105 105 105 105 105 105 105 105]\n(VAL) Batch 164 Loss : 3.0222585201263428, accuracy: 0.25\nVAL : 예측라벨 : [ 32  63 105 131 100  82 105 120 105 105  85 105 134 105  53  32  55 141\n 150 105  92  82 112 119  73 106 106 106 100  63   5 117], 정답 [105 105 105 105 105 105 105 105 105 105 105 105 105 105 105 105 105 105\n 105 105 106 106 106 106 106 106 106 106 106 106 106 106]\n(VAL) Batch 165 Loss : 2.9787094593048096, accuracy: 0.3125\nVAL : 예측라벨 : [ 63 140 143  12  75 163 119 106 106 106 106 112  63  62 120  89  82 123\n 106  30 106 112 105 106  73  60  12 125  98  77  81  55], 정답 [106 106 106 106 106 106 106 106 106 106 106 106 106 106 106 106 106 106\n 106 106 106 106 106 106 106 106 106 106 106 106 106 106]\n(VAL) Batch 166 Loss : 3.2448041439056396, accuracy: 0.21875\nVAL : 예측라벨 : [ 94  99  60 119 104 152 111 107 119 107  90 107 164 161 107 107 107 107\n 107 174 107 107 115 107  56 153 118 107 154 107 107 180], 정답 [106 106 106 106 106 106 107 107 107 107 107 107 107 107 107 107 107 107\n 107 107 107 107 107 107 107 107 107 107 107 107 107 107]\n(VAL) Batch 167 Loss : 2.924656629562378, accuracy: 0.4375\nVAL : 예측라벨 : [107 107 107 107  43 153 107 107 107 107  11 139 107 111  75 121 107 107\n  70 107 164 107 107 153 108 118  65  55 108 162   8  70], 정답 [107 107 107 107 107 107 107 107 107 107 107 107 107 107 107 107 107 107\n 107 107 107 107 107 107 108 108 108 108 108 108 108 108]\n(VAL) Batch 168 Loss : 1.9608793258666992, accuracy: 0.5\nVAL : 예측라벨 : [108 108 108 119 147 108 108 142 167 108 166 107 173 108  82 108 108 108\n 142 166 148 173 103 108 197 108  90  60 108 103 108 166], 정답 [108 108 108 108 108 108 108 108 108 108 108 108 108 108 108 108 108 108\n 108 108 108 108 108 108 108 108 108 108 108 108 108 108]\n(VAL) Batch 169 Loss : 2.177381753921509, accuracy: 0.4375\nVAL : 예측라벨 : [108 108 198 129 119 108 115 103 108 103 109 109 119 109 125 140 105 144\n 117  93  31 163  99 105  72 106 110 173  24 120 130 180], 정답 [108 108 108 108 108 108 108 108 108 108 109 109 109 109 109 109 109 109\n 109 109 109 109 109 109 109 109 109 109 109 109 109 109]\n(VAL) Batch 170 Loss : 3.2301363945007324, accuracy: 0.21875\nVAL : 예측라벨 : [109 105 189 125 109  89 169 105 108  90  24 139 109  93 199  90 109 106\n  68   8 102 128 169  42 144 109  99 163 144 110  97  87], 정답 [109 109 109 109 109 109 109 109 109 109 109 109 109 109 109 109 109 109\n 109 109 109 109 109 109 109 109 109 109 110 110 110 110]\n(VAL) Batch 171 Loss : 4.0921549797058105, accuracy: 0.1875\nVAL : 예측라벨 : [130 151 110 128 110  31  58 140 110 104  90 106 130 110 180 100  52  92\n 141 140 110  31  62 110 123  97 127  28 127 178 110 155], 정답 [110 110 110 110 110 110 110 110 110 110 110 110 110 110 110 110 110 110\n 110 110 110 110 110 110 110 110 110 110 110 110 110 110]\n(VAL) Batch 172 Loss : 3.5544519424438477, accuracy: 0.21875\nVAL : 예측라벨 : [151 141 172 155  86  87 110 113 110 187  77  63  85  75  74 129  62  60\n 111 111 111 111 111 111 119  84 111 119  65 112 128 176], 정답 [110 110 110 110 110 110 110 110 110 110 110 110 110 110 111 111 111 111\n 111 111 111 111 111 111 111 111 111 111 111 111 111 111]\n(VAL) Batch 173 Loss : 2.7186083793640137, accuracy: 0.28125\nVAL : 예측라벨 : [163 140 111 112 111 111 111 119 111 167 111 111  84 129 111 111 111 111\n 136 118 111 111 111 119 176 111  90 119  29 111 111 128], 정답 [111 111 111 111 111 111 111 111 111 111 111 111 111 111 111 111 111 111\n 111 111 111 111 111 111 111 111 111 111 111 111 111 111]\n(VAL) Batch 174 Loss : 2.157477617263794, accuracy: 0.53125\nVAL : 예측라벨 : [ 90 112 120 112  93 169 143 118 120  82 112 134 169 134 105  90  60 199\n 161   9  90 112 120 107 112  60  79 112 112  90  60  85], 정답 [112 112 112 112 112 112 112 112 112 112 112 112 112 112 112 112 112 112\n 112 112 112 112 112 112 112 112 112 112 112 112 112 112]\n(VAL) Batch 175 Loss : 3.0756468772888184, accuracy: 0.21875\nVAL : 예측라벨 : [169 163 176 169 169 138 156 119  12 112 163  60 105 106 119 153  63 134\n  98 113 174 172 185  40  13  79  64 113  40  90 140  82], 정답 [112 112 112 112 112 112 112 112 112 112 112 112 112 112 112 112 112 112\n 113 113 113 113 113 113 113 113 113 113 113 113 113 113]\n(VAL) Batch 176 Loss : 3.3271355628967285, accuracy: 0.09375\nVAL : 예측라벨 : [ 79  89  91  98 113 158  89 113 113  24  79  98 113  76  99 126  98 113\n  92 113 105   8 113 187 192 113 173  85 178  61 160  98], 정답 [113 113 113 113 113 113 113 113 113 113 113 113 113 113 113 113 113 113\n 113 113 113 113 113 113 113 113 113 113 113 113 113 113]\n(VAL) Batch 177 Loss : 3.5396358966827393, accuracy: 0.25\nVAL : 예측라벨 : [104 152 126 140 118 162 111  82 152 114 114  76 176 114  90 132 114 118\n 119 114 107  45 107 144 134 112  94 164  70 157 153  76], 정답 [113 113 113 113 114 114 114 114 114 114 114 114 114 114 114 114 114 114\n 114 114 114 114 114 114 114 114 114 114 114 114 114 114]\n(VAL) Batch 178 Loss : 3.304831027984619, accuracy: 0.15625\nVAL : 예측라벨 : [114 107 118 111 118 107 146  73 142  78 114 114 118 118   2 114 189 162\n 163 114 129 152 115 115  78 115 115  10 115 115 115 144], 정답 [114 114 114 114 114 114 114 114 114 114 114 114 114 114 114 114 114 114\n 114 114 114 114 115 115 115 115 115 115 115 115 115 115]\n(VAL) Batch 179 Loss : 3.0469508171081543, accuracy: 0.375\nVAL : 예측라벨 : [115 115 146 115 101 115 115 146  41 115 115 115 115 115 115 157 115 115\n  68  95 115 115 107 148 115 198 145 115 115 115 115 115], 정답 [115 115 115 115 115 115 115 115 115 115 115 115 115 115 115 115 115 115\n 115 115 115 115 115 115 115 115 115 115 115 115 115 115]\n(VAL) Batch 180 Loss : 1.4197899103164673, accuracy: 0.65625\nVAL : 예측라벨 : [115  18 115 115 166 115 115  82 116 123  87 100 116 154 116 163  87 121\n 116 116 116 118 116 115 133  99 165 133  75 139 192 154], 정답 [115 115 115 115 115 115 115 115 116 116 116 116 116 116 116 116 116 116\n 116 116 116 116 116 116 116 116 116 116 116 116 116 116]\n(VAL) Batch 181 Loss : 2.7043850421905518, accuracy: 0.375\nVAL : 예측라벨 : [ 93 116  70  70  70 147 114 140 154  87 116 166 133  63  94  81 116 116\n  49 116 145 157 116 116 116  94  45 106 117  52 147 117], 정답 [116 116 116 116 116 116 116 116 116 116 116 116 116 116 116 116 116 116\n 116 116 116 116 116 116 116 116 117 117 117 117 117 117]\n(VAL) Batch 182 Loss : 2.8276093006134033, accuracy: 0.3125\nVAL : 예측라벨 : [155 156 183 174 117 117  13  73  93 149 117 173 117 117  78 117  62 139\n 155 117 117   6 119 117  85 117 118 117 117 155 117 100], 정답 [117 117 117 117 117 117 117 117 117 117 117 117 117 117 117 117 117 117\n 117 117 117 117 117 117 117 117 117 117 117 117 117 117]\n(VAL) Batch 183 Loss : 2.9847593307495117, accuracy: 0.40625\nVAL : 예측라벨 : [173 118 151 117 159 117 155 130 143 160  40 155 118 170 118 170 118 118\n 118 118 118 118 132 118 118 118 114  85 118 164 118 118], 정답 [117 117 117 117 117 117 117 117 117 117 117 117 118 118 118 118 118 118\n 118 118 118 118 118 118 118 118 118 118 118 118 118 118]\n(VAL) Batch 184 Loss : 2.075122356414795, accuracy: 0.5\nVAL : 예측라벨 : [163 132 163 118  62 118 118 119  95 118 118 118 132 118 118 118  44 118\n 118 118 118 118 118 118 118 155 118 118 118 118  57 119], 정답 [118 118 118 118 118 118 118 118 118 118 118 118 118 118 118 118 118 118\n 118 118 118 118 118 118 118 118 118 118 118 118 119 119]\n(VAL) Batch 185 Loss : 1.4829317331314087, accuracy: 0.6875\nVAL : 예측라벨 : [119  51 119 119 173 119  21 119 119  75 140 148 105 118 169  75 106 119\n 120 119 156 119 119 105 119 106 119  32 167 128 136  53], 정답 [119 119 119 119 119 119 119 119 119 119 119 119 119 119 119 119 119 119\n 119 119 119 119 119 119 119 119 119 119 119 119 119 119]\n(VAL) Batch 186 Loss : 2.968554973602295, accuracy: 0.375\nVAL : 예측라벨 : [118  60  57 118 162 167 118 119 105 119 163 118  60 124 173 106 142  98\n 170 111 120 120  58  60 113  90  73 163 120  74  60  85], 정답 [119 119 119 119 119 119 119 119 119 119 119 119 119 119 119 119 120 120\n 120 120 120 120 120 120 120 120 120 120 120 120 120 120]\n(VAL) Batch 187 Loss : 3.389695644378662, accuracy: 0.15625\nVAL : 예측라벨 : [150 144  79  60 105 120 131  68 120 176 149 120 120 131  62 141 131 105\n 120  69  85  90  91 120 123 100 123  60  60 120  68  36], 정답 [120 120 120 120 120 120 120 120 120 120 120 120 120 120 120 120 120 120\n 120 120 120 120 120 120 120 120 120 120 120 120 120 120]\n(VAL) Batch 188 Loss : 3.3949623107910156, accuracy: 0.21875\nVAL : 예측라벨 : [ 21 134 153  94 121  97 121 166 121  94  96 157 121 128 145  75 138 121\n 121 121 121  62  97 111 121 133 166 121  70 121  98 147], 정답 [120 120 121 121 121 121 121 121 121 121 121 121 121 121 121 121 121 121\n 121 121 121 121 121 121 121 121 121 121 121 121 121 121]\n(VAL) Batch 189 Loss : 2.661372661590576, accuracy: 0.34375\nVAL : 예측라벨 : [197 166 157 145 166 133 121 115  81 166 121 166 165 121 121 121 121 154\n  94 121 124   6 128  24 122  10 161 121 189 122  91 126], 정답 [121 121 121 121 121 121 121 121 121 121 121 121 121 121 121 121 121 121\n 121 121 122 122 122 122 122 122 122 122 122 122 122 122]\n(VAL) Batch 190 Loss : 3.3035619258880615, accuracy: 0.28125\nVAL : 예측라벨 : [122 106   8   8 137  88 101 113  53 181 122  95 113  43  49 109 122  96\n 144 108 117  91 113  10  52  91  29 167 129  22 106  69], 정답 [122 122 122 122 122 122 122 122 122 122 122 122 122 122 122 122 122 122\n 122 122 122 122 122 122 122 122 122 122 122 122 122 122]\n(VAL) Batch 191 Loss : 3.7400362491607666, accuracy: 0.09375\nVAL : 예측라벨 : [144 105  19 126 170  72 158 123 138 158 105  74 118 100 119  60 119 106\n 123 194 106 106 123 147 106  45  60  68 105  93  32  63], 정답 [122 122 122 122 122 122 123 123 123 123 123 123 123 123 123 123 123 123\n 123 123 123 123 123 123 123 123 123 123 123 123 123 123]\n(VAL) Batch 192 Loss : 4.155333042144775, accuracy: 0.09375\nVAL : 예측라벨 : [156  57 156 112  32 156 120 180 100 171  60 123 123  75 123 140 106 123\n  24  85 105  74 123 180 124 132 124 124 124 109 124 109], 정답 [123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123 123\n 123 123 123 123 123 123 124 124 124 124 124 124 124 124]\n(VAL) Batch 193 Loss : 2.9558067321777344, accuracy: 0.3125\nVAL : 예측라벨 : [131 124 124 124 124 124 124 124 124 124 101 124 124 124  62 124 124 124\n 124 124 124 124 124 165  71 198 124 124 124 124 157 124], 정답 [124 124 124 124 124 124 124 124 124 124 124 124 124 124 124 124 124 124\n 124 124 124 124 124 124 124 124 124 124 124 124 124 124]\n(VAL) Batch 194 Loss : 1.369468092918396, accuracy: 0.78125\nVAL : 예측라벨 : [124 124 124 124 124  71 124 124  95 124 156 123 144  10 125  95 163  60\n 157 112 146 125   8 125 138 156 105  60  33  43 147 156], 정답 [124 124 124 124 124 124 124 124 124 124 125 125 125 125 125 125 125 125\n 125 125 125 125 125 125 125 125 125 125 125 125 125 125]\n(VAL) Batch 195 Loss : 2.82546067237854, accuracy: 0.34375\nVAL : 예측라벨 : [163  30  28  95 106 152 103  77 157 123 141 188 163  61  95 125 144 106\n  68 132  60 123  99 125  77  18 105 169 126 119 142  61], 정답 [125 125 125 125 125 125 125 125 125 125 125 125 125 125 125 125 125 125\n 125 125 125 125 125 125 125 125 125 125 126 126 126 126]\n(VAL) Batch 196 Loss : 3.5871121883392334, accuracy: 0.09375\nVAL : 예측라벨 : [ 61 126 126 126 129 142 129 169  61  35  61 126 126 126 129 105  57 129\n  61  61   6 162 126  91  52 126 169  57 126 109  89 126], 정답 [126 126 126 126 126 126 126 126 126 126 126 126 126 126 126 126 126 126\n 126 126 126 126 126 126 126 126 126 126 126 126 126 126]\n(VAL) Batch 197 Loss : 2.8570854663848877, accuracy: 0.3125\nVAL : 예측라벨 : [151  60  61   6 142 126 126 162 126 126  61 165 169 126  20 139  69  93\n 162 170 128  63  78 139 127 127 127 151 165  96  63 140], 정답 [126 126 126 126 126 126 126 126 126 126 126 126 126 126 127 127 127 127\n 127 127 127 127 127 127 127 127 127 127 127 127 127 127]\n(VAL) Batch 198 Loss : 3.267188549041748, accuracy: 0.25\nVAL : 예측라벨 : [ 63 167  63  42 109 132 145  71 105 127 106  72 164  69  87 128 121 127\n 104 144  63  63  87 140 154  62  83  63  21  67 141  87], 정답 [127 127 127 127 127 127 127 127 127 127 127 127 127 127 127 127 127 127\n 127 127 127 127 127 127 127 127 127 127 127 127 127 127]\n(VAL) Batch 199 Loss : 3.783231735229492, accuracy: 0.0625\nVAL : 예측라벨 : [ 63  60 110 147 188 167 128  90 149 128 128 169 167 128 128 118  60 128\n 128 102 128 127  78 140 163  63 111  77  60  63  63 183], 정답 [128 128 128 128 128 128 128 128 128 128 128 128 128 128 128 128 128 128\n 128 128 128 128 128 128 128 128 128 128 128 128 128 128]\n(VAL) Batch 200 Loss : 3.3261196613311768, accuracy: 0.25\nVAL : 예측라벨 : [128 151 138 128 167 128 128 128 167  60 128  78  63 103  85 128 128 128\n 129 185 129 129 178 167 118 118 129 154 129 129 154 129], 정답 [128 128 128 128 128 128 128 128 128 128 128 128 128 128 128 128 128 128\n 129 129 129 129 129 129 129 129 129 129 129 129 129 129]\n(VAL) Batch 201 Loss : 2.3046181201934814, accuracy: 0.5\nVAL : 예측라벨 : [188  60 173 151 129 129 137 129 178 129 169  63  13 170  96 165 129 129\n 134 129  71  21 105 162 129  57 129 132 129 129 129  78], 정답 [129 129 129 129 129 129 129 129 129 129 129 129 129 129 129 129 129 129\n 129 129 129 129 129 129 129 129 129 129 129 129 129 129]\n(VAL) Batch 202 Loss : 2.765126943588257, accuracy: 0.375\nVAL : 예측라벨 : [ 71 129  57 129 144  90  31 144  59 181 148  28 130 189 173 188 144 180\n  23  84 130 189  73  98  21 180 178 163  36 182  99 105], 정답 [129 129 129 129 130 130 130 130 130 130 130 130 130 130 130 130 130 130\n 130 130 130 130 130 130 130 130 130 130 130 130 130 130]\n(VAL) Batch 203 Loss : 3.5982887744903564, accuracy: 0.125\nVAL : 예측라벨 : [104 173 130  59  61 130 113 140 130  11 113 177 147 147 130 186 135 130\n 180 153 181 193 131 125  77 132 183  62 100 147 128  68], 정답 [130 130 130 130 130 130 130 130 130 130 130 130 130 130 130 130 130 130\n 130 130 130 130 131 131 131 131 131 131 131 131 131 131]\n(VAL) Batch 204 Loss : 3.9538068771362305, accuracy: 0.1875\nVAL : 예측라벨 : [ 77 142  60 152 158 138 144  90 122 125  53 134 159 135 138 131 144 180\n  99 183 123 140  58 194  68 132 131 142   8  89  61 105], 정답 [131 131 131 131 131 131 131 131 131 131 131 131 131 131 131 131 131 131\n 131 131 131 131 131 131 131 131 131 131 131 131 131 131]\n(VAL) Batch 205 Loss : 3.9366540908813477, accuracy: 0.0625\nVAL : 예측라벨 : [106 131  91   8  99  63 167 152 118 101 132 125 101 119  52 157 124 167\n 113 100 144 101 132 128  71 154 124  95 132  68 144 132], 정답 [131 131 131 131 131 131 131 131 132 132 132 132 132 132 132 132 132 132\n 132 132 132 132 132 132 132 132 132 132 132 132 132 132]\n(VAL) Batch 206 Loss : 3.485713243484497, accuracy: 0.15625\nVAL : 예측라벨 : [132 132   8  60 112  78 128 101 105 144 101  68   7 167 124  53  70  28\n 105 118 124  79  76  31 129 180 133 133 116 133 133 121], 정답 [132 132 132 132 132 132 132 132 132 132 132 132 132 132 132 132 132 132\n 132 132 132 132 132 132 132 132 133 133 133 133 133 133]\n(VAL) Batch 207 Loss : 3.467471122741699, accuracy: 0.1875\nVAL : 예측라벨 : [116  94 121 133 170 133 133  97 133 133 133 116 133 166 133 133 133 153\n 133 153 164 133 133 133 133 121 116 116 153  94 133 133], 정답 [133 133 133 133 133 133 133 133 133 133 133 133 133 133 133 133 133 133\n 133 133 133 133 133 133 133 133 133 133 133 133 133 133]\n(VAL) Batch 208 Loss : 1.9457955360412598, accuracy: 0.53125\nVAL : 예측라벨 : [140 133 133 121 121  81 133 116 133  81 116  70 149 134 190 123  60 105\n 118  85 118   7  85  62  68  37 118 134 134 163  62 134], 정답 [133 133 133 133 133 133 133 133 133 133 133 133 134 134 134 134 134 134\n 134 134 134 134 134 134 134 134 134 134 134 134 134 134]\n(VAL) Batch 209 Loss : 2.650826930999756, accuracy: 0.25\nVAL : 예측라벨 : [134 134 169 134 134 134 129 134  90 134 134 134 119  93 134 134  85 134\n  78 134 118 105  78 112  85  13 134  93 134  45 183  90], 정답 [134 134 134 134 134 134 134 134 134 134 134 134 134 134 134 134 134 134\n 134 134 134 134 134 134 134 134 134 134 134 134 135 135]\n(VAL) Batch 210 Loss : 2.4996814727783203, accuracy: 0.46875\nVAL : 예측라벨 : [172 162 114 104  67  60 124  73  54  93  80 186 108  75  90  60  67 176\n 125  79 162  93  93 118 176 113 103 139 112 111  40 112], 정답 [135 135 135 135 135 135 135 135 135 135 135 135 135 135 135 135 135 135\n 135 135 135 135 135 135 135 135 135 135 135 135 135 135]\n(VAL) Batch 211 Loss : 4.7820329666137695, accuracy: 0.0\nVAL : 예측라벨 : [ 72 169 121  80 158 173  93  98  40 108  73  85 141 144 144 131  12 144\n  18 136 140  89 171 136 153  62  24 123  12  63  32  32], 정답 [135 135 135 135 135 135 135 135 135 135 135 135 135 135 135 135 136 136\n 136 136 136 136 136 136 136 136 136 136 136 136 136 136]\n(VAL) Batch 212 Loss : 4.088150501251221, accuracy: 0.0625\nVAL : 예측라벨 : [ 24  25 141 136  86  75  31 142  85  98 151 105 136 136  30 105 136  53\n 173  62 136 144  48  65 144 119  74  82  68 156 161 142], 정답 [136 136 136 136 136 136 136 136 136 136 136 136 136 136 136 136 136 136\n 136 136 136 136 136 136 136 136 136 136 136 136 136 136]\n(VAL) Batch 213 Loss : 3.804264545440674, accuracy: 0.15625\nVAL : 예측라벨 : [136 136 132  70  57  69  22  29  21  21 171  21 133 157 116  13 137  79\n 107 119 124 115 142  55 131 144  88  21  80 118  71 137], 정답 [136 136 137 137 137 137 137 137 137 137 137 137 137 137 137 137 137 137\n 137 137 137 137 137 137 137 137 137 137 137 137 137 137]\n(VAL) Batch 214 Loss : 3.7954447269439697, accuracy: 0.125\nVAL : 예측라벨 : [128 115 173  21 146 142 119 124  13  21  22 140 125 137 172  71 132  92\n 137  69 138  63 138 138 120  68  60 138  60 138 172 128], 정답 [137 137 137 137 137 137 137 137 137 137 137 137 137 137 137 137 137 137\n 137 137 138 138 138 138 138 138 138 138 138 138 138 138]\n(VAL) Batch 215 Loss : 3.587425708770752, accuracy: 0.21875\nVAL : 예측라벨 : [ 73  81 131  63  62 116  60  77 101  73 167  23 112 184  60 169 100 134\n 120  21  73   6 100 149  60  90  86  90 110 140 113  21], 정답 [138 138 138 138 138 138 138 138 138 138 138 138 138 138 138 138 138 138\n 138 138 138 138 138 138 138 138 138 138 138 138 138 138]\n(VAL) Batch 216 Loss : 4.039402484893799, accuracy: 0.0\nVAL : 예측라벨 : [119 100 176 105 120  90  52 196  19  23 122 165  12 117 139  75 139 101\n 136  98 135  92  22 157  89  43 146   5 106 106 107  95], 정답 [138 138 138 138 138 138 139 139 139 139 139 139 139 139 139 139 139 139\n 139 139 139 139 139 139 139 139 139 139 139 139 139 139]\n(VAL) Batch 217 Loss : 4.161694049835205, accuracy: 0.0625\nVAL : 예측라벨 : [166 139 155  21 139 183 144  40 197 106 146  89 102  32  63   8 117  89\n 119  83 124 112   4 117 121 140 140 171 127  89 140  86], 정답 [139 139 139 139 139 139 139 139 139 139 139 139 139 139 139 139 139 139\n 139 139 139 139 139 139 140 140 140 140 140 140 140 140]\n(VAL) Batch 218 Loss : 3.9637930393218994, accuracy: 0.15625\nVAL : 예측라벨 : [140 131  68 140  62 140  60 159 140 121 140 136 140 107  86  47  30 183\n 140 102 167  63 113 128 104  62 140  89 178  11 140  60], 정답 [140 140 140 140 140 140 140 140 140 140 140 140 140 140 140 140 140 140\n 140 140 140 140 140 140 140 140 140 140 140 140 140 140]\n(VAL) Batch 219 Loss : 3.6799750328063965, accuracy: 0.28125\nVAL : 예측라벨 : [117 167 140  89 140  21 140 140 140  17 106  11 160  87 141  37  98 141\n 100 174  65 103 110 106 141  75 154 128  61 128  87 110], 정답 [140 140 140 140 140 140 140 140 140 140 141 141 141 141 141 141 141 141\n 141 141 141 141 141 141 141 141 141 141 141 141 141 141]\n(VAL) Batch 220 Loss : 3.800849676132202, accuracy: 0.25\nVAL : 예측라벨 : [ 23 106 107  92 149  79  23 151  72 130 141 167  33 148  86  36  60 159\n 193 141  87 141 153  67 141 128 106 103  57 142  53 142], 정답 [141 141 141 141 141 141 141 141 141 141 141 141 141 141 141 141 141 141\n 141 141 141 141 141 141 141 141 141 141 142 142 142 142]\n(VAL) Batch 221 Loss : 4.031024932861328, accuracy: 0.1875\nVAL : 예측라벨 : [106 140 142  61 100 173 142 142 119  73 142 111 142 128  52 142  48 142\n 137 142  61  63 102  74 146 142  52 142 129 142 139  73], 정답 [142 142 142 142 142 142 142 142 142 142 142 142 142 142 142 142 142 142\n 142 142 142 142 142 142 142 142 142 142 142 142 142 142]\n(VAL) Batch 222 Loss : 3.090881109237671, accuracy: 0.34375\nVAL : 예측라벨 : [126  81  98 128  68 115  61 154  82 100 136 142  69 117 143 143 143 143\n 112 143  45 143 143 143 143 143 120 143 143 143 143 143], 정답 [142 142 142 142 142 142 142 142 142 142 142 142 142 142 143 143 143 143\n 143 143 143 143 143 143 143 143 143 143 143 143 143 143]\n(VAL) Batch 223 Loss : 2.2301409244537354, accuracy: 0.5\nVAL : 예측라벨 : [143 164 143 163 143 143  11 143 143 143 143 106  14 143 185  52 143 143\n 118 143 143 143 143 143 198 118 143 163 143 123 143 123], 정답 [143 143 143 143 143 143 143 143 143 143 143 143 143 143 143 143 143 143\n 143 143 143 143 143 143 143 143 143 143 143 143 143 143]\n(VAL) Batch 224 Loss : 2.172968864440918, accuracy: 0.59375\nVAL : 예측라벨 : [144  91 106 144 120 120  90 144 144  42  62 144  60 144   5 142 116 140\n 147 131 131 193 131 167 144 144 117  85 148 113 122 139], 정답 [144 144 144 144 144 144 144 144 144 144 144 144 144 144 144 144 144 144\n 144 144 144 144 144 144 144 144 144 144 144 144 144 144]\n(VAL) Batch 225 Loss : 3.560598850250244, accuracy: 0.25\nVAL : 예측라벨 : [140 100  32 139 147 144 158 144 155 144 144 144  30 147  21  90 192 144\n 145 145 166 145 145 145 145 145 145 145 145 170  66  71], 정답 [144 144 144 144 144 144 144 144 144 144 144 144 144 144 144 144 144 144\n 145 145 145 145 145 145 145 145 145 145 145 145 145 145]\n(VAL) Batch 226 Loss : 2.5522239208221436, accuracy: 0.5\nVAL : 예측라벨 : [145 145 145 145 145 145 145 145 145 129 150 145  89 145 145 145 145 145\n 107 104 145 128 145 145 145 145 145 145 139 153 145 145], 정답 [145 145 145 145 145 145 145 145 145 145 145 145 145 145 145 145 145 145\n 145 145 145 145 145 145 145 145 145 145 145 145 145 145]\n(VAL) Batch 227 Loss : 1.1861350536346436, accuracy: 0.75\nVAL : 예측라벨 : [145 145 145 145 103 146 164 146 146 146 146 146 176  63 146 146 146 146\n 146 146 146 146 147 146  65 166 146 146 140 146 171 116], 정답 [145 145 145 145 146 146 146 146 146 146 146 146 146 146 146 146 146 146\n 146 146 146 146 146 146 146 146 146 146 146 146 146 146]\n(VAL) Batch 228 Loss : 1.8253350257873535, accuracy: 0.6875\nVAL : 예측라벨 : [171 171 146 128 146 146 145  86 146 154 128 167  61 165 108 111 121 143\n 190 129 146 103  73 143  73 147 147  55 154 126 113 126], 정답 [146 146 146 146 146 146 146 146 146 146 146 146 146 146 146 146 146 146\n 146 146 146 146 147 147 147 147 147 147 147 147 147 147]\n(VAL) Batch 229 Loss : 3.4458465576171875, accuracy: 0.21875\nVAL : 예측라벨 : [163 147  98  98 147 144 121 147  81 147 171 147 107 136 106 140 140 147\n  97 147  98 147 142 151 147 147  89 147  97 116  62 147], 정답 [147 147 147 147 147 147 147 147 147 147 147 147 147 147 147 147 147 147\n 147 147 147 147 147 147 147 147 147 147 147 147 147 147]\n(VAL) Batch 230 Loss : 2.8731348514556885, accuracy: 0.375\nVAL : 예측라벨 : [ 97  73 147 117 147 147 147 121 148 150 158 122  68 148 148  74 148 183\n 164  66 148 148 196  60 198  13  52  23 115 148 105 158], 정답 [147 147 147 147 147 147 147 147 148 148 148 148 148 148 148 148 148 148\n 148 148 148 148 148 148 148 148 148 148 148 148 148 148]\n(VAL) Batch 231 Loss : 3.1433963775634766, accuracy: 0.34375\nVAL : 예측라벨 : [148 148  23 148  23 154  63  29 150  13 148 196 196  13  24 196  23  62\n 110 148 100 100  23 196 148 148 149 134 134  44 150 149], 정답 [148 148 148 148 148 148 148 148 148 148 148 148 148 148 148 148 148 148\n 148 148 148 148 148 148 148 148 149 149 149 149 149 149]\n(VAL) Batch 232 Loss : 3.0953261852264404, accuracy: 0.28125\nVAL : 예측라벨 : [ 93 112  90 169 127  74  90  24  62 178 111 134  31  62  62 149  76 189\n 149 146 149 134  85 149 120  93 183  62  85 128   2 135], 정답 [149 149 149 149 149 149 149 149 149 149 149 149 149 149 149 149 149 149\n 149 149 149 149 149 149 149 149 149 149 149 149 149 149]\n(VAL) Batch 233 Loss : 3.501660108566284, accuracy: 0.125\nVAL : 예측라벨 : [161 118  16   8  90  89 134  77 180 149  33   2 118 171  94 106 112 123\n 150  93 150 119  37 140 174  65 150 150  82 150 150 164], 정답 [149 149 149 149 149 149 149 149 149 149 149 149 150 150 150 150 150 150\n 150 150 150 150 150 150 150 150 150 150 150 150 150 150]\n(VAL) Batch 234 Loss : 3.794543981552124, accuracy: 0.21875\nVAL : 예측라벨 : [ 28 150  63  61 193  34 169 142 190  90 187  77  52  91  84 150  60 169\n 185 112  58  89  82 150 150  35  60  68 163 123 113 137], 정답 [150 150 150 150 150 150 150 150 150 150 150 150 150 150 150 150 150 150\n 150 150 150 150 150 150 150 150 150 150 150 150 151 151]\n(VAL) Batch 235 Loss : 4.031260967254639, accuracy: 0.125\nVAL : 예측라벨 : [140 169  62 151  69 151 151  79 134 140 180  89 151 151  83 113  67  89\n  89 141 151 108 151 151 151  95 151 124  77 126 141 172], 정답 [151 151 151 151 151 151 151 151 151 151 151 151 151 151 151 151 151 151\n 151 151 151 151 151 151 151 151 151 151 151 151 151 151]\n(VAL) Batch 236 Loss : 3.419177532196045, accuracy: 0.3125\nVAL : 예측라벨 : [151 172  90 100 157  91 106 140 151 173  63 173 151 151 154  94  14 152\n  19   2  14 152 152 152  46   2 152  14   6  37  34  63], 정답 [151 151 151 151 151 151 151 151 151 151 151 151 151 151 151 151 152 152\n 152 152 152 152 152 152 152 152 152 152 152 152 152 152]\n(VAL) Batch 237 Loss : 3.1733031272888184, accuracy: 0.28125\nVAL : 예측라벨 : [152  12   4  37 152  85  34 152  89 153 152 152 152 152  45  89 199 199\n 152   2 152   9 152  37 152  14 152  14   4 152 173  14], 정답 [152 152 152 152 152 152 152 152 152 152 152 152 152 152 152 152 152 152\n 152 152 152 152 152 152 152 152 152 152 152 152 152 152]\n(VAL) Batch 238 Loss : 2.782879114151001, accuracy: 0.40625\nVAL : 예측라벨 : [ 32 195  94 153  87  62 153  87  94 145  70 133 153 140 153  94 153 171\n  94  94  81 116 116  93 145 145 116  94 153  94  94  94], 정답 [152 152 153 153 153 153 153 153 153 153 153 153 153 153 153 153 153 153\n 153 153 153 153 153 153 153 153 153 153 153 153 153 153]\n(VAL) Batch 239 Loss : 2.1603758335113525, accuracy: 0.1875\nVAL : 예측라벨 : [153  70 153 145 153 145 153  94  94  81  94  70 145  94 153 153 121 153\n 153  94 154 142 169 154 162 128 157 129 154 157 132 154], 정답 [153 153 153 153 153 153 153 153 153 153 153 153 153 153 153 153 153 153\n 153 153 154 154 154 154 154 154 154 154 154 154 154 154]\n(VAL) Batch 240 Loss : 2.3911149501800537, accuracy: 0.375\nVAL : 예측라벨 : [ 70 154  52 137 157 103 154 154 170  66 170 102 166 173 154 154 194 129\n  93 157  12 154 157 154 154  95 165 154 154 157 167 154], 정답 [154 154 154 154 154 154 154 154 154 154 154 154 154 154 154 154 154 154\n 154 154 154 154 154 154 154 154 154 154 154 154 154 154]\n(VAL) Batch 241 Loss : 2.8992326259613037, accuracy: 0.34375\nVAL : 예측라벨 : [154  95 198 154  55 154  24 155  54 117 110 155  13  87  87 117 114 149\n  13 144  74  13 117 141 147 155 155 180 171 155 130 123], 정답 [154 154 154 154 154 154 155 155 155 155 155 155 155 155 155 155 155 155\n 155 155 155 155 155 155 155 155 155 155 155 155 155 155]\n(VAL) Batch 242 Loss : 3.4262259006500244, accuracy: 0.25\nVAL : 예측라벨 : [155 117 155  75  13 117 177  13 106 104 144  87 155 135 119 135 155 155\n 124 149 183  76 155  69 112  82  75 180  77   8 169  99], 정답 [155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155\n 155 155 155 155 155 155 156 156 156 156 156 156 156 156]\n(VAL) Batch 243 Loss : 3.5004472732543945, accuracy: 0.1875\nVAL : 예측라벨 : [144 144 156  18 128 156 156 128 144 156 106 180 144  79 156 156 117  77\n 180 199  63 112 105  29 156 144 187   9 156 100 156 156], 정답 [156 156 156 156 156 156 156 156 156 156 156 156 156 156 156 156 156 156\n 156 156 156 156 156 156 156 156 156 156 156 156 156 156]\n(VAL) Batch 244 Loss : 3.4494800567626953, accuracy: 0.3125\nVAL : 예측라벨 : [156  84 156  87  74 144 156  52  76  25 195 157 166 170 157 157 170 118\n 154 157 132 132 157 152 170 152 146 162 162 124 173 162], 정답 [156 156 156 156 156 156 156 156 156 156 157 157 157 157 157 157 157 157\n 157 157 157 157 157 157 157 157 157 157 157 157 157 157]\n(VAL) Batch 245 Loss : 2.6751091480255127, accuracy: 0.25\nVAL : 예측라벨 : [157 157 118 157 198 154 162 118 129 154 157 128 157 132 170 162 157 109\n  92 129  96  78 154 157 165 157 124 157 122 158 158 156], 정답 [157 157 157 157 157 157 157 157 157 157 157 157 157 157 157 157 157 157\n 157 157 157 157 157 157 157 157 157 157 158 158 158 158]\n(VAL) Batch 246 Loss : 2.518768787384033, accuracy: 0.34375\nVAL : 예측라벨 : [ 62 123 146  63  21  19 134  60 105  12  68  75 117 158 114 132 163 171\n 131  68 110  76 158 112  67 158  26  96 158 158  85  84], 정답 [158 158 158 158 158 158 158 158 158 158 158 158 158 158 158 158 158 158\n 158 158 158 158 158 158 158 158 158 158 158 158 158 158]\n(VAL) Batch 247 Loss : 3.679014205932617, accuracy: 0.15625\nVAL : 예측라벨 : [123 158 158  63 148 120 144 158 131 158  74 117  74 134  13 100 179  89\n 180 159 189 129  60  40 144   2  92 115  77 104 122 100], 정답 [158 158 158 158 158 158 158 158 158 158 158 158 158 158 159 159 159 159\n 159 159 159 159 159 159 159 159 159 159 159 159 159 159]\n(VAL) Batch 248 Loss : 3.8312060832977295, accuracy: 0.15625\nVAL : 예측라벨 : [ 77 180   4  91 115 173  52 131 159  29 125  24 180  87 156  72  22 126\n 182  90   8 130  16 119  19 150  89 159 162 180  92  31], 정답 [159 159 159 159 159 159 159 159 159 159 159 159 159 159 159 159 159 159\n 159 159 159 159 159 159 159 159 159 159 159 159 159 159]\n(VAL) Batch 249 Loss : 4.547660827636719, accuracy: 0.0625\nVAL : 예측라벨 : [177 106 183  45 160  60  91  89  90 140 128 160  98  22 178 160  90 151\n 140 172 160 141 146 113 126   2 155 181  18  19 177 110], 정답 [160 160 160 160 160 160 160 160 160 160 160 160 160 160 160 160 160 160\n 160 160 160 160 160 160 160 160 160 160 160 160 160 160]\n(VAL) Batch 250 Loss : 3.841309070587158, accuracy: 0.125\nVAL : 예측라벨 : [160  93 151 114 106  61 147 180 137 161 160 135 160  87 106 160 192  12\n  34  53  32  99 189  33  45 190 144 108 143 106 105  31], 정답 [160 160 160 160 160 160 160 160 160 160 160 160 160 160 160 160 160 160\n 161 161 161 161 161 161 161 161 161 161 161 161 161 161]\n(VAL) Batch 251 Loss : 4.066403388977051, accuracy: 0.125\nVAL : 예측라벨 : [112  90  36  93 105 160  52 182  48  34  21 180  31 181  18 161  27  62\n  60  26  63  90  57  47  55  26 185  26 171 181  35 179], 정답 [161 161 161 161 161 161 161 161 161 161 161 161 161 161 161 161 161 161\n 161 161 161 161 161 161 161 161 161 161 161 161 161 161]\n(VAL) Batch 252 Loss : 3.8902618885040283, accuracy: 0.03125\nVAL : 예측라벨 : [ 28  90 161 161 170 162  82 152  53 174 170  53 162  78 165 162 162 173\n 162 162 170 129 103 129  52  85 114 162  14 170 162  14], 정답 [161 161 161 161 162 162 162 162 162 162 162 162 162 162 162 162 162 162\n 162 162 162 162 162 162 162 162 162 162 162 162 162 162]\n(VAL) Batch 253 Loss : 2.3655991554260254, accuracy: 0.3125\nVAL : 예측라벨 : [162 165 152 162  94 162  51  78 152  76 162 162 162 162 162 162 162 162\n 170 162  12 162 173  60 104 189 163 171 118  98 163 163], 정답 [162 162 162 162 162 162 162 162 162 162 162 162 162 162 162 162 162 162\n 162 162 162 162 163 163 163 163 163 163 163 163 163 163]\n(VAL) Batch 254 Loss : 2.46064829826355, accuracy: 0.5\nVAL : 예측라벨 : [163 163 163 163  65 163  60 163 163 105 168 163 163 163  65 163  68  60\n  85  13 132  68 163 163 140  60 105 171  99 163 135 163], 정답 [163 163 163 163 163 163 163 163 163 163 163 163 163 163 163 163 163 163\n 163 163 163 163 163 163 163 163 163 163 163 163 163 163]\n(VAL) Batch 255 Loss : 2.3043525218963623, accuracy: 0.46875\nVAL : 예측라벨 : [163 163  60 101  71 118 163 143 153 101 164 107 115 176 115 133 115 164\n  66 164 166 165 164 107 108  52 164 164 145 197  89 164], 정답 [163 163 163 163 163 163 163 163 164 164 164 164 164 164 164 164 164 164\n 164 164 164 164 164 164 164 164 164 164 164 164 164 164]\n(VAL) Batch 256 Loss : 2.7354724407196045, accuracy: 0.3125\nVAL : 예측라벨 : [164  76 166 114  66 164 114 164  84 107  84 102 107 128 163  93 118 111\n 196 145 111  84 108 164 118 118 170 165 165 171 170 165], 정답 [164 164 164 164 164 164 164 164 164 164 164 164 164 164 164 164 164 164\n 164 164 164 164 164 164 164 164 165 165 165 165 165 165]\n(VAL) Batch 257 Loss : 2.9942078590393066, accuracy: 0.21875\nVAL : 예측라벨 : [102 165 165 165 165 165 165 166 165 126 165 165 165 165 124 113  52 165\n 165 165 165 165 165 167 128 165 165 165 165 169  78 165], 정답 [165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165\n 165 165 165 165 165 165 165 165 165 165 165 165 165 165]\n(VAL) Batch 258 Loss : 1.6206201314926147, accuracy: 0.6875\nVAL : 예측라벨 : [165 165 165 165 195 165  53 124  67 165 165 170 166 166 118 166 145 166\n 166  94 166 121 166 146 166 166 166 166 166 166 166 166], 정답 [165 165 165 165 165 165 165 165 165 165 165 165 166 166 166 166 166 166\n 166 166 166 166 166 166 166 166 166 166 166 166 166 166]\n(VAL) Batch 259 Loss : 1.252590537071228, accuracy: 0.6875\nVAL : 예측라벨 : [162 108 166 166 166 157 166 166 166 166 166 108 145 157 166 166 166 146\n 166 166 101 166 166 166 166 166 115 166  93 167 172 167], 정답 [166 166 166 166 166 166 166 166 166 166 166 166 166 166 166 166 166 166\n 166 166 166 166 166 166 166 166 166 166 166 166 167 167]\n(VAL) Batch 260 Loss : 1.7628339529037476, accuracy: 0.625\nVAL : 예측라벨 : [128 118 151 129  81 146   8 150 141 167 132  62 167 110  75 146 109 128\n 128 114 128 167 167 170  81 167 163 129 128 111 167  68], 정답 [167 167 167 167 167 167 167 167 167 167 167 167 167 167 167 167 167 167\n 167 167 167 167 167 167 167 167 167 167 167 167 167 167]\n(VAL) Batch 261 Loss : 2.925732374191284, accuracy: 0.1875\nVAL : 예측라벨 : [167 129 167 163 167 132 167 141 167 148 167 163 167  92 125 167 158 152\n 111  60 148 111  75 170  65 157  18 105 146 164 111  72], 정답 [167 167 167 167 167 167 167 167 167 167 167 167 167 167 167 167 168 168\n 168 168 168 168 168 168 168 168 168 168 168 168 168 168]\n(VAL) Batch 262 Loss : 3.9211654663085938, accuracy: 0.25\nVAL : 예측라벨 : [180  82  70 139 118 128  93  36  62 172  66 100 111 158 158  75 168 119\n  90 154 163 169 168  60  40 105  52 113  29  65 101 107], 정답 [168 168 168 168 168 168 168 168 168 168 168 168 168 168 168 168 168 168\n 168 168 168 168 168 168 168 168 168 168 168 168 168 168]\n(VAL) Batch 263 Loss : 4.55505895614624, accuracy: 0.0625\nVAL : 예측라벨 : [ 66 176 145  61 182 169  61 163 169 169 105 169 112 102 148  21 169 169\n 169 169  89  85 145 169 126 169 118  93  62 169 180 105], 정답 [168 168 169 169 169 169 169 169 169 169 169 169 169 169 169 169 169 169\n 169 169 169 169 169 169 169 169 169 169 169 169 169 169]\n(VAL) Batch 264 Loss : 2.9098427295684814, accuracy: 0.34375\nVAL : 예측라벨 : [119 128  68 169 134  62 169  62 169 134  85  65 105 118 105  62 169  68\n  61 169 170  60 170 170 162 170 170 154 194 170 170 170], 정답 [169 169 169 169 169 169 169 169 169 169 169 169 169 169 169 169 169 169\n 169 169 170 170 170 170 170 170 170 170 170 170 170 170]\n(VAL) Batch 265 Loss : 2.6111795902252197, accuracy: 0.40625\nVAL : 예측라벨 : [  2  96 154 146 154 194 170 162 165 170 170 129 165  53 162  52 162  69\n 170 194   2 154 170 105 129 170 170 165 170 162 170  96], 정답 [170 170 170 170 170 170 170 170 170 170 170 170 170 170 170 170 170 170\n 170 170 170 170 170 170 170 170 170 170 170 170 170 170]\n(VAL) Batch 266 Loss : 2.435019016265869, accuracy: 0.28125\nVAL : 예측라벨 : [170 169 154 170 162 154  96 171 171 171 156 171 131 171 142 146 171 171\n 190 139 171 171  74  68  77 171 171  68 171 171 171  60], 정답 [170 170 170 170 170 170 171 171 171 171 171 171 171 171 171 171 171 171\n 171 171 171 171 171 171 171 171 171 171 171 171 171 171]\n(VAL) Batch 267 Loss : 2.5729079246520996, accuracy: 0.5\nVAL : 예측라벨 : [121  68 119 171 118 163 171 171 119 171 120 171 171 169 118 171 180 171\n 171 161 171 171 171 171 119  72 163 172 120 141 147  61], 정답 [171 171 171 171 171 171 171 171 171 171 171 171 171 171 171 171 171 171\n 171 171 171 171 171 171 172 172 172 172 172 172 172 172]\n(VAL) Batch 268 Loss : 2.6652188301086426, accuracy: 0.4375\nVAL : 예측라벨 : [ 68  33  62 140 138  67 160 173 128  72 169 134  62 172 161  62 118 117\n 131  63 179 119 117 172 105  21 144  73 131 111 172 187], 정답 [172 172 172 172 172 172 172 172 172 172 172 172 172 172 172 172 172 172\n 172 172 172 172 172 172 172 172 172 172 172 172 172 172]\n(VAL) Batch 269 Loss : 3.841271162033081, accuracy: 0.09375\nVAL : 예측라벨 : [  0  72 172 147 154 179  67  90  52 160 170 173 173 173 129 170  95 173\n 173 132 109 118  71 165 170 105 165 173 173 173 173 124], 정답 [172 172 172 172 172 172 172 172 172 172 173 173 173 173 173 173 173 173\n 173 173 173 173 173 173 173 173 173 173 173 173 173 173]\n(VAL) Batch 270 Loss : 2.802603006362915, accuracy: 0.3125\nVAL : 예측라벨 : [167 173 173  66 173  96 101 157 173  95 129 173 173 173 132 103 173 124\n 173 173 173 173 173 173  13 173 173 173 103  11  87 104], 정답 [173 173 173 173 173 173 173 173 173 173 173 173 173 173 173 173 173 173\n 173 173 173 173 173 173 173 173 173 173 174 174 174 174]\n(VAL) Batch 271 Loss : 2.2080862522125244, accuracy: 0.53125\nVAL : 예측라벨 : [174 174  31 144 104 183 174  76 177 190 174  61 104  17 104 174 174 178\n 178  46  23 174 174 174 142 174 174 174 174 106 104 174], 정답 [174 174 174 174 174 174 174 174 174 174 174 174 174 174 174 174 174 174\n 174 174 174 174 174 174 174 174 174 174 174 174 174 174]\n(VAL) Batch 272 Loss : 2.5191619396209717, accuracy: 0.4375\nVAL : 예측라벨 : [177  98 191 174 151  95 136 174 193 174 183 174 178   2 122 193 186  27\n  68 106  52 187 122 192 100 193   7 190 191  12  77  98], 정답 [174 174 174 174 174 174 174 174 174 174 174 174 174 174 175 175 175 175\n 175 175 175 175 175 175 175 175 175 175 175 175 175 175]\n(VAL) Batch 273 Loss : 3.7079224586486816, accuracy: 0.125\nVAL : 예측라벨 : [110 183   7  90 150  93 119 104 109 124  89 170 112 131  22  68 150 190\n 144 181 105 171 144 142 180  74  14 175  47 171 164 144], 정답 [175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175\n 175 175 175 175 175 175 175 175 175 175 175 175 175 175]\n(VAL) Batch 274 Loss : 4.7260823249816895, accuracy: 0.03125\nVAL : 예측라벨 : [ 93 176  93 176 176 176 176  90 171 176 126 150 176 176 176 118  97  62\n  17 176 176  62 176 176  93  43  93 176  65  93 176 176], 정답 [176 176 176 176 176 176 176 176 176 176 176 176 176 176 176 176 176 176\n 176 176 176 176 176 176 176 176 176 176 176 176 176 176]\n(VAL) Batch 275 Loss : 2.111859083175659, accuracy: 0.5\nVAL : 예측라벨 : [176 119  62 176  93 176 176  82 176  93 146 111  12 148  62 169 176  91\n 196 177 177 190  41 177  37 177 190 177 199 177 174  38], 정답 [176 176 176 176 176 176 176 176 176 176 176 176 176 176 176 176 176 176\n 177 177 177 177 177 177 177 177 177 177 177 177 177 177]\n(VAL) Batch 276 Loss : 2.774510383605957, accuracy: 0.375\nVAL : 예측라벨 : [177 190 181 144   5 190  72 174  25 177 177 192 161 177 177 190 140 192\n 177 178 177  18 191 191 191 193 178 141 178 177 190 104], 정답 [177 177 177 177 177 177 177 177 177 177 177 177 177 177 177 177 177 177\n 177 177 177 177 177 177 177 177 177 177 177 177 177 177]\n(VAL) Batch 277 Loss : 2.7817463874816895, accuracy: 0.25\nVAL : 예측라벨 : [178 177 182  91   2  76 178 177 178 178 178 178 178 178 183 178 178 190\n 178  42 178 190 178 178 182 150 183 178 177 178 183  44], 정답 [177 177 177 177 178 178 178 178 178 178 178 178 178 178 178 178 178 178\n 178 178 178 178 178 178 178 178 178 178 178 178 178 178]\n(VAL) Batch 278 Loss : 2.020443916320801, accuracy: 0.5\nVAL : 예측라벨 : [  2 185 192 190 178 178 178 177 178 178 190 183 178 199 178 178 182 178\n 192 117 178 177 161 183 182 144 138  24 179 182  13 177], 정답 [178 178 178 178 178 178 178 178 178 178 178 178 178 178 178 178 178 178\n 178 178 178 178 179 179 179 179 179 179 179 179 179 179]\n(VAL) Batch 279 Loss : 2.486227512359619, accuracy: 0.34375\nVAL : 예측라벨 : [ 47  26 179 189 177 100 144 179 147  31 177 182 189  76  92 182 182  86\n 179 106  68 190  48 190 179 190 191 179  24 189  24 106], 정답 [179 179 179 179 179 179 179 179 179 179 179 179 179 179 179 179 179 179\n 179 179 179 179 179 179 179 179 179 179 179 179 179 179]\n(VAL) Batch 280 Loss : 3.254617929458618, accuracy: 0.15625\nVAL : 예측라벨 : [181 181  49  32 179  40  31  91 123  90  74 189  60 180 180 161 123 123\n  90 123  60 180 123  85 180 193 135  77  72 169 183  24], 정답 [179 179 179 179 179 179 179 179 180 180 180 180 180 180 180 180 180 180\n 180 180 180 180 180 180 180 180 180 180 180 180 180 180]\n(VAL) Batch 281 Loss : 3.507862091064453, accuracy: 0.15625\nVAL : 예측라벨 : [ 60 130 106  60 180 180  73 180 189 180  85 112  24  74 163 131 114 150\n 134  34 131 144  26 180  74 100  93  89  74 161 182  18], 정답 [180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180\n 180 180 180 180 180 180 180 180 181 181 181 181 181 181]\n(VAL) Batch 282 Loss : 3.5601131916046143, accuracy: 0.15625\nVAL : 예측라벨 : [182 174 181 192 123 181 177 163 181 181  67 101 177  30 181 193 180 181\n 178 185  87 179 177 190  74 104   3  73  40 181 104 192], 정답 [181 181 181 181 181 181 181 181 181 181 181 181 181 181 181 181 181 181\n 181 181 181 181 181 181 181 181 181 181 181 181 181 181]\n(VAL) Batch 283 Loss : 3.9377005100250244, accuracy: 0.21875\nVAL : 예측라벨 : [ 82 160 181 191 181 183 128 195 177 181 181 181 182 104 191 177 190  25\n 177 182 182  45 177 182 182 179 177 147 182 190 191 191], 정답 [181 181 181 181 181 181 181 181 181 181 181 181 182 182 182 182 182 182\n 182 182 182 182 182 182 182 182 182 182 182 182 182 182]\n(VAL) Batch 284 Loss : 2.622138023376465, accuracy: 0.34375\nVAL : 예측라벨 : [181 174 175 192 183 182   7 104 179 182 192   0 182  39 192 182 177 191\n 192 182 182 177 183  17 181 183 192 182 183 190 183  47], 정답 [182 182 182 182 182 182 182 182 182 182 182 182 182 182 182 182 182 182\n 182 182 182 182 182 182 182 182 182 182 182 182 183 183]\n(VAL) Batch 285 Loss : 2.6014959812164307, accuracy: 0.25\nVAL : 예측라벨 : [ 17 182 190 183 177 183 183 183 183 196 183 199 183 183 183 183  17  38\n 183 199  40 183 183 183 183 183 199 183 183 180 196  14], 정답 [183 183 183 183 183 183 183 183 183 183 183 183 183 183 183 183 183 183\n 183 183 183 183 183 183 183 183 183 183 183 183 183 183]\n(VAL) Batch 286 Loss : 1.7481592893600464, accuracy: 0.5625\nVAL : 예측라벨 : [178 183 182 183 183 183  60  85 182 183 196 182 179 178 178 183 199 199\n 184 184 184 184  42 184 187   0 189 184  14 184 179 189], 정답 [183 183 183 183 183 183 183 183 183 183 183 183 183 183 183 183 184 184\n 184 184 184 184 184 184 184 184 184 184 184 184 184 184]\n(VAL) Batch 287 Loss : 2.059187173843384, accuracy: 0.40625\nVAL : 예측라벨 : [184 184 186 187 148 184  45 184 184 177 184 184   0  42 184 184 184  79\n 184 184 169 121 184  18 184 184 184  23 184 184 184 199], 정답 [184 184 184 184 184 184 184 184 184 184 184 184 184 184 184 184 184 184\n 184 184 184 184 184 184 184 184 184 184 184 184 184 184]\n(VAL) Batch 288 Loss : 1.967297911643982, accuracy: 0.59375\nVAL : 예측라벨 : [184 187 104 119 157 190 185 119 102 185 185  58  52 185 162 185  12 185\n 185 185 185 149 173  58  93  76 185 190   5 185 185 185], 정답 [184 184 185 185 185 185 185 185 185 185 185 185 185 185 185 185 185 185\n 185 185 185 185 185 185 185 185 185 185 185 185 185 185]\n(VAL) Batch 289 Loss : 2.62817120552063, accuracy: 0.4375\nVAL : 예측라벨 : [ 76  52 185 199 185 185   0 185  58 185 185 185 185 185  78 144 185   3\n  60  15 181  73 186 187 187 192 187 104 196 186 186 180], 정답 [185 185 185 185 185 185 185 185 185 185 185 185 185 185 185 185 185 185\n 185 185 186 186 186 186 186 186 186 186 186 186 186 186]\n(VAL) Batch 290 Loss : 2.486039638519287, accuracy: 0.40625\nVAL : 예측라벨 : [ 13 186 186 186 186  13 192 180 186 140 186  37 184 179   0   6 184 190\n 192 192 186 104 187 192 186 104 184 188 192  45 186 186], 정답 [186 186 186 186 186 186 186 186 186 186 186 186 186 186 186 186 186 186\n 186 186 186 186 186 186 186 186 186 186 186 186 186 186]\n(VAL) Batch 291 Loss : 2.619882106781006, accuracy: 0.3125\nVAL : 예측라벨 : [ 46 186 179 186 104 187 104 140 187 199 184  18 187 187 187  21 186 104\n  42 188  36 187 187 187  42 186 187  45 187 171 187 192], 정답 [186 186 186 186 186 186 187 187 187 187 187 187 187 187 187 187 187 187\n 187 187 187 187 187 187 187 187 187 187 187 187 187 187]\n(VAL) Batch 292 Loss : 2.7184786796569824, accuracy: 0.375\nVAL : 예측라벨 : [187  45 183 199  21  45 199 199 184 188 187 178 187 178 192 186 186 187\n 187  37 187 177 187 192 192  38 130 180 177 188 188 188], 정답 [187 187 187 187 187 187 187 187 187 187 187 187 187 187 187 187 187 187\n 187 187 187 187 187 187 188 188 188 188 188 188 188 188]\n(VAL) Batch 293 Loss : 2.482447862625122, accuracy: 0.3125\nVAL : 예측라벨 : [184  99  21 192 186  38 190  83 191  99 188 187  42 187  47 188 188  45\n 188  21  14 186  60 175 189 187 188 113  45 188 192 188], 정답 [188 188 188 188 188 188 188 188 188 188 188 188 188 188 188 188 188 188\n 188 188 188 188 188 188 188 188 188 188 188 188 188 188]\n(VAL) Batch 294 Loss : 3.4792332649230957, accuracy: 0.21875\nVAL : 예측라벨 : [177 191  42  42 188  38   1 188  36 161 189 189  90 189 189 189 189 188\n  36 189  93 189 189 189 189  90 189  90 134 189 189 189], 정답 [188 188 188 188 188 188 188 188 188 188 189 189 189 189 189 189 189 189\n 189 189 189 189 189 189 189 189 189 189 189 189 189 189]\n(VAL) Batch 295 Loss : 2.301006317138672, accuracy: 0.53125\nVAL : 예측라벨 : [189 189 199 180 189 189  18  48 199  37 189 189  18  18  90 190 189 189\n 189 189 190 185 189 189  26 163  44 189 190 190 190 190], 정답 [189 189 189 189 189 189 189 189 189 189 189 189 189 189 189 189 189 189\n 189 189 189 189 189 189 189 189 189 189 190 190 190 190]\n(VAL) Batch 296 Loss : 2.23549747467041, accuracy: 0.53125\nVAL : 예측라벨 : [191 190 190  98 177 190 190  37 190 190 182 191  41 162 191 190 177 191\n 190 104 190  18  66 182 190 191 190 177 191 182 190 136], 정답 [190 190 190 190 190 190 190 190 190 190 190 190 190 190 190 190 190 190\n 190 190 190 190 190 190 190 190 190 190 190 190 190 190]\n(VAL) Batch 297 Loss : 2.279040575027466, accuracy: 0.375\nVAL : 예측라벨 : [191 192  82 190 191 190 104 190 182 190 188 177 192 142 174 191 191  18\n 191  10 191 191 190 191 191 191 191 190  14 190 191 191], 정답 [190 190 190 190 190 190 190 190 190 190 190 190 190 190 191 191 191 191\n 191 191 191 191 191 191 191 191 191 191 191 191 191 191]\n(VAL) Batch 298 Loss : 1.919407844543457, accuracy: 0.46875\nVAL : 예측라벨 : [191 191 177 191 192 164 192 191 191 191 191 181 191 191  68 191 191 183\n 191 191 191 190 174 190 190 191 191 191  82 191 191 191], 정답 [191 191 191 191 191 191 191 191 191 191 191 191 191 191 191 191 191 191\n 191 191 191 191 191 191 191 191 191 191 191 191 191 191]\n(VAL) Batch 299 Loss : 1.5328766107559204, accuracy: 0.625\nVAL : 예측라벨 : [192 190 175 144 183 192 198 192 192 192 192 192 192 144 187 192 192 192\n 182 192 192 192 192 182 182 192 190 192 192 192 136 192], 정답 [192 192 192 192 192 192 192 192 192 192 192 192 192 192 192 192 192 192\n 192 192 192 192 192 192 192 192 192 192 192 192 192 192]\n(VAL) Batch 300 Loss : 1.952736735343933, accuracy: 0.625\nVAL : 예측라벨 : [192 192  83 182 190 177 191 182 192 192 192 192 178  24 192 192 192  99\n  89 193 193 193 193 104 193 130 192 193 193 193 193 176], 정답 [192 192 192 192 192 192 192 192 192 192 192 192 192 192 192 192 192 192\n 193 193 193 193 193 193 193 193 193 193 193 193 193 193]\n(VAL) Batch 301 Loss : 2.164783477783203, accuracy: 0.5625\nVAL : 예측라벨 : [193 188  27 193 193 193 193 193  31 193  93 144 104 193 136 110 181 193\n  89 193  98 113 193  11 113 193 116 193 193 193 104 193], 정답 [193 193 193 193 193 193 193 193 193 193 193 193 193 193 193 193 193 193\n 193 193 193 193 193 193 193 193 193 193 193 193 193 193]\n(VAL) Batch 302 Loss : 2.6557252407073975, accuracy: 0.5\nVAL : 예측라벨 : [193 113 193 193  13 165  96 194 154 194  92 194 194 194 194 170 195 162\n 194 198 194 198 157 197 194 114 194 194 194 103 194 194], 정답 [193 193 193 193 194 194 194 194 194 194 194 194 194 194 194 194 194 194\n 194 194 194 194 194 194 194 194 194 194 194 194 194 194]\n(VAL) Batch 303 Loss : 2.077127695083618, accuracy: 0.53125\nVAL : 예측라벨 : [194 194 197 132  69 194 114  53 117 170 194  23  31 157 194 197 137 154\n 118  99  13 194 132  57 129 197 162 195 198  12 162 194], 정답 [194 194 194 194 194 194 194 194 194 194 194 194 194 194 194 194 194 194\n 194 194 194 194 195 195 195 195 195 195 195 195 195 195]\n(VAL) Batch 304 Loss : 3.098658323287964, accuracy: 0.21875\nVAL : 예측라벨 : [ 53 105 124 195  61 157  66 198  14 162 100 195 170 197  53 129 194  57\n 195 124  84 198 195 195 194  96   4 198 195 129 118 190], 정답 [195 195 195 195 195 195 195 195 195 195 195 195 195 195 195 195 195 195\n 195 195 195 195 195 195 195 195 195 195 195 195 195 195]\n(VAL) Batch 305 Loss : 3.3766191005706787, accuracy: 0.1875\nVAL : 예측라벨 : [ 96 170 194 195 170 195  78 194 196  23 196 196 196 196  14  14  93 196\n 196  55 196  13  14 183 196 196 196 196  23 183 196 183], 정답 [195 195 195 195 195 195 195 195 196 196 196 196 196 196 196 196 196 196\n 196 196 196 196 196 196 196 196 196 196 196 196 196 196]\n(VAL) Batch 306 Loss : 1.766284704208374, accuracy: 0.46875\nVAL : 예측라벨 : [196 183  30 196  14 196  17 196  14 196 196 196  14 196  14  19 196   7\n  46 196  14 196 196   1  46  14 162  81 198 197  23 198], 정답 [196 196 196 196 196 196 196 196 196 196 196 196 196 196 196 196 196 196\n 196 196 196 196 196 196 196 196 197 197 197 197 197 197]\n(VAL) Batch 307 Loss : 1.9886085987091064, accuracy: 0.40625\nVAL : 예측라벨 : [197  23 137 146 197 198 154 154 195  23 198 198 197  21 154 118 162 118\n 170 197 198 197 154 194  71   2  42 194  53  19 118 197], 정답 [197 197 197 197 197 197 197 197 197 197 197 197 197 197 197 197 197 197\n 197 197 197 197 197 197 197 197 197 197 197 197 197 197]\n(VAL) Batch 308 Loss : 3.1476540565490723, accuracy: 0.1875\nVAL : 예측라벨 : [195 158   2  75 195 154  13 157 157 102 198 118 197 198 198 158 154 198\n 198 158 198   0 198 198 198  96  89  96 198 198 198 154], 정답 [197 197 197 197 197 197 197 197 197 197 197 197 198 198 198 198 198 198\n 198 198 198 198 198 198 198 198 198 198 198 198 198 198]\n(VAL) Batch 309 Loss : 2.796607732772827, accuracy: 0.34375\nVAL : 예측라벨 : [198 198  71 198 154 198 198 198 198  66  89 154  69 198 198 124  78  66\n 165 198 198 197 198  53 195 198  96 198 198  96 199 182], 정답 [198 198 198 198 198 198 198 198 198 198 198 198 198 198 198 198 198 198\n 198 198 198 198 198 198 198 198 198 198 198 198 199 199]\n(VAL) Batch 310 Loss : 2.2567431926727295, accuracy: 0.5\nVAL : 예측라벨 : [ 36  15 199  10 199 199  33  93 199 199  76 182  13  44 199  43  33  69\n 185  45  89 199 180 185 199 199  24 199 199 199  96 199], 정답 [199 199 199 199 199 199 199 199 199 199 199 199 199 199 199 199 199 199\n 199 199 199 199 199 199 199 199 199 199 199 199 199 199]\n(VAL) Batch 311 Loss : 2.9519596099853516, accuracy: 0.40625\nVAL : 예측라벨 : [  6 187 102 199  42  52 185   2  31  99 199 142 199 119 180  36], 정답 [199 199 199 199 199 199 199 199 199 199 199 199 199 199 199 199]\n(VAL) Batch 312 Loss : 3.3959031105041504, accuracy: 0.1875\nepoch 3 Loss/Validate :2.9883692550202148 \nepoch 3 Accuracy/Validate : 0.3111\nEpoch : 4, batch 0\n(Train) Batch 0 Loss : 2.8389344215393066, 맞은 개수 : 42\nEpoch : 4, batch 1\n(Train) Batch 1 Loss : 2.637979507446289, 맞은 개수 : 46\nEpoch : 4, batch 2\n(Train) Batch 2 Loss : 2.811976194381714, 맞은 개수 : 41\nEpoch : 4, batch 3\n(Train) Batch 3 Loss : 2.8038926124572754, 맞은 개수 : 42\nEpoch : 4, batch 4\n(Train) Batch 4 Loss : 3.0519192218780518, 맞은 개수 : 36\nEpoch : 4, batch 5\n(Train) Batch 5 Loss : 2.5494937896728516, 맞은 개수 : 48\nEpoch : 4, batch 6\n(Train) Batch 6 Loss : 2.741966962814331, 맞은 개수 : 41\nEpoch : 4, batch 7\n(Train) Batch 7 Loss : 2.701866865158081, 맞은 개수 : 44\nEpoch : 4, batch 8\n(Train) Batch 8 Loss : 3.030277967453003, 맞은 개수 : 32\nEpoch : 4, batch 9\n(Train) Batch 9 Loss : 2.6997063159942627, 맞은 개수 : 45\nEpoch : 4, batch 10\n(Train) Batch 10 Loss : 2.5461275577545166, 맞은 개수 : 46\nEpoch : 4, batch 11\n(Train) Batch 11 Loss : 2.8995306491851807, 맞은 개수 : 34\nEpoch : 4, batch 12\n(Train) Batch 12 Loss : 2.946516990661621, 맞은 개수 : 38\nEpoch : 4, batch 13\n(Train) Batch 13 Loss : 2.7771544456481934, 맞은 개수 : 48\nEpoch : 4, batch 14\n(Train) Batch 14 Loss : 2.717681646347046, 맞은 개수 : 49\nEpoch : 4, batch 15\n(Train) Batch 15 Loss : 2.4505460262298584, 맞은 개수 : 47\nEpoch : 4, batch 16\n(Train) Batch 16 Loss : 2.7955117225646973, 맞은 개수 : 46\nEpoch : 4, batch 17\n(Train) Batch 17 Loss : 2.7381668090820312, 맞은 개수 : 50\nEpoch : 4, batch 18\n(Train) Batch 18 Loss : 2.7357850074768066, 맞은 개수 : 48\nEpoch : 4, batch 19\n(Train) Batch 19 Loss : 2.7364614009857178, 맞은 개수 : 44\nEpoch : 4, batch 20\n(Train) Batch 20 Loss : 2.5183966159820557, 맞은 개수 : 54\nEpoch : 4, batch 21\n(Train) Batch 21 Loss : 2.553008556365967, 맞은 개수 : 52\nEpoch : 4, batch 22\n(Train) Batch 22 Loss : 2.5668771266937256, 맞은 개수 : 56\nEpoch : 4, batch 23\n(Train) Batch 23 Loss : 2.4093008041381836, 맞은 개수 : 55\nEpoch : 4, batch 24\n(Train) Batch 24 Loss : 2.680527448654175, 맞은 개수 : 46\nEpoch : 4, batch 25\n(Train) Batch 25 Loss : 2.687851667404175, 맞은 개수 : 50\nEpoch : 4, batch 26\n(Train) Batch 26 Loss : 2.8263180255889893, 맞은 개수 : 45\nEpoch : 4, batch 27\n(Train) Batch 27 Loss : 2.8369174003601074, 맞은 개수 : 48\nEpoch : 4, batch 28\n(Train) Batch 28 Loss : 2.622676134109497, 맞은 개수 : 48\nEpoch : 4, batch 29\n(Train) Batch 29 Loss : 2.7185685634613037, 맞은 개수 : 48\nEpoch : 4, batch 30\n(Train) Batch 30 Loss : 2.77268123626709, 맞은 개수 : 48\nEpoch : 4, batch 31\n(Train) Batch 31 Loss : 2.6628730297088623, 맞은 개수 : 43\nEpoch : 4, batch 32\n(Train) Batch 32 Loss : 3.074725389480591, 맞은 개수 : 37\nEpoch : 4, batch 33\n(Train) Batch 33 Loss : 2.864776134490967, 맞은 개수 : 46\nEpoch : 4, batch 34\n(Train) Batch 34 Loss : 2.7447891235351562, 맞은 개수 : 47\nEpoch : 4, batch 35\n(Train) Batch 35 Loss : 2.613053798675537, 맞은 개수 : 50\nEpoch : 4, batch 36\n(Train) Batch 36 Loss : 2.726034641265869, 맞은 개수 : 42\nEpoch : 4, batch 37\n(Train) Batch 37 Loss : 2.919447422027588, 맞은 개수 : 42\nEpoch : 4, batch 38\n(Train) Batch 38 Loss : 2.665210008621216, 맞은 개수 : 43\nEpoch : 4, batch 39\n(Train) Batch 39 Loss : 3.001530170440674, 맞은 개수 : 35\nEpoch : 4, batch 40\n(Train) Batch 40 Loss : 2.7705979347229004, 맞은 개수 : 41\nEpoch : 4, batch 41\n(Train) Batch 41 Loss : 2.7497284412384033, 맞은 개수 : 44\nEpoch : 4, batch 42\n(Train) Batch 42 Loss : 2.8431766033172607, 맞은 개수 : 39\nEpoch : 4, batch 43\n(Train) Batch 43 Loss : 2.3307087421417236, 맞은 개수 : 53\nEpoch : 4, batch 44\n(Train) Batch 44 Loss : 2.611860752105713, 맞은 개수 : 51\nEpoch : 4, batch 45\n(Train) Batch 45 Loss : 2.4362785816192627, 맞은 개수 : 55\nEpoch : 4, batch 46\n(Train) Batch 46 Loss : 2.7126576900482178, 맞은 개수 : 45\nEpoch : 4, batch 47\n(Train) Batch 47 Loss : 2.709615707397461, 맞은 개수 : 46\nEpoch : 4, batch 48\n(Train) Batch 48 Loss : 2.8720827102661133, 맞은 개수 : 49\nEpoch : 4, batch 49\n(Train) Batch 49 Loss : 2.8498356342315674, 맞은 개수 : 41\nEpoch : 4, batch 50\n(Train) Batch 50 Loss : 2.7790274620056152, 맞은 개수 : 39\nEpoch : 4, batch 51\n(Train) Batch 51 Loss : 2.484339714050293, 맞은 개수 : 52\nEpoch : 4, batch 52\n(Train) Batch 52 Loss : 2.66825270652771, 맞은 개수 : 41\nEpoch : 4, batch 53\n(Train) Batch 53 Loss : 2.789659261703491, 맞은 개수 : 41\nEpoch : 4, batch 54\n(Train) Batch 54 Loss : 3.0426247119903564, 맞은 개수 : 42\nEpoch : 4, batch 55\n(Train) Batch 55 Loss : 2.674487590789795, 맞은 개수 : 50\nEpoch : 4, batch 56\n(Train) Batch 56 Loss : 2.5689544677734375, 맞은 개수 : 48\nEpoch : 4, batch 57\n(Train) Batch 57 Loss : 2.6395211219787598, 맞은 개수 : 44\nEpoch : 4, batch 58\n(Train) Batch 58 Loss : 2.605675458908081, 맞은 개수 : 50\nEpoch : 4, batch 59\n(Train) Batch 59 Loss : 2.4887149333953857, 맞은 개수 : 52\nEpoch : 4, batch 60\n(Train) Batch 60 Loss : 2.749142646789551, 맞은 개수 : 50\nEpoch : 4, batch 61\n(Train) Batch 61 Loss : 2.657460927963257, 맞은 개수 : 47\nEpoch : 4, batch 62\n(Train) Batch 62 Loss : 2.485633373260498, 맞은 개수 : 56\nEpoch : 4, batch 63\n(Train) Batch 63 Loss : 2.6139211654663086, 맞은 개수 : 47\nEpoch : 4, batch 64\n(Train) Batch 64 Loss : 3.0761282444000244, 맞은 개수 : 37\nEpoch : 4, batch 65\n(Train) Batch 65 Loss : 2.783940553665161, 맞은 개수 : 44\nEpoch : 4, batch 66\n(Train) Batch 66 Loss : 2.665475845336914, 맞은 개수 : 52\nEpoch : 4, batch 67\n(Train) Batch 67 Loss : 2.6141483783721924, 맞은 개수 : 52\nEpoch : 4, batch 68\n(Train) Batch 68 Loss : 2.706031322479248, 맞은 개수 : 44\nEpoch : 4, batch 69\n(Train) Batch 69 Loss : 2.8029794692993164, 맞은 개수 : 44\nEpoch : 4, batch 70\n(Train) Batch 70 Loss : 2.952523708343506, 맞은 개수 : 32\nEpoch : 4, batch 71\n(Train) Batch 71 Loss : 2.551602840423584, 맞은 개수 : 49\nEpoch : 4, batch 72\n(Train) Batch 72 Loss : 2.8181416988372803, 맞은 개수 : 44\nEpoch : 4, batch 73\n(Train) Batch 73 Loss : 2.892864227294922, 맞은 개수 : 42\nEpoch : 4, batch 74\n(Train) Batch 74 Loss : 2.6717443466186523, 맞은 개수 : 48\nEpoch : 4, batch 75\n(Train) Batch 75 Loss : 2.725856065750122, 맞은 개수 : 42\nEpoch : 4, batch 76\n(Train) Batch 76 Loss : 2.659898042678833, 맞은 개수 : 45\nEpoch : 4, batch 77\n(Train) Batch 77 Loss : 2.674570322036743, 맞은 개수 : 42\nEpoch : 4, batch 78\n(Train) Batch 78 Loss : 2.757946729660034, 맞은 개수 : 43\nEpoch : 4, batch 79\n(Train) Batch 79 Loss : 2.952545642852783, 맞은 개수 : 40\nEpoch : 4, batch 80\n(Train) Batch 80 Loss : 2.576462745666504, 맞은 개수 : 42\nEpoch : 4, batch 81\n(Train) Batch 81 Loss : 2.822268486022949, 맞은 개수 : 47\nEpoch : 4, batch 82\n(Train) Batch 82 Loss : 2.6731231212615967, 맞은 개수 : 48\nEpoch : 4, batch 83\n(Train) Batch 83 Loss : 2.6783103942871094, 맞은 개수 : 49\nEpoch : 4, batch 84\n(Train) Batch 84 Loss : 2.5773773193359375, 맞은 개수 : 48\nEpoch : 4, batch 85\n(Train) Batch 85 Loss : 2.5216078758239746, 맞은 개수 : 44\nEpoch : 4, batch 86\n(Train) Batch 86 Loss : 2.7137179374694824, 맞은 개수 : 46\nEpoch : 4, batch 87\n(Train) Batch 87 Loss : 2.4476053714752197, 맞은 개수 : 55\nEpoch : 4, batch 88\n(Train) Batch 88 Loss : 2.76906681060791, 맞은 개수 : 44\nEpoch : 4, batch 89\n(Train) Batch 89 Loss : 2.8861660957336426, 맞은 개수 : 43\nEpoch : 4, batch 90\n(Train) Batch 90 Loss : 2.7042558193206787, 맞은 개수 : 46\nEpoch : 4, batch 91\n(Train) Batch 91 Loss : 2.890376329421997, 맞은 개수 : 38\nEpoch : 4, batch 92\n(Train) Batch 92 Loss : 2.4598240852355957, 맞은 개수 : 51\nEpoch : 4, batch 93\n(Train) Batch 93 Loss : 2.7257213592529297, 맞은 개수 : 44\nEpoch : 4, batch 94\n(Train) Batch 94 Loss : 2.625150680541992, 맞은 개수 : 47\nEpoch : 4, batch 95\n(Train) Batch 95 Loss : 2.7756333351135254, 맞은 개수 : 50\nEpoch : 4, batch 96\n(Train) Batch 96 Loss : 2.640601873397827, 맞은 개수 : 53\nEpoch : 4, batch 97\n(Train) Batch 97 Loss : 2.8617429733276367, 맞은 개수 : 41\nEpoch : 4, batch 98\n(Train) Batch 98 Loss : 2.791072130203247, 맞은 개수 : 45\nEpoch : 4, batch 99\n(Train) Batch 99 Loss : 2.6932120323181152, 맞은 개수 : 50\nEpoch : 4, batch 100\n(Train) Batch 100 Loss : 2.9798755645751953, 맞은 개수 : 36\nEpoch : 4, batch 101\n(Train) Batch 101 Loss : 2.457078456878662, 맞은 개수 : 55\nEpoch : 4, batch 102\n(Train) Batch 102 Loss : 2.909984827041626, 맞은 개수 : 47\nEpoch : 4, batch 103\n(Train) Batch 103 Loss : 2.639021158218384, 맞은 개수 : 42\nEpoch : 4, batch 104\n(Train) Batch 104 Loss : 2.771347999572754, 맞은 개수 : 50\nEpoch : 4, batch 105\n(Train) Batch 105 Loss : 2.820366859436035, 맞은 개수 : 44\nEpoch : 4, batch 106\n(Train) Batch 106 Loss : 2.68068790435791, 맞은 개수 : 44\nEpoch : 4, batch 107\n(Train) Batch 107 Loss : 2.7837471961975098, 맞은 개수 : 46\nEpoch : 4, batch 108\n(Train) Batch 108 Loss : 2.642620325088501, 맞은 개수 : 46\nEpoch : 4, batch 109\n(Train) Batch 109 Loss : 2.8229434490203857, 맞은 개수 : 46\nEpoch : 4, batch 110\n(Train) Batch 110 Loss : 2.813530921936035, 맞은 개수 : 41\nEpoch : 4, batch 111\n(Train) Batch 111 Loss : 2.5534636974334717, 맞은 개수 : 43\nEpoch : 4, batch 112\n(Train) Batch 112 Loss : 2.701843500137329, 맞은 개수 : 49\nEpoch : 4, batch 113\n(Train) Batch 113 Loss : 2.5037453174591064, 맞은 개수 : 46\nEpoch : 4, batch 114\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# 시각화 해보기 \nplt.plot(epoch_train_losses, label='Train')\nplt.plot(epoch_val_losses,label = 'Val')\nplt.xlabel('Epoch')\nplt.ylabel(\"Train Loss\")\nplt.title('Train Loss')\nplt.legend()\nplt.grid(True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T13:21:37.305540Z","iopub.execute_input":"2025-12-04T13:21:37.305989Z","iopub.status.idle":"2025-12-04T13:21:37.633166Z","shell.execute_reply.started":"2025-12-04T13:21:37.305933Z","shell.execute_reply":"2025-12-04T13:21:37.632168Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABr/klEQVR4nO3dd1xVhf/H8de9bBAU90Jxb1ykOVBxj0xtmIqrcpSa62tWvyy1NM3KnSMbZmWWDTMzjVRcOHDvvfcWFGWe3x8ESS5QuAcu7+fjcR8P7+Hccz/3E8Gbsz4WwzAMREREROyE1ewCRERERNKSwo2IiIjYFYUbERERsSsKNyIiImJXFG5ERETErijciIiIiF1RuBERERG7onAjIiIidkXhRkREROyKwo2IZDjdu3fH19fX7DJEJJNSuBGRFLNYLCl6hISEmF1qMiEhIVgsFn766SezSxERG3A0uwARyTy++eabZM/nzJlDcHDwXcvLlSv3WO8za9Ys4uPjH2sbIpJ1KdyISIp17tw52fP169cTHBx81/L/ioyMxN3dPcXv4+Tk9Ej1iYiADkuJSBpr0KABFStWZPPmzdSrVw93d3f+7//+D4DffvuNVq1aUbBgQVxcXChRogTvv/8+cXFxybbx33Nujh07hsVi4eOPP+azzz6jRIkSuLi48MQTTxAWFpZmtR85coTnn3+enDlz4u7uzpNPPskff/xx13pTpkyhQoUKuLu74+3tjb+/P3Pnzk36ekREBAMHDsTX1xcXFxfy5s1LkyZN2LJlS5rVKiL3pz03IpLmLl++TIsWLejQoQOdO3cmX758AMyePZts2bIxePBgsmXLxvLly3n33XcJDw/no48+euh2586dS0REBL1798ZisTBu3DieeeYZjhw58th7e86fP0/t2rWJjIykf//+5MqVi6+//pqnn36an376iXbt2gEJh8z69+/Pc889x4ABA7h9+zY7duxgw4YNdOrUCYBXXnmFn376iX79+lG+fHkuX77MmjVr2Lt3L9WqVXusOkUkBQwRkUfUt29f478/RurXr28AxowZM+5aPzIy8q5lvXv3Ntzd3Y3bt28nLevWrZtRtGjRpOdHjx41ACNXrlzGlStXkpb/9ttvBmD8/vvvD6xzxYoVBmDMnz//vusMHDjQAIzVq1cnLYuIiDCKFStm+Pr6GnFxcYZhGEabNm2MChUqPPD9smfPbvTt2/eB64hI+tFhKRFJcy4uLrz44ot3LXdzc0v6d0REBJcuXSIgIIDIyEj27dv30O2+8MILeHt7Jz0PCAgAEg4nPa7FixdTo0YN6tatm7QsW7Zs9OrVi2PHjrFnzx4AcuTIwalTpx54OCxHjhxs2LCBM2fOPHZdIpJ6CjcikuYKFSqEs7PzXct3795Nu3btyJ49O15eXuTJkyfpZOTr168/dLtFihRJ9jwx6Fy9evWxaz5+/DhlypS5a3nilV/Hjx8H4I033iBbtmzUqFGDUqVK0bdvX9auXZvsNePGjWPXrl34+PhQo0YNRowYkSYBTERSRuFGRNLcnXtoEl27do369euzfft23nvvPX7//XeCg4P58MMPAVJ06beDg8M9lxuG8XgFp0K5cuXYv38/8+bNo27duvz888/UrVuX4cOHJ63Tvn17jhw5wpQpUyhYsCAfffQRFSpU4M8//7RZnSJZmcKNiNhESEgIly9fZvbs2QwYMICnnnqKxo0bJzvMZKaiRYuyf//+u5YnHi4rWrRo0jIPDw9eeOEFvvrqK06cOEGrVq0YPXo0t2/fTlqnQIEC9OnThwULFnD06FFy5crF6NGj0/+DiIjCjYjYRuJelzv3skRHRzNt2jSzSkqmZcuWbNy4kXXr1iUtu3nzJp999hm+vr6UL18eSLgS7E7Ozs6UL18ewzCIiYkhLi7urkNsefPmpWDBgkRFRaX/BxERXQouIrZRu3ZtvL296datG/3798disfDNN9/Y9JDSzz//fM8Tl7t168abb77J999/T4sWLejfvz85c+bk66+/5ujRo/z8889YrQl/CzZt2pT8+fNTp04d8uXLx969e5k6dSqtWrXC09OTa9euUbhwYZ577jkqV65MtmzZ+PvvvwkLC+OTTz6x2WcVycoUbkTEJnLlysWiRYv43//+x7Bhw/D29qZz5840atSIZs2a2aSGefPm3XN5gwYNqFu3LqGhobzxxhtMmTKF27dv4+fnx++//06rVq2S1u3duzffffcd48eP58aNGxQuXJj+/fszbNgwANzd3enTpw9//fUXv/zyC/Hx8ZQsWZJp06bx6quv2uRzimR1FsOWfzaJiIiIpDOdcyMiIiJ2ReFGRERE7IrCjYiIiNgVhRsRERGxKwo3IiIiYlcUbkRERMSuZLn73MTHx3PmzBk8PT2xWCxmlyMiIiIpYBgGERERFCxYMOmmmveT5cLNmTNn8PHxMbsMEREReQQnT56kcOHCD1wny4UbT09PIKE5Xl5eabrtmJgY/vrrL5o2bYqTk1Oablv+pT7bhvpsG+qz7ajXtpFefQ4PD8fHxyfp9/iDZLlwk3goysvLK13Cjbu7O15eXvofJx2pz7ahPtuG+mw76rVtpHefU3JKiU4oFhEREbuicCMiIiJ2ReFGRERE7EqWO+dGREQkvcTFxRETE2N2GaaKiYnB0dGR27dvExcXl6rXOjs7P/Qy75RQuBEREXlMhmFw7tw5rl27ZnYppjMMg/z583Py5MlU30/OarVSrFgxnJ2dH6sGhRsREZHHlBhs8ubNi7u7e5a+SWx8fDw3btwgW7ZsqdoLk3iT3bNnz1KkSJHH6qHCjYiIyGOIi4tLCja5cuUyuxzTxcfHEx0djaura6oPMeXJk4czZ84QGxv7WJeR64RiERGRx5B4jo27u7vJlWR+iYejUnuuzn8p3IiIiKSBrHwoKq2kVQ8VbkRERMSuKNyIiIhImvD19WXSpElml6FwIyIiktVYLJYHPkaMGPFI2w0LC6Nnz55pW+wj0NVSaSj08GVi482uQkRE5MHOnj2b9O8ffviBd999l/379ycty5YtW9K/DcMgLi4OR8eHR4Y8efIQHx9PeHh42hacStpzk0aOXLzBi19vZtRWB37YdIqYOKUcERHJmPLnz5/0yJ49OxaLJen5vn378PT05M8//6R69eq4uLiwZs0aDh8+TJs2bciXLx/ZsmXjiSee4O+//0623f8elrJYLHz++ee0a9cOd3d3SpUqxcKFC9P98yncpJHT126RJ5sLV6MtDPttD4Efh/Bj2EmFHBGRLMYwDCKjY015GIaRZp/jzTffZOzYsezduxc/Pz9u3LhBy5YtWbZsGVu3bqV58+a0bt2aEydOPHA7I0eOpH379uzYsYOWLVsSFBTElStX0qzOe9FhqTQSUCoPfw+qy7tz/mLNJTdOXb3F0J938GnIIV5rWIq2VQri6KAsKSJi727FxFH+3aWmvPee95rh7pw2v9rfe+89mjRpkvQ8Z86cVK5cOen5+++/z6+//srChQvp16/ffbfTvXt3OnbsCMAHH3zA5MmT2bhxI82bN0+TOu9Fv23TkKuTAw0KGCwbFMCwVuXInc2Z45cjGTJ/O00mrGLB1tPExaddqhYREUkv/v7+yZ7fuHGDIUOGUK5cOXLkyEG2bNnYu3fvQ/fc+Pn5Jf3bw8MDLy8vLly4kC41J9Kem3Tg5uxAj4DidKpZhG/WHWfmqiMcvXSTgT9sY8rygwxoXJpWlQrgYNUNn0RE7I2bkwN73mtm2nunFQ8Pj2TPhwwZQnBwMB9//DElS5bEzc2N5557jujo6Adu579jFCwWC/Hx6XvKhsJNOnJ3dqR3/RJ0frIoX687xmerjnD44k36f7+VKcsOMrBxaVpUzI9VIUdExG5YLJY0OzSUkaxdu5bu3bvTrl07IGFPzrFjx8wt6j50WMoGPFwc6dOgJKuHBvK/JqXxcnXk4IUb9J27hZaTV7Nk17k0PQlMREQkrZUqVYpffvmFbdu2sX37djp16pTue2AelcKNDXm6OvFao1KsebMhAxuXwtPFkX3nInjl2820mryG4D3nFXJERCRDGj9+PN7e3tSuXZvWrVvTrFkzqlWrZnZZ92R/+80yAS9XJwY2Ls2LtYvxxZojfLn2GHvOhtNzziYqFcrOoCalCCyTV0PYREQk3XXv3p3u3bsnPW/QoME9/9D29fVl+fLlyZb17ds32fNjx44lu4nfvbZz7dq1xy/6IbTnxkTZ3Z0Y3LQMq4cG0qdBCdydHdh5+jovzd5E22mhhOy/oD05IiIiqaRwkwF4ezgztHlZVg8NpHf94rg5ObD95DW6fxXGs9NDWXPwkkKOiIhICincZCC5srnwVotyrH4jkJ4BxXBxtLLlxDU6f7GB9jPXEXr4ktklioiIZHgKNxlQ7mwuvN2qPKuHBvJiHV+cHa2EHbtKp1kb6PDZOjYcuWx2iSIiIhmWwk0GltfLleGtK7Dq9UC61SqKs4OV9Ueu8MJn6wn6fD2bj6fvbA4REZHMSOEmE8if3ZWRbSoS8noDOj9ZBCcHC2sPXebZ6evo+uVGtp64anaJIiIiGYbCTSZSMIcbo9pWYsWQBnSs4YOj1cKqAxdpNy2UF7/ayI5T18wuUURExHQKN5lQYW93xjzjx4ohDWjvXxgHq4UV+y/y9NS19Pg6jF2nr5tdooiIiGkUbjIxn5zujHuuMssG1+fZaoWxWuDvvRd4asoaen+zib1nw80uUURExOYUbuyAb24PPmlfmb8H16dtlYJYLLB093laTFpNn+82s/9chNklioiInWnQoAEDBw40u4x7UrixI8XzZGNih6oED6pH68oJIWfxznM0n7SKfnO3cOiCQo6IiEDr1q1p3rz5Pb+2evVqLBYLO3bssHFVacfUcDNixAgsFkuyR9myZR/4mvnz51O2bFlcXV2pVKkSixcvtlG1mUfJvJ5M6ViVpQPr0apSAQwDFu04S5MJqxgwbyuHL94wu0QRETHRyy+/THBwMKdOnbrra1999RX+/v74+fmZUFnaMH3PTYUKFTh79mzSY82aNfddNzQ0lI4dO/Lyyy+zdetW2rZtS9u2bdm1a5cNK848Sufz5NOgavw5IIDmFfJjGPDbtjM0Gb+SwT9u49ilm2aXKCIiJnjqqafIkycPs2fPTrb8xo0bzJ8/n7Zt29KxY0cKFSqEu7s7lSpV4vvvvzen2EdgerhxdHQkf/78SY/cuXPfd91JkybRvHlzXn/9dcqVK8f7779PtWrVmDp1qg0rznzKFfBiRpfqLHqtLo3L5SPegF+2nKbR+JW8Pn87Jy5Hml2iiIj9MAyIvmnOI4VzCB0dHenatSuzZ89ONrtw/vz5xMXF0blzZ6pXr84ff/zBrl276NWrF126dGHjxo3p1bU05Wh2AQcPHqRgwYK4urpSq1YtxowZQ5EiRe657rp16xg8eHCyZc2aNWPBggX33X5UVBRRUVFJzxPHsMfExBATE/P4H+AOidtL6+2mlTJ53ZneqTI7T19n8vLDhBy4xPzNp/h162meqVqQPg2KUyiHm9llPlRG77O9UJ9tQ322nfTqdUxMDIZhEB8fT3x8PETfxDq2cJq+R0rFv3kKnD1StG737t356KOPWLFiBQ0aNAASDkk988wz+Pj4JPt927dvX5YsWcIPP/yAv79/0vLEz32nxLB0r689tP74eAzDICYmBgcHh2RfS81/N1PDTc2aNZk9ezZlypTh7NmzjBw5koCAAHbt2oWnp+dd6587d458+fIlW5YvXz7OnTt33/cYM2YMI0eOvGv5X3/9hbu7++N/iHsIDg5Ol+2mpXa5oGpF+POklX3Xrfy4+TQ/bznFk3kNmhSKx9vF7AofLjP02R6oz7ahPttOWvc68QjEjRs3iI6OhphIcqTpO6RceEQEOMWlaN2CBQtSo0YNPvvsM6pVq8aRI0dYvXo1v//+O1evXmX8+PH8+uuvnD17lpiYGKKionB2dk7aSRAbG0t0dHTS8/+KiEj9RSzR0dHcunWLVatWERsbm+xrkZEpP8pgarhp0aJF0r/9/PyoWbMmRYsW5ccff+Tll19Ok/d46623kqXP8PBwfHx8aNq0KV5eXmnyHoliYmIIDg6mSZMmODk5pem200sfYMuJa0xafojQw1dYe97CxksOvOBfmN71ipHfy9XsEu+SGfucGanPtqE+20569fr27ducPHmSbNmy4erqCoZnwh4UE3g5uYPFkuL1e/bsyYABA5g5cyY//fQTJUqUoEWLFowbN46ZM2cyfvx4KlWqhIeHB4MGDSI+Pj7pd6ejoyPOzs53/S41DIOIiAg8PT2xpKIWSOilm5sb9erVS+jlHe4Xou7F9MNSd8qRIwelS5fm0KFD9/x6/vz5OX/+fLJl58+fJ3/+/PfdpouLCy4ud++GcHJySrcfJOm57fRQs0Qe5pbIw8ajV5gQfIB1Ry7z7YaT/Lj5NJ1qFKFPgxLkzYAhJ7P1ObNSn21DfbadtO51XFwcFosFq9WK1frPqawOdx99yIg6dOjAoEGDmDdvHt988w2vvvoqDg4OhIaG0qZNG7p27QokHC46ePAg5cuX//czQtLnvlPioah7fe1hrFYrFovlnv+NUvPfzPQTiu9048YNDh8+TIECBe759Vq1arFs2bJky4KDg6lVq5YtyrN7NYrl5PteTzK3Z01q+OYkOjae2aHHCBi3glGL9nAxIurhGxERkUwjW7ZsvPDCC7z11lucPXuW7t27A1CqVCmCg4MJDQ1l79699O7d+66dCxmZqeFmyJAhrFy5kmPHjhEaGkq7du1wcHCgY8eOAHTt2pW33noraf0BAwawZMkSPvnkE/bt28eIESPYtGkT/fr1M+sj2KXaJXLzQ+8n+a5HTaoX9SYqNp7P1xwlYNxyxizey+UbCjkiIvbi5Zdf5urVqzRr1oyCBQsCMGzYMKpVq0azZs1o0KAB+fPnp23btuYWmgqmHpY6deoUHTt25PLly+TJk4e6deuyfv168uTJA8CJEyeS7dKqXbs2c+fOZdiwYfzf//0fpUqVYsGCBVSsWNGsj2C3LBYLdUrmpnaJXKw6eIkJwQfYdvIaM1cd4Zv1x+le25eeAcXx9nA2u1QREXkMtWrVSnY5OEDOnDkfeCUyQEhISPoV9ZhMDTfz5s174Nfv1bjnn3+e559/Pp0qkv+yWCzUL52HeqVyE7L/IuODD7Dz9HWmhRxmzrrjvFjHlx51i5PdXecKiIhIxpChzrmRjMtisRBYNi8L+9Xh867+lC/gxY2oWKYsP0TdD5czIfgA12/pPh0iImI+hRtJFYvFQuPy+fijf11mdK5O2fyeRETFMmnZQQI+XM7kZQeJuK2QIyIi5lG4kUdisVhoXjE/i/sHMC2oGqXzZSP8dizjgw8QMG4Fn644xI2o2IdvSEREJI0p3MhjsVottKxUgCUD6jGlY1VK5PHgWmQMHy3dT8CHy5mx8jCR0Qo5ImL//ntSrqReWvVQ4UbShNVqoXXlgvw1qD6TOlSheG4PrkbGMPbPfQR8uIJZq45wKzpltwQXEclMEm8ul5rxAHJv0dHRAHfNlUqtDHWHYsn8HKwW2lQpRKtKBfht2xkmLz/I8cuRjF68l5mrjvBqgxIE1SyCq9PjfeOKiGQUDg4O5MiRgwsXLgDg7u6e6rED9iQ+Pp7o6Ghu376dqjsUx8fHc/HiRdzd3XF0fLx4onAj6cLRwcqz1QvzdJWC/Lr1NJOXHeTU1Vu8v2gPM1cepm9gSV54wkchR0TsQuIYoMSAk5UZhsGtW7dwc3NLdcizWq0UKVLkscOhwo2kKycHK+39fWhXtRA/bz7FlOWHOH3tFsMX7mbGysP0CSxJe//CuDgq5IhI5mWxWChQoAB58+YlJiZrXzEaExPDqlWrqFevXqpneDk7O6d6HtW9KNyITTg5WOlQowjPVCvMj5tO8umKQ5y9fpt3FuxiRshh+jUsyXPVC+PkoNPARCTzcnBweOzzRTI7BwcHYmNjcXV1NW0YrH6TiE05O1rp/GRRQl5vwHttKpDPy4XT127x1i87Cfw4hB/DThITF292mSIikokp3IgpXBwd6FrLl5WvB/LuU+XJ4+nCqau3GPrzDhqPX8lPm08Rq5AjIiKPQOFGTOXq5MBLdYux6vVAhrUqR+5szhy/HMmQ+dtpMmEVC7aeJi5e944QEZGUU7iRDMHN2YEeAcVZNTSQt1qUxdvdiaOXbjLwh200nbCShdvPKOSIiEiKKNxIhuLu7Ejv+iVY/UZDXm9WhhzuThy+eJP+32+l+cRV/LHjLPEKOSIi8gC6WkoypGwujvQNLEnXWkWZvfYYs1Yf4eCFG/Sdu4Uy+bJRJ7uFFrrVuYiI3IP23EiG5unqxGuNSrH6jYYMbFwKTxdH9p+/wZcHHGgzbT3Be85rnouIiCSjcCOZQnY3JwY2Ls2aNxrSt0FxXBwM9p6LoOecTTw9dS3L9ynkiIhIAoUbyVSyuzsxsFFJhleN45V6xXB3dmDn6eu8NHsTbaeFErL/gkKOiEgWp3AjmZKHE/yvSSlWDw2kd/3iuDk5sP3kNbp/Fcaz00NZc/CSQo6ISBalcCOZWq5sLrzVohyrhgbSo24xXBytbDlxjc5fbKD9zHWEHr5kdokiImJjCjdiF/J4ujDsqfKsHhrIi3V8cXa0EnbsKp1mbaDDZ+vYcOSy2SWKiIiNKNyIXcnr5crw1hVY9Xog3WoVxdnByvojV3jhs/UEfb6eTceumF2iiIikM4UbsUv5s7sysk1FQl5vQFDNIjg5WFh76DLPzVhHly82sOXEVbNLFBGRdKJwI3atYA43RrerxIohDehYwwdHq4XVBy/xzLRQXvxqIztOXTO7RBERSWMKN5IlFPZ2Z8wzfqwY0oD2/oVxsFpYsf8iT09dS4+vw9h1+rrZJYqISBpRuJEsxSenO+Oeq8yywfV5tlphrBb4e+8Fnpqyht7fbGLv2XCzSxQRkcekcCNZkm9uDz5pX5m/B9enbZWCWCywdPd5WkxaTZ/vNrP/XITZJYqIyCNSuJEsrXiebEzsUJXgQfVoXTkh5CzeeY7mk1bRb+4WDl1QyBERyWwUbkSAknk9mdKxKksH1qNVpQIYBizacZYmE1YxYN5WDl+8YXaJIiKSQgo3Inconc+TT4Oq8eeAAJpVyIdhwG/bztBk/EoG/7iNY5duml2iiIg8hMKNyD2UK+DFzC7+LHqtLo3L5SPegF+2nKbR+JW8Pn87Jy5Hml2iiIjch8KNyANULJSdz7v5s7BfHRqWzUtcvMH8zado+EkIb/68g1NXFXJERDIahRuRFPArnIMvuz/Br31qU690HmLjDeaFnSTw4xDe/nUnZ67dMrtEERH5h8KNSCpULeLNnJdq8POrtahbMjcxcQbfbThBg49CePe3XZy7ftvsEkVEsjyFG5FHUL1oTr7tUZMfe9eiVvFcRMfFM2fdcep9tIIRC3dzIVwhR0TELAo3Io+hRrGcfN/rSeb2rEkN35xEx8YzO/QYAeNWMGrRHi5GRJldoohIlqNwI5IGapfIzQ+9n+Tbl2tSvag3UbHxfL7mKAHjljNm8V4u31DIERGxFYUbkTRisVioWyo3P71Si69fqkEVnxzcjoln5qojBIxbwYdL9nH1ZrTZZYqI2D2FG5E0ZrFYqF86D7/2qc1X3Z+gUqHsREbHMT3kMHU/XM4nf+3nemSM2WWKiNitDBNuxo4di8ViYeDAgQ9cb+LEiZQpUwY3Nzd8fHwYNGgQt2/r5E3JeCwWC4Fl87KwXx0+7+pP+QJe3IyOY8ryQ9T9cDkTgg9w/ZZCjohIWnM0uwCAsLAwZs6ciZ+f3wPXmzt3Lm+++SZffvkltWvX5sCBA3Tv3h2LxcL48eNtVK1I6lgsFhqXz0ejcnlZuvs8E/8+wL5zEUxadpCv1h6lR0BxXqzji6erk9mliojYBdP33Ny4cYOgoCBmzZqFt7f3A9cNDQ2lTp06dOrUCV9fX5o2bUrHjh3ZuHGjjaoVeXQWi4XmFfOzuH8A04KqUTpfNsJvxzI++AAB41bw6YpD3IiKNbtMEZFMz/Q9N3379qVVq1Y0btyYUaNGPXDd2rVr8+2337Jx40Zq1KjBkSNHWLx4MV26dLnva6KiooiK+vdKlfDwcABiYmKIiUnbQwKJ20vr7Upy9tDnJmVz06h0Lv7cfZ7Jyw9z5NJNPlq6n89XH6FHXV861/TB3dnc/z3toc+ZgfpsO+q1baRXn1OzPYthGEaavnsqzJs3j9GjRxMWFoarqysNGjSgSpUqTJw48b6vmTx5MkOGDMEwDGJjY3nllVeYPn36fdcfMWIEI0eOvGv53LlzcXd3T4uPIfJY4g3YcsnC0lNWLty2AJDN0aBRoXjq5jNwdjC5QBGRDCAyMpJOnTpx/fp1vLy8HriuaeHm5MmT+Pv7ExwcnHSuzcPCTUhICB06dGDUqFHUrFmTQ4cOMWDAAHr27Mk777xzz9fca8+Nj48Ply5demhzUismJobg4GCaNGmCk5POn0gv9trn2Lh4ft9xjqkhhzlxJWFWVe5szvQKKEbHJwrj6mTblGOvfc5o1GfbUa9tI736HB4eTu7cuVMUbkzb771582YuXLhAtWrVkpbFxcWxatUqpk6dSlRUFA4OyX+Yv/POO3Tp0oUePXoAUKlSJW7evEmvXr14++23sVrvPoXIxcUFFxeXu5Y7OTml2zd3em5b/mVvfXZygvY1itKuug+/bj3N5GUHOXX1Fh/8uZ/P1xyjb2BJXnjCx+Yhx976nFGpz7ajXttGWvc5NdsyLdw0atSInTt3Jlv24osvUrZsWd544427gg0k7JL6b4BJXM/Eo2siacrJwUp7fx/aVS3Ez5tPMWX5IU5fu8XwhbuZsfIwfQJL0t6/MC6OOl4lInIvpoUbT09PKlasmGyZh4cHuXLlSlretWtXChUqxJgxYwBo3bo148ePp2rVqkmHpd555x1at259zzAkkpk5OVjpUKMIz1QrzI+bTvLpikOcvX6bdxbsYkbIYfo1LMlz1Qvj5GD6RY8iIhmK6VdLPciJEyeS7akZNmwYFouFYcOGcfr0afLkyUPr1q0ZPXq0iVWKpC9nRyudnyzKc9UL80PYSaaFJOzJeeuXnXy64hD9G5aiXbVCCjkiIv/IUOEmJCTkgc8dHR0ZPnw4w4cPt11RIhmEq5MD3Wr78sITPszdcIJpIYc5dfUWQ3/ewachh3itYSnaVimIo0KOiGRx+ikoksm4OjnwUt1irB4ayLBW5cjl4czxy5EMmb+dJhNWsWDraeLidQ6aiGRdCjcimZSbswM9Aoqz+o1A3mpRFm93J45eusnAH7bRdMJKFm4/o5AjIlmSwo1IJufu7Ejv+iVY/UZDXm9WhhzuThy+eJP+32+l+cRV/LHjLPEKOSKShSjciNiJbC6O9A0syeqhgfyvSWm8XB05eOEGfeduoeXk1SzZpZAjIlmDwo2InfF0deK1RqVY/UZDBjYuhaeLI/vORfDKt1t4asoagvec132hRMSuKdyI2Knsbk4MbFyaNW805LWGJcnm4sies+H0nLOJp6euZfk+hRwRsU8KNyJ2Lru7E/9rWobVQwPp06AE7s4O7Dx9nZdmb6LttFBC9l9QyBERu6JwI5JFeHs4M7R5WVYPDaR3/eK4OTmw/eQ1un8VxrPTQ1lz8JJCjojYBYUbkSwmVzYX3mpRjlVDA+lRtxgujla2nLhG5y820H7mOkIPXzK7RBGRx6JwI5JF5fF0YdhT5Vk9NJAX6/ji7Ggl7NhVOs3aQIfP1rHx2BWzSxQReSQKNyJZXF4vV4a3rsCq1wPpVqsozg5W1h+5QtAXm/h0j5XNx6+aXaKISKoo3IgIAPmzuzKyTUVCXm9AUM0iODlYOHDdSofPw+jyxQa2nFDIEZHMQeFGRJIpmMON0e0qETywLrXyxuNotbD64CWemRbKi19tZMepa2aXKCLyQAo3InJPhXK40aFEPH8NrEN7/8I4WC2s2H+Rp6eupcfXYew6fd3sEkVE7knhRkQeyMfbnXHPVWbZ4Po8U60QVgv8vfcCT01ZQ+9vNrH3bLjZJYqIJKNwIyIp4pvbg/Htq/D34Pq0rVIQiwWW7j5Pi0mr6fPdZvafizC7RBERQOFGRFKpeJ5sTOxQleBB9WhdOSHkLN55juaTVtFv7hYOXVDIERFzKdyIyCMpmdeTKR2rsnRgPVpVKoBhwKIdZ2kyYRUD5m3l8MUbZpcoIlmUwo2IPJbS+Tz5NKgafw4IoFmFfBgG/LbtDE3Gr2Twj9s4dumm2SWKSBajcCMiaaJcAS9mdvFn0Wt1aVwuH/EG/LLlNI3Gr+T1+ds5cTnS7BJFJItQuBGRNFWxUHY+7+bPwn51CCyTh7h4g/mbT9HwkxDe/HkHp64q5IhI+lK4EZF04Vc4B1+9WINf+9SmXuk8xMYbzAs7SeDHIbz9607OXLtldokiYqcUbkQkXVUt4s2cl2rw86u1qFsyNzFxBt9tOEGDj0J497ddnLt+2+wSRcTOKNyIiE1UL5qTb3vU5MfetahVPBfRcfHMWXeceh+tYMTC3VwIV8gRkbShcCMiNlWjWE6+7/Ukc3vWpIZvTqJj45kdeoyAcSsYtWgPFyOizC5RRDI5hRsRMUXtErn5ofeTfPtyTaoVyUFUbDyfrzlKwLjljFm8l8s3FHJE5NEo3IiIaSwWC3VL5ebnV2vz9Us1qOyTg9sx8cxcdYSAcSv4cMk+rt6MNrtMEclkFG5ExHQWi4X6pfOwoE9tvur+BJUKZScyOo7pIYep++FyPvlrP9cjY8wuU0QyCYUbEckwLBYLgWXzsrBfHWZ19ad8AS9uRscxZfkh6n64nAnBB7h+SyFHRB5M4UZEMhyLxUKT8vn4o39dZnSuTtn8nkRExTJp2UECPlzO5GUHibitkCMi96ZwIyIZlsVioXnF/CzuH8C0oGqUzpeN8NuxjA8+QMC4FXy64hA3omLNLlNEMhiFGxHJ8KxWCy0rFWDJgHpM6ViVEnk8uBYZw0dL9xPw4XJmrDxMZLRCjogkULgRkUzDarXQunJB/hpUn4kvVKFYbg+uRsYw9s99BHy4glmrjnArOs7sMkXEZAo3IpLpOFgttK1aiOBB9fjk+coUzeXO5ZvRjF68l4BxK/hizVFuxyjkiGRVCjcikmk5Olh5tnph/h5cn3HP+VHY241LN6J4f9Ee6o1bwdehxxRyRLIghRsRyfScHKy09/dh+f8aMOaZShTK4caFiCiGL9xN4MchfLP+OFGxCjkiWYXCjYjYDWdHKx1rFGHFkAaMaluRAtldOXv9Nu8s2EXDj1fy/cYTxMTFm12miKQzhRsRsTvOjlY6P1mUFUMaMPLpCuTzcuH0tVu89ctOAj8O4cewkwo5InYsw4SbsWPHYrFYGDhw4APXu3btGn379qVAgQK4uLhQunRpFi9ebJsiRSRTcXVyoFttX1a+Hsi7T5UndzYXTl29xdCfd9B4/Ep+2nyKWIUcEbvjaHYBAGFhYcycORM/P78HrhcdHU2TJk3ImzcvP/30E4UKFeL48ePkyJHDNoWKSKbk6uTAS3WL0bFGEb7bcJzpIYc5fjmSIfO38+mKQwxoVIrWlQviYLWYXaqIpAHTw82NGzcICgpi1qxZjBo16oHrfvnll1y5coXQ0FCcnJwA8PX1tUGVImIP3Jwd6BFQnE41izBn3XFmrjzM0Us3GfjDNqYsP8iAxqVpVamAQo5IJmd6uOnbty+tWrWicePGDw03CxcupFatWvTt25fffvuNPHny0KlTJ9544w0cHBzu+ZqoqCiioqKSnoeHhwMQExNDTEzazqZJ3F5ab1eSU59tw5777GSBl2sX4YXqBfl2/Qk+X3uMwxdv0v/7rUz++wD9G5agWfl8WG0Qcuy5zxmNem0b6dXn1GzPYhiGkabvngrz5s1j9OjRhIWF4erqSoMGDahSpQoTJ0685/ply5bl2LFjBAUF0adPHw4dOkSfPn3o378/w4cPv+drRowYwciRI+9aPnfuXNzd3dPy44hIJnU7Flaes7DijJVbcQmBpoC7QYvC8VTKaaAdOSLmi4yMpFOnTly/fh0vL68HrmtauDl58iT+/v4EBwcnnWvzsHBTunRpbt++zdGjR5P21IwfP56PPvqIs2fP3vM199pz4+Pjw6VLlx7anNSKiYkhODiYJk2aJB02k7SnPttGVuxz+K0Yvl53gi9DjycN5CyX35MBDUvQsGweLJa0TzlZsc9mUa9tI736HB4eTu7cuVMUbkw7LLV582YuXLhAtWrVkpbFxcWxatUqpk6dSlRU1F2HmgoUKICTk1Oy5eXKlePcuXNER0fj7Ox81/u4uLjg4uJy13InJ6d0++ZOz23Lv9Rn28hKfc7l5MTgZmV5OaAEn685wldrj7H3XASvzN1GpULZGdSkFIFl8qZLyMlKfTabem0bad3n1GzLtEvBGzVqxM6dO9m2bVvSw9/fn6CgILZt23bPc2jq1KnDoUOHiI//99LNAwcOUKBAgXsGGxGRR5Hd3Yn/NS3D6qGB9GlQAndnB3aevs5LszfRdlooIfsvYOIRfRF5CNPCjaenJxUrVkz28PDwIFeuXFSsWBGArl278tZbbyW95tVXX+XKlSsMGDCAAwcO8Mcff/DBBx/Qt29fsz6GiNgxbw9nhjYvy+qhgfSuXxw3Jwe2n7xG96/CeHZ6KGsOXlLIEcmAMsxN/O7lxIkTyc6l8fHxYenSpYSFheHn50f//v0ZMGAAb775polV3iH2ttkViEg6yJXNhbdalGPV0EB61C2Gi6OVLSeu0fmLDbSfuY7Qw5fMLlFE7mD6peB3CgkJeeBzgFq1arF+/XrbFJQat8NxnFqdyq7l4XIpyF/e7IpEJI3l8XRh2FPl6VWvONNXHua7DScIO3aVTrM28GTxnAxqXJqaxXOZXaZIlpeh99xkKvsXY7l5Ad/LITjOqA3zguDEBrOrEpF0kNfLleGtK7Dq9UC61SqKs4OV9Ueu8MJn6wn6fD2bjl0xu0SRLE3hJq34vUBs10Wc9aqKBQP2LYIvm8IXzWDfHxCv+TUi9iZ/dldGtqlIyOsNCKpZBCcHC2sPXea5Gevo8sUGtpy4anaJIlmSwk1asVgwfJ5kY4lBxPQOhapdwMEZTq6HeZ3g0xqw+WuI0Xk5IvamYA43RrerxIohDehYwwdHq4XVBy/xzLRQXvxqIztOXTO7RJEsReEmPeQuDW2mwsCdUHcQuGSHywfh9/4wsRKs+hhu6S86EXtT2NudMc/4sWJIA9r7F8bBamHF/os8PXUtPb4OY9fp62aXKJIlKNykJ8/80HgEDN4NTUeDVyG4eQGWvw/jK8CSt+DaSbOrFJE05pPTnXHPVWbZ4Po8U60QVgv8vfcCT01ZQ+9vNrH3bLjZJYrYNYUbW3DxhNr9YMB2aPcZ5K0AMTdh/TSYVBl+7gnndppdpYikMd/cHoxvX4XgwfVpW6UgFgss3X2eFpNW0+e7zew/F2F2iSJ2KdXh5tatW0RGRiY9P378OBMnTuSvv/5K08LskoMTVH4BXl0LnX+GYvXBiIOdP8KMujCnLRxeAbopmIhdKZEnGxM7VCV4UD1aV04IOYt3nqP5pFUM/GEH5yIfvg0RSblUh5s2bdowZ84cAK5du0bNmjX55JNPaNOmDdOnT0/zAu2SxQIlG0O3hdBrJVR8FixWOLICvmkLMwNgx3yIizW7UhFJQyXzejKlY1WWDKhHy0r5MQz4Y9c5xm53YPD8HRy+eMPsEkXsQqrDzZYtWwgICADgp59+Il++fBw/fpw5c+YwefLkNC/Q7hWsAs99Cf23Qo3e4OSecIjqlx4wuSqsnw5R+oEnYk/K5PdkWlB1/hwQQJNyeTGw8PuOczQZv5LBP27j2KWbZpcokqmlOtxERkbi6ekJwF9//cUzzzyD1WrlySef5Pjx42leYJbh7Qstx8Gg3RA4DNxzw/UTsORNmFABlr0PNy6YXaWIpKFyBbyY1qkKr/vF0qhsHuIN+GXLaRqNX8nr87dz4rKOV4k8ilSHm5IlS7JgwQJOnjzJ0qVLadq0KQAXLlzAy8srzQvMctxzQv3XYdAueGoC5CwBt6/B6o9hQkVY2B8uHTS7ShFJQ4U9YEZQVRb2q0NgmTzExRvM33yKhp+E8ObPOzh1VSFHJDVSHW7effddhgwZgq+vLzVr1qRWrVpAwl6cqlWrpnmBWZaTG/i/BP3CoP03UPgJiIuCLV/D1Cc03kHEDvkVzsFXL9bg1z61qVc6D7HxBvPCThL4cQhv/7qTM9dumV2iSKaQ6nDz3HPPceLECTZt2sSSJUuSljdq1IgJEyakaXECWB2g/NPwcjC8uARKtwCNdxCxa1WLeDPnpRr8/Got6pbMTUycwXcbTtDgoxDe/W0X567rTuciD/JI97nJnz8/VatWxWq1Eh4ezoIFC/D09KRs2bJpXZ8ksligaC3oNA/6boSqnTXeQcTOVS+ak2971OSHXk/yZPGcRMfFM2fdcep9tIIRC3dzIVz/v4vcS6rDTfv27Zk6dSqQcM8bf39/2rdvj5+fHz///HOaFyj3kKcMtPn0/uMdVn+i8Q4idqRm8VzM61WLuT1rUsM3J9Gx8cwOPUbAuBWMWrSHixFRZpcokqGkOtysWrUq6VLwX3/9FcMwuHbtGpMnT2bUqFFpXqA8wP3GOyx7T+MdROxQ7RK5+aH3k3z7ck2qFclBVGw8n685SsC45YxZvJfLNxRyROARws3169fJmTMnAEuWLOHZZ5/F3d2dVq1acfCgruIxhcY7iGQZFouFuqVy8/Ortfn6pRpU9snB7Zh4Zq46QsC4FXy4ZB9Xb0abXaaIqVIdbnx8fFi3bh03b95kyZIlSZeCX716FVdX1zQvUFLhrvEO9ZKPd/imncY7iNgJi8VC/dJ5WNCnNl91f4JKhbITGR3H9JDD1P1wOZ/8tZ/rkTFmlyliilSHm4EDBxIUFEThwoUpWLAgDRo0ABIOV1WqVCmt65NHkTTe4ffk4x0OL/93vMPOnzTeQcQOWCwWAsvmZWG/Oszq6k/5Al7cjI5jyvJD1P1wOROCD3D9lkKOZC2pDjd9+vRh3bp1fPnll6xZswarNWETxYsX1zk3GdH9xjv8/LLGO4jYEYvFQpPy+Vj0Wl1mdK5O2fyeRETFMmnZQQI+XM7kZQeJuK2QI1nDI10K7u/vT7t27fDw8MD45xBHq1atqFOnTpoWJ2ko2XiHtzXeQcROWa0WmlfMz+L+AUwLqkapvNkIvx3L+OADBIxbwacrDnEjSnttxb49UriZM2cOlSpVws3NDTc3N/z8/Pjmm2/SujZJD+45of7QO8Y7FE8+3uH3AXDpkNlVishjslottKxUgCUD6zG5Y1VK5PHgWmQMHy3dT8CHy5mx8jCR0Qo5Yp9SHW7Gjx/Pq6++SsuWLfnxxx/58ccfad68Oa+88oruUJyZJI132JQw3qGQf8J4h82zYap/wniHkxvNrlJEHpOD1cLTlQvy16D6THyhCsVye3A1Moaxf+4j4MMVzFp1hFvRcWaXKZKmHFP7gilTpjB9+nS6du2atOzpp5+mQoUKjBgxgkGDBqVpgZLOEsc7lGsNJ9bB2slw4M+E8Q77FoHPk1Cnf8LYB+sj7egTkQzAwWqhbdVCPOVXgN+2nWHy8oMcvxzJ6MV7mbnqCK82KEFQzSK4OjmYXarIY0v1b6uzZ89Su3btu5bXrl2bs2fPpklRYgKLBYrWThjv0GeDxjuI2ClHByvPVi/M34PrM+45Pwp7u3HpRhTvL9pDvXEr+Dr0GLdjtCdHMrdUh5uSJUvy448/3rX8hx9+oFSpUmlSlJgsb9mE8Q4DdkCdgRrvIGKHnBystPf3Yfn/GjDmmUoUyuHGhYgohi/cTeDHIXyz/jhRsQo5kjml+rDUyJEjeeGFF1i1alXS1VFr165l2bJl9ww9kol5FYAmIyHgf7BlTsIdj8NPJ4x3WPUJVO8GT/aBHD5mVyoij8jZ0UrHGkV4ploh5m86xacrDnH2+m3eWbCLGSGH6dewJM9VL4yTgw5LS+aR6u/WZ599lg0bNpA7d24WLFjAggULyJ07Nxs3bqRdu3bpUaOYzdXrjvEOMzXeQcQOuTg60PnJoqwY0oCRT1cgr6cLp6/d4q1fdhL4cQg/hp0kJi7e7DJFUuSRonj16tX59ttv2bx5M5s3b+bbb7+lUKFCfPDBB2ldn2QkDk5QuUPCeIcgjXcQsUeuTg50q+3LqqGBvPtUeXJnc+HU1VsM/XkHjcev5KfNp4hVyJEMLs32M549e5Z33nknrTYnGZnFAqUSxzuEQIVn/jPeoZ7GO4hkcq5ODrxUtxirhwYyrFU5cnk4c/xyJEPmb6fJhFUs2HqauHj9ISMZkw6iyuMpWBWe/+o/4x123DHeYYbGO4hkYm7ODvQIKM7qNwJ5s0VZvN2dOHrpJgN/2EbTCStZuP2MQo5kOAo3kjbuO97hDY13ELED7s6OvFK/BKvfaMjrzcqQ3c2Jwxdv0v/7rTSfuIo/dpwlXiFHMgiFG0lbd453aDVe4x1E7Ew2F0f6BpZkzRuB/K9JabxcHTl44QZ9526h5eTVLNmlkCPmS/Gl4IMHD37g1y9evPjYxYgdcXKDJ16G6t1h3x+wdhKc3pQw3mHz11C2FdQZAD41zK5URB6Bp6sTrzUqRdfavny55ihfrjnKvnMRvPLtFsoX8GJQk9I0LpcXi8VidqmSBaU43GzduvWh69SrV++xihE7lKLxDgOgdHONdxDJhLK7OTGoSWleqlOMz9cc4cs1R9lzNpyeczZRqVB2BjUpRWAZhRyxrRSHmxUrVqRnHWLvEsc7FK0NF/bBuimw/Yd/xjush9ylofZr4PcCOLqYXa2IpFJ2dyf+17QML9UpxqzVR5gdeoydp6/z0uxNVPbJwaDGpahfOo9CjtiE/lQW20sc7zBw57/jHS4dgIWvabyDSCbn7eHM0OZlWT00kN71i+Pm5MD2k9fo/lUYz04PZc3BSxi6F5akM4UbMU/ieIdBu6DpaPAqBDfOJ4x3mFARlvwfXDtpdpUi8ghyZXPhrRblWDU0kB51i+HiaGXLiWt0/mID7WeuI/TwJbNLFDumcCPmSxzv0H/bv+Mdom/A+k9hchX4pZfGO4hkUnk8XRj2VHlWDw3kxTq+ODtaCTt2lU6zNtDhs3VsOHLZ7BLFDmWYcDN27FgsFgsDBw5M0frz5s3DYrHQtm3bdK1LbMjR+e7xDvGxsOOHf8c7HAnReAeRTCivlyvDW1dg1euBdK1VFGcHK+uPXOGFz9YT9Pl6Nh27YnaJYkcyRLgJCwtj5syZ+Pn5pWj9Y8eOMWTIEAICAtK5MjHFg8Y7zGmD4xcNKXRlXULwEZFMJX92V95rU5GQ1xsQVLMITg4W1h66zHMz1tHliw1sOaHz7eTxpfhqqTtdu3aNjRs3cuHCBeLjkw9Q69q1a6q2dePGDYKCgpg1axajRo166PpxcXEEBQUxcuRIVq9ezbVr11L1fpLJJI53uDoc1n0KW77Bcn4n/uzEmPYH1OoL1bqAs4fZlYpIKhTM4cbodpV4tUEJPl1xiPmbTrH64CVWH7xEYJk8DGpSGr/COcwuUzKpVIeb33//naCgIG7cuIGXl1eyy/osFkuqw03fvn1p1aoVjRs3TlG4ee+998ibNy8vv/wyq1evfuj6UVFRREVFJT0PDw8HICYmhpiYmFTV+jCJ20vr7QqQrRA0+QDqDMEIm4WxfgYu/4x3MELGEF/9ZeL9X4Zsec2u1G7o+9k2snqf82Vz4r3W5ehRpyjTVh5hwbazrNh/kRX7L9KwTB76NyxBhYJeafJeWb3XtpJefU7N9ixGKq/JK126NC1btuSDDz7A3d091cXdad68eYwePZqwsDBcXV1p0KABVapUYeLEifdcf82aNXTo0IFt27aRO3duunfvzrVr11iwYMF932PEiBGMHDnyruVz58597PrFPNb4aIpcWUOJC3+SLeo8AHEWJ07mrMuhvM256VrA5ApF5FFcvAVLT1vZdNGCQcIfz34542leOJ5C2kGbpUVGRtKpUyeuX7+Ol9eDA2+qw42Hhwc7d+6kePHij1XkyZMn8ff3Jzg4OOlcmweFm4iICPz8/Jg2bRotWrQASFG4udeeGx8fHy5duvTQ5qRWTEwMwcHBNGnSBCcnpzTdtvwrWZ8drFgOLMa6birWM5sBMLBglGlJ/JP9MAo/YXK1mZe+n21Dfb63Ixdv8mnIEX7feTbpGoLmFfLxWmBxSufzfKRtqte2kV59Dg8PJ3fu3CkKN6k+LNWsWTM2bdr02OFm8+bNXLhwgWrVqiUti4uLY9WqVUydOpWoqCgcHBySvnb48GGOHTtG69atk5Ylnu/j6OjI/v37KVGixF3v4+LigovL3Xe8dXJySrdv7vTctvwrqc+VnoGK7f4Z7zAJy4ElWPb/gXX/H1CkFtTur/EOj0Hfz7ahPidXpmAOJneqRv8LEUxadohFO86wZPd5lu45T6tKBRjYuBQl8z5ayFGvbSOt+5yabaU63LRq1YrXX3+dPXv2UKlSpbve7Omnn07Rdho1asTOncnvXfLiiy9StmxZ3njjjWTBBqBs2bJ3rT9s2DAiIiKYNGkSPj4+qf0oYk/uN97hxLqEh8Y7iGRKJfN6MqVjVfoFlmTSsgMs3nmORTvO8sfOszxduSD9G5WiRJ5sZpcpGUyqw03Pnj2BhBN7/8tisRAXF5ei7Xh6elKxYsVkyzw8PMiVK1fS8q5du1KoUCHGjBmDq6vrXevnyJED4K7lksUljncIHAYbZsCmr/4d77B8FNTsDf4vgZu32ZWKSAqVye/JtKDq7DkTzqRlB1i6+zy/bTvD79vP0LZqIfo3LIVvbp2UIwlSvZ8+Pj7+vo+UBpuUOnHiBGfPnk3TbUoWkmy8wyiNdxCxA+ULejGziz+LXqtL43J5iTfgly2naTR+Ja/P386Jy5FmlygZwCPd5ya9hISEPPD5f82ePTvdahE74uqVcEiqRm/Y/QusnQQX9iSMd9g4Eyo+m3BeTn7tARTJLCoWys7n3Z5g+8lrTPz7ACv2X2T+5lP8uvU0z1UvTL+GJSnsrStis6oUhZvJkyfTq1cvXF1dmTx58gPX7d+/f5oUJpLmEsc7+L0Ah5ZB6CQ4uiphvMOOH6BEQ6gzAIrVTziHR0QyvMo+OfjqxRpsPXGVCX8fZNWBi8wLO8nPW07xvL8P/QJLUjCHm9llio2lKNxMmDCBoKAgXF1dmTBhwn3Xs1gsCjeS8SWOdyjVGM5shbWTYc+ChPEOh5dDfr+EkFO+LThkqJ2bInIfVYt4M+elGmw+foUJwQdZc+gSczec4KdNp+hQw4c+DUqSy93h4RsSu5Cin9xHjx69579FMr3E8Q5X3oX102DLN3BuB/z8MiwbCU9qvINIZlK9aE6+7VGTDUcuM+HvA6w/coU5644zL+wkHfwLU1I3J84SdOMPEYCcxaDlRzB4DwS+De654FrCeAfGl0+4yurGRbOrFJEUqlk8F/N61WJuz5o84etNdGw8c9af4P0tDoz5cz8XI6IevhHJtB5pn/upU6dYuHAhJ06cIDo6OtnXxo8fnyaFiZjCPSfUH5pwAvK2uRA6Ba4ehVUfJRy+qtIp4Wu57r5hpIhkPLVL5KZW8VysPXSZT/7ax9aT1/ky9Dhzw07SrZYvveoVJ1c23fvK3qQ63Cxbtoynn36a4sWLs2/fPipWrMixY8cwDCPZ3YZFMjUnN3jiZajeHfYtSrjC6vRm2PwVbJ4NZVtBnYHgo/EOIhmdxWKhbqnc1Chag/HfLyE0wpsdp8KZueoI36w/TrfavvQKKI63h7PZpUoaSfVhqbfeeoshQ4awc+dOXF1d+fnnnzl58iT169fn+eefT48aRcxjdYDybaDHMui+OGGMA0ZC4PmiMXzZHPYthn9GgYhIxmWxWCiXw+CnXjX5srs/lQplJzI6jukhh6n74XI++Ws/1yN1Uo49SHW42bt3L127dgUSZjrdunWLbNmy8d577/Hhhx+meYEiGYLFAr51oNMP0GcDVOkMVqeE0Q7zOsK0mrBlDsTqOL5IRmexWGhYNh8L+9VhVld/yhfw4mZ0HFOWH6Luh8uZEHyA67cUcjKzVIcbDw+PpPNsChQowOHDh5O+dunSpbSrTCSjylsW2n4KA3cmHJpy8fp3vMPESrB6PNy6ZnaVIvIQFouFJuXzsei1uszoXJ2y+T2JiIpl0rKDBHy4nMnLDhJxWyEnM0p1uHnyySdZs2YNAC1btuR///sfo0eP5qWXXuLJJ59M8wJFMqyk8Q67/zPeYSRMqKDxDiKZhNVqoXnF/CzuH8C0oGqUypuN8NuxjA8+QMC4FXy64hA3omLNLlNSIdXhZvz48dSsWROAkSNH0qhRI3744Qd8fX354osv0rxAkQwvcbxD/23QdgbkLQ/RNxLGO0yuAr/0gnO7zK5SRB7CarXQslIBlgysx+SOVSmex4NrkTF8tHQ/AR8uZ8bKw0RGK+RkBqm6WiouLo5Tp07h5+cHJByimjFjRroUJpLpODpDlY4JIx4OLYO1E+HY6jvGOzSCOv013kEkg3OwWni6ckFaVSrA79vPMGnZQY5eusnYP/cxa9URXqlfgs5PFsXNWXc8zqhStefGwcGBpk2bcvXq1fSqRyTzSxzv0H0R9FwBFZ4BixUOL4M5beCz+rDzJ4jTX4AiGZmD1ULbqoUIHlSPT56vTJGc7ly+Gc3oxXsJGLeCL9Yc5XZMnNllyj2k+rBUxYoVOXLkSHrUImJ/ClVLGO/w2hao0Qsc3eDs9oTxDlOqwvoZEH3T7CpF5AEcHaw8W70wy/5Xn3HP+lHY241LN6J4f9Ee6o1bwdehxxRyMphUh5tRo0YxZMgQFi1axNmzZwkPD0/2EJF7SBzvMGg3NPi/5OMdJlTQeAeRTMDJwUr7J3xY/r8GjHmmEoVyuHEhIorhC3cT+HEI36w/TlSsQk5GkOJw895773Hz5k1atmzJ9u3befrppylcuDDe3t54e3uTI0cOvL2907NWkczPIxc0eCMh5LQaD97F4NbVhPEOEyrA7wPh8uGHbkZEzOPsaKVjjSIsH1KfUW0rUiC7K2ev3+adBbto+PFKvt94gpg43djTTCk+oXjkyJG88sorrFixIj3rEckaNN5BJNNzcXSg85NFea56YX4IO8mnKw5x+tot3vplJ5+uOET/hqVoV60QTg6aUW1rKQ43hmEAUL9+/XQrRiTLSRzvUO5pOB4KoZPhwJKEwLNvERSpBXUGQKlmYNUPSJGMyNXJgW61fXnhCR/mbjjBtJDDnLp6i6E/72DqikP0b1SKtlUK4qiQYzOp6rRFl6+KpI8HjXf4voPGO4hkAq5ODrxUtxirhwbydsty5PJw5sSVSIbM306TCatYsPU0cfGG2WVmCakKN6VLlyZnzpwPfIjIY9J4B5FMzc3ZgZ71irP6jUDebFEWb3cnjl66ycAfttF0wkoWbj+jkJPOUnUTv5EjR5I9e/b0qkVE7pQ43iHgf7Dla1g3DSLOJIx3WP1Jwvk6T74K2QubXamI3IO7s2PSDf++Dj3GZ6uOcPjiTfp/v5Upyw4ysHFpWlTMj9WqoyJpLVXhpkOHDuTNmze9ahGRe0kc71CjN+z6OeG8nAt7YN1U2DADKj4LtftD/opmVyoi95DNxZG+gSXpWqsos9ceY9bqIxy8cIO+c7dQNr8nAxuXoml5hZy0lOLDUjrfRsRkieMdXg2FoJ/ANwDiYxNGO8yoA988A0dCwNDubpGMyNPVidcalWL1Gw0Z0KgUni6O7DsXwSvfbuGpKWsI3nM+6eIdeTwpDjdquEgGYbFAqSZ3jHdop/EOIplIdjcnBjUpzZo3GvJaw5J4ODuw52w4Peds4umpa1m+TyHncaU43MTHx+uQlEhGU6gaPD/7/uMdNszUeAeRDCq7uxP/a1qGNW80pE+DErg7O7Dz9HVemr2JttNCCdl/QSHnEemiexF7cL/xDn8O1XgHkQzO28OZoc3LsnpoIL3rFcfNyYHtJ6/R/aswnp0eypqDlxRyUknhRsSeJI53GLgLWn2SfLzDxIoa7yCSgeXK5sJbLcuxamggPeoWw8XRypYT1+j8xQbaz1xH6OFLZpeYaSjciNgjZ3d4oge8thnaz4FC1SH2dsJ4hynV4YfOcDLM7CpF5B7yeLow7KnyrB4ayIt1fHF2tBJ27CqdZm2gw2fr2HDkstklZngKNyL2LHG8Q49l0H0xlG4OGLD3d/iiMXzZHPb/CfEa8ieS0eT1cmV46wqsej2QrrWK4uxgZf2RK7zw2XqCPl/PpmNXzC4xw1K4EckKUjTe4RuNdxDJgPJnd+W9NhUJeb0BQTWL4ORgYe2hyzw3Yx1dvtjAlhNXzS4xw1G4EclqksY77EgYypk03qEfTPTTeAeRDKpgDjdGt6vEiiEN6FjDB0erhdUHL/HMtFBe/GojO05dM7vEDEPhRiSr8ioITd5LuMKq6SjwLAg3ziWMd5hQAevf7+AarWP7IhlNYW93xjzjx/L/NeD56oVxsFpYsf8iT09dS4+vw9h1+rrZJZpO4UYkq0sc7zBgO7SdAXnLQ/QNHDZMp8nuITj89iqc22V2lSLyH0VyufPR85VZNrg+z1QrhNUCf++9wFNT1tBrzib2nAk3u0TTKNyISIL/jHeIL1oXK3FYd82/Y7zDSo13EMlgfHN7ML59FYIH16dtlYJYLPDXnvO0nLyaPt9tZv+5CLNLtDmFGxFJ7p/xDnGdF7CyzAjiy7W5Y7zD0xrvIJJBlciTjYkdqvLXwHo85VcAiwUW7zxH80mr6Dd3C4cuZJ2Qo3AjIvd1zb04cc98kTDe4YmeGu8gkgmUyufJ1E7VWDKgHi0r5ccwYNGOszSZsIoB87Zy+OINs0tMdwo3IvJwOYtBq48fMN5htMY7iGQwZfJ7Mi2oOov7B9CsQj4MA37bdoYm41cy+MdtHLtkv3+YKNyISMrdd7zDOI13EMmgyhf0YmYXfxa9VpfG5fISb8AvW07TaPxKXp+/nROXI80uMc1lmHAzduxYLBYLAwcOvO86s2bNIiAgAG9vb7y9vWncuDEbN260XZEikuDO8Q7Pf63xDiKZQMVC2fm82xP81rcOgWXyEBdvMH/zKRp+EsKbP+/g1FX7CTkZItyEhYUxc+ZM/Pz8HrheSEgIHTt2ZMWKFaxbtw4fHx+aNm3K6dOnbVSpiCRjdYAKbf8d71CqGcnHO7TQeAeRDKayTw6+erEGv/SpTb3SeYiNN5gXdpLAj0P4v193cubaLbNLfGymh5sbN24QFBTErFmz8Pb2fuC63333HX369KFKlSqULVuWzz//nPj4eJYtW2ajakXknhLHOwT9CH3W3zHeIfSf8Q5ParyDSAZTrYg3c16qwU+v1KJOyVzExBnM3XCCBh+F8O5vuzh3/bbZJT4yR7ML6Nu3L61ataJx48aMGjUqVa+NjIwkJiaGnDlz3nedqKgooqL+/YEaHp5wU6OYmBhiYmIerej7SNxeWm9XklOfbeOR++xdElpNhIA3sG76DOuW2Vgu7YeF/TCWv0/8E72Ir9YdXLOnec2Zkb6fbUe9vrfKhTyZ3a06G49dYfLyw2w4epU5644zL+wkHfwL07teMfJ6uqR4e+nV59Rsz2IY5t2Ra968eYwePZqwsDBcXV1p0KABVapUYeLEiSl6fZ8+fVi6dCm7d+/G1dX1nuuMGDGCkSNH3rV87ty5uLu7P075IpICjnG3KHppBSUuLsUtJmHAX6zVlWO5GnA4bzNuO+cyuUIRudPB6xYWn7RyJMICgJPFoE5+g0YF4/FyNq+uyMhIOnXqxPXr1/Hy8nrguqaFm5MnT+Lv709wcHDSuTapCTdjx45l3LhxhISEPPBcnXvtufHx8eHSpUsPbU5qxcTEEBwcTJMmTXByckrTbcu/1GfbSPM+x0Vj2f0rDuunYrm4FwDD6ohR4RniavaFfBUe/z0yIX0/2456nXKGYRB65AqTlh1i68mEWVWuTlY61yxCj7q+5PK4f8pJrz6Hh4eTO3fuFIUb0w5Lbd68mQsXLlCtWrWkZXFxcaxatYqpU6cSFRWFg4PDPV/78ccfM3bsWP7++++HnoTs4uKCi8vdu9OcnJzS7Zs7Pbct/1KfbSPN+uzkBNU7Q7UgOPQ3rJ2E5dhqLDt/xLrzRyjRKGFKebF6CefwZDH6frYd9TplGpTNT/0y+Vh18BLjgw+w/eQ1Pl9zjLkbT9Ktti+9Aorj/YCQk9Z9Ts22TAs3jRo1YufOncmWvfjii5QtW5Y33njjvsFm3LhxjB49mqVLl+Lv72+LUkUkLf0z3oFSTeD0FgidDHt+SxjvcHgZFKicEHLKtQEH008LFMnSLBYL9UvnoV6p3KzYf4EJwQfZefo600MOMyf0GC/VLUaPusXJ7p6xwqJpPzk8PT2pWLFismUeHh7kypUraXnXrl0pVKgQY8aMAeDDDz/k3XffZe7cufj6+nLu3DkAsmXLRrZs2Wz7AUTk8RWqBs/PhitHYd2nsPXbhPEOP70EOYpArX5QtTM4e5hdqUiWZrFYaFg2H4Fl8vL33gtMCD7AnrPhTFl+iNlrE0LOS3WLkd0tY4Qc0y8Ff5ATJ05w9uzZpOfTp08nOjqa5557jgIFCiQ9Pv74YxOrFJHHpvEOIpmCxWKhSfl8LHqtLjM6V6dsfk8iomKZtOwgAR8uZ/Kyg0TcNn+oboba5xsSEvLA58eOHbNZLSJigsTxDrVfg+1zIXQqXD2aMN4hdDJU7pjwtVwlzK5UJEuzWi00r5ifpuXz8eeuc0z8+wAHL9xgfPABvlxzlDq5LTSJi8esU5sy9J4bEcmi/jveoWC1u8c7nNpkdpUiWZ7VaqGVXwGWDKzH5I5VKZ7Hg2u3Yth+xYqj1bwLAzLUnhsRkWQSxzuUbwPH18LayXBwacJ4h72/Q5HaUKd/wtgHq/5WEzGLg9XC05UL0qpSAX7dcpJje7ZhMfGqR/00EJGMz2IB37p3jHcI0ngHkQzIwWqhTeUClMpu2v2BAYUbEcls8paDttNg4I6ES8ZdvOCf8Q5M9IM1E+DWNbOrFBETKdyISObkVRCavAeDdkGT98GzINw4B3+PSLjCaunbcP2U2VWKiAkUbkQkc3PNnnDezYDt0HY65CkH0Tdg3VSYVBl+6Q3ndpldpYjYkMKNiNgHR2eo0gn6rINO88E3AOJjYcc8mFEHvn0WjqwE82YFi4iNKNyIiH2xWKB0U+i+CHouh/JtwWJNmGc152n4rD7s+hnizL/RmIikD4UbEbFfhapD+68T7pfzRE9wdPt3vMOUqrBhJkTfNLtKEUljCjciYv9yFr9jvMNbGu8gYucUbkQk6/DIBQ3ehIG7oOXH4O0Lt64mjHeYWBEWDYLLh82uUkQek8KNiGQ9zu5Qoye8tiX5eIdNX2q8g4gdULgRkawrcbxDz+XQ/Y+EMQ4YCaMdPm8EX7aA/UsgPt7sSkUkFTRbSkQkcbyDb124sBdCp8COHxPGO5wIhdxlEqaR+7UHRxezqxWRh9CeGxGRO9053qF2f413EMmEFG5ERO7FqyA0ff+O8Q4F7hjvUPGf8Q6nza5SRO5B4UZE5EGSxjvsuGO8Q8Q/4x38EsY7nN9tdpUicgeFGxGRlHjQeIfptRPGOxxdpfEOIhmAwo2ISGo8aLzD163hswYa7yBiMoUbEZFHdc/xDtv+Ge9QDTZ8pvEOIiZQuBEReVz3HO9wHP58XeMdREygcCMiklY03kEkQ1C4ERFJa8nGO8y+x3iHLhrvIJKOdIdiEZH0YnWACu0STjo+vhbWToKDf8HehQmPonWw1OwDhsY7iKQlhRsRkfR2v/EOx9fieHwtDV0LYil0Hap21HgHkTSgw1IiIrb0n/EOhosnnrfP4PjHAI13EEkjCjciImb4Z7xDbL/t7C74Aka2/BrvIJJGFG5ERMzk6sWhfK2I7bfl3uMdfn1F4x1EUknhRkQkI3C4z3iH7d9rvINIKinciIhkJBrvIPLYFG5ERDKqZOMdemi8g0gKKdyIiGR0OYtDq0/+He/gljP5eIcVH8DNS2ZXKZJhKNyIiGQWieMdBu1OPt5h5YcJIUfjHUQAhRsRkcxH4x1EHkjhRkQks0oc79BzOXRbBKWaAkbCaIfPG8FXLWH/EojXeAfJWjR+QUQks7NYoFhAwuM/4x04vhZyl4E6/aHS8xrvIFmC9tyIiNiT/4x3wMULLu2H3/pqvINkGQo3IiL26J/xDgzaBU3eA88CGu8gWYbCjYiIPXPNDnUGwIAd0GaaxjtIlpBhws3YsWOxWCwMHDjwgevNnz+fsmXL4urqSqVKlVi8eLFtChQRycwcnaFq0L/jHYrW/c94h+c03kHsRoYIN2FhYcycORM/P78HrhcaGkrHjh15+eWX2bp1K23btqVt27bs2rXLRpWKiGRyieMdXvzjP+MdgjXeQeyG6eHmxo0bBAUFMWvWLLy9vR+47qRJk2jevDmvv/465cqV4/3336datWpMnTrVRtWKiNgRjXcQO2X6peB9+/alVatWNG7cmFGjRj1w3XXr1jF48OBky5o1a8aCBQvu+5qoqCiioqKSnoeHhwMQExNDTEzMoxd+D4nbS+vtSnLqs22oz7aRIfrs6QNNx0KdIVg3f4F10xdY/hnvYISMIb76S8T79wCP3ObVmAYyRK+zgPTqc2q2Z2q4mTdvHlu2bCEsLCxF6587d458+fIlW5YvXz7OnTt339eMGTOGkSNH3rX8r7/+wt3dPXUFp1BwcHC6bFeSU59tQ322jYzT50o4lP4Qn8urKXlhCR63LuCw5mNYO4kTuQI4nLcFN13yPXwzGVjG6bV9S+s+R0ZGpnhd08LNyZMnGTBgAMHBwbi6uqbb+7z11lvJ9vaEh4fj4+ND06ZN8fLyStP3iomJITg4mCZNmuDk5JSm25Z/qc+2oT7bRsbtczuI/4jY/YuwrpuKw9mtFLu0HN9LKzDKPkX8k/0wClU3u8hUybi9ti/p1efEIy8pYVq42bx5MxcuXKBatWpJy+Li4li1ahVTp04lKioKBweHZK/Jnz8/58+fT7bs/Pnz5M+f/77v4+LigovL3XfkdHJySrdv7vTctvxLfbYN9dk2MmafncDvOaj0LBxbA6GTsRz8C8u+37Hu+x2K1km4UWCppmA1/RTOFMuYvbY/ad3n1GzLtO/GRo0asXPnTrZt25b08Pf3JygoiG3btt0VbABq1arFsmXLki0LDg6mVq1atipbRCTrSRzvEDQfXl0HlTuB1SlhtMP3L8D0WrD1W4iNevi2RGzAtD03np6eVKxYMdkyDw8PcuXKlbS8a9euFCpUiDFjxgAwYMAA6tevzyeffEKrVq2YN28emzZt4rPPPrN5/SIiWVK+8tBuOjR6B9ZPh01fwcV9CeMdlr0PT74K/i8m3DxQxCQZej/iiRMnOHv2bNLz2rVrM3fuXD777DMqV67MTz/9xIIFC+4KSSIiks4SxzsM3v2f8Q7DYXwFjXcQU5l+KfidQkJCHvgc4Pnnn+f555+3TUEiIvJgieMdar4KO+cnTCS/uDdhvMOGGQmTyGu/BvkqmF2pZCEZes+NiIhkEonjHV4NhU4/aryDmErhRkRE0o7VCqWbPWS8wy8a7yDpSuFGRETSx33HO7yo8Q6SrhRuREQkfeUsDq0+gUG7oP6b4JYT/hnvwISKsOIDuHnJ7CrFjijciIiIbXjkhsC3YNBuaPkxePvCrSuw8kOYUAEWDYbLh82uUuyAwo2IiNiWszvU6AmvbYHnZ0PBqhB7GzZ9AVOqw49d4dRms6uUTEzhRkREzGF1gArtoOcK6LYoYYwDBuz5DT5vCF+1hP1LID7e7Eolk8lQ97kREZEsKHG8Q7EAOL8n4V45O+cnjHc4vhbylE24V06l58Hx7lmBIv+lPTciIpJxJI53GLA9IdA4e/473mFSZVgzEW5fN7tKyeAUbkREJOPJXgiajko+3iHi7L/jHf4apvEOcl8KNyIiknEljncYsAPaTIM85SA6IuHQ1SQ/+PUVOL/b7Colg1G4ERGRjE/jHSQVFG5ERCTzuHO8Q4/lUL5N8vEOswI13kEUbkREJJMqXB3az7ljvIMrnNn673iHjbMgOtLsKsUECjciIpK5JY132J18vMPiIQl3PtZ4hyxH4UZEROzDQ8Y7WP98HY+o82ZXKTagm/iJiIh9SRzvUP1F2LsQQifDma04bPmKRlgw4ldD3YEJh7XELmnPjYiI2CcHR6j4TNJ4h/gSjbFgYN238N/xDgeWaryDHVK4ERER+/bPeIe4DvNYXvYD4v06gNUpYbTD3PYwvRZs/RZio8yuVNKIwo2IiGQZEW6FiWs9VeMd7JzCjYiIZD13jndoPFLjHeyMwo2IiGRdrtkTTi5OGu9Q9j/jHV5NmFQumYrCjYiISNJ4h3X/Ge8wN+GcHI13yFQUbkRERBJpvINdULgRERG5l8TxDv02gf/Lycc7TK2u8Q4ZmMKNiIjIg+QqAU+NTz7e4eqxO8Y7jNF4hwxG4UZERCQl7jveYWxCyFk0GC4fNrtKQeFGREQkdRLHO/TbDM99BQWrQuxt2PQFTPWHH7vCqc1mV5mlKdyIiIg8iv+Md6BkEzDiYc9v/4x3aKXxDibR4EwREZHH8c94B4oFJNwTJ3QK7PwRjq9JeOQpC7X7Q6XnEy45l3SnPTciIiJpJV95aDc94aaAycY79Em4KaDGO9iEwo2IiEha03gHUynciIiIpJek8Q7boc2n/xnvUFnjHdKJwo2IiEh6c3SBqp3vGO9QB+Jj/jPeYbXGO6QRhRsRERFbSRrvsPjf8Q5Y/hnv8JTGO6QRhRsREREzJI53eG2zxjukMYUbERERMyUb7/CGxjukAYUbERGRjMAjNwT+HwzaBS0+ghxFk493+ON/cOWI2VVmCqaGm+nTp+Pn54eXlxdeXl7UqlWLP//884GvmThxImXKlMHNzQ0fHx8GDRrE7du3bVSxiIhIOnP2gJq94LUtCeMdClRJGO8Q9jlMqa7xDilg6h2KCxcuzNixYylVqhSGYfD111/Tpk0btm7dSoUKFe5af+7cubz55pt8+eWX1K5dmwMHDtC9e3csFgvjx4834ROIiIikk8TxDhXawbHVsHZywonHe35LeBStC3X6J4x9sOpAzJ1MDTetW7dO9nz06NFMnz6d9evX3zPchIaGUqdOHTp16gSAr68vHTt2ZMOGDTapV0RExOYsFihWL+Fxfvc/4x3m3zHeoVzC3ZA13iFJhpktFRcXx/z587l58ya1atW65zq1a9fm22+/ZePGjdSoUYMjR46wePFiunTpct/tRkVFERUVlfQ8PDwcgJiYGGJiYtL0MyRuL623K8mpz7ahPtuG+mw7dtHrnKXhqSlQ702sG2di3ToHy8W98FsfjGXvEV+jN/FVu4Grl2klplefU7M9i2GYe8egnTt3UqtWLW7fvk22bNmYO3cuLVu2vO/6kydPZsiQIRiGQWxsLK+88grTp0+/7/ojRoxg5MiRdy2fO3cu7u7uafIZREREzOAYF4nvpRWUuLAU19hrAMRYXTmWO5AjeZpx2zmnuQWmocjISDp16sT169fx8npweDM93ERHR3PixAmuX7/OTz/9xOeff87KlSspX778XeuGhITQoUMHRo0aRc2aNTl06BADBgygZ8+evPPOO/fc/r323Pj4+HDp0qWHNie1YmJiCA4OpkmTJjg5OaXptuVf6rNtqM+2oT7bjl33OjYKy+6fcVj/KZZL+wEwrE4YFZ8lrmZfyFvOZqWkV5/Dw8PJnTt3isKN6YelnJ2dKVmyJADVq1cnLCyMSZMmMXPmzLvWfeedd+jSpQs9evQAoFKlSty8eZNevXrx9ttvY73HCVUuLi64uLjctdzJySndvrnTc9vyL/XZNtRn21Cfbccue+3kBP7doFqXhJOO107Ccnwtlh3zsO6YB6WaQu3+4Fs34Rwem5SUtn1OzbYy3OnV8fHxyfa03CkyMvKuAOPg4ACAyTugREREzJdsvMMyKPc0YIGDf/073mH3rxAfZ3al6crUPTdvvfUWLVq0oEiRIkRERDB37lxCQkJYunQpAF27dqVQoUKMGTMGSLi6avz48VStWjXpsNQ777xD69atk0KOiIiIAIX94YVv4PJhWPcpbPsuYbzD/O7g7Qu1+kGVIHC2v/NPTQ03Fy5coGvXrpw9e5bs2bPj5+fH0qVLadKkCQAnTpxItqdm2LBhWCwWhg0bxunTp8mTJw+tW7dm9OjRZn0EERGRjC1xvEODtyBsVsLMqsTxDiFj4ImeUKNnwh2S7YSp4eaLL7544NdDQkKSPXd0dGT48OEMHz48HasSERGxQ9nyJIx3qDMAtn4H66bCteMJ4x3WToKqQVCrL+Qsbnaljy3DnXMjIiIi6eie4x1u3THeoRucztzjHRRuREREsqLE8Q69QqDb7wljHIx42LMAZjWEr1rBgb8gE16wY/ql4CIiImIiOxzvoD03IiIikiBfBWg3AwZsT7iaytkT/hnvwKTKCefm3L5udpUPpXAjIiIiyWUvDM1Gw6Bd0HgkZMsPEWcg+F2YUBH+egfCz5hd5X0p3IiIiMi9ueWAugNh4A5o8ynkKQtR4RA6GSb6wa+vwvk9Zld5F4UbEREReTBHF6jaGV5dBx1/gKJ1ID4Gts+F6bXgu+fh6OoMc/KxTigWERGRlLFaoUzzhMepTQnn4Oz9PWG8w8G/oGA1LE/2BcPcqQHacyMiIiKplzje4bXN4P8SOLrCmS04/vIyDff9H8TFmFaawo2IiIg8ulwl4KkJMHAX1H8Dw82bK+4lwcG8yesKNyIiIvL4/hnvENtvG3sKtje1FIUbERERSTvOHkQ7eZlagsKNiIiI2BWFGxEREbErCjciIiJiVxRuRERExK4o3IiIiIhdUbgRERERu6JwIyIiInZF4UZERETsisKNiIiI2BWFGxEREbErCjciIiJiVxRuRERExK4o3IiIiIhdcTS7AFszDAOA8PDwNN92TEwMkZGRhIeH4+TklObblwTqs22oz7ahPtuOem0b6dXnxN/bib/HHyTLhZuIiAgAfHx8TK5EREREUisiIoLs2bM/cB2LkZIIZEfi4+M5c+YMnp6eWCyWNN12eHg4Pj4+nDx5Ei8vrzTdtvxLfbYN9dk21GfbUa9tI736bBgGERERFCxYEKv1wWfVZLk9N1arlcKFC6fre3h5eel/HBtQn21DfbYN9dl21GvbSI8+P2yPTSKdUCwiIiJ2ReFGRERE7IrCTRpycXFh+PDhuLi4mF2KXVOfbUN9tg312XbUa9vICH3OcicUi4iIiH3TnhsRERGxKwo3IiIiYlcUbkRERMSuKNyIiIiIXVG4SaVPP/0UX19fXF1dqVmzJhs3bnzg+vPnz6ds2bK4urpSqVIlFi9ebKNKM7fU9HnWrFkEBATg7e2Nt7c3jRs3fuh/F0mQ2u/nRPPmzcNisdC2bdv0LdBOpLbP165do2/fvhQoUAAXFxdKly6tnx0pkNo+T5w4kTJlyuDm5oaPjw+DBg3i9u3bNqo2c1q1ahWtW7emYMGCWCwWFixY8NDXhISEUK1aNVxcXChZsiSzZ89O9zoxJMXmzZtnODs7G19++aWxe/duo2fPnkaOHDmM8+fP33P9tWvXGg4ODsa4ceOMPXv2GMOGDTOcnJyMnTt32rjyzCW1fe7UqZPx6aefGlu3bjX27t1rdO/e3ciePbtx6tQpG1eeuaS2z4mOHj1qFCpUyAgICDDatGljm2IzsdT2OSoqyvD39zdatmxprFmzxjh69KgREhJibNu2zcaVZy6p7fN3331nuLi4GN99951x9OhRY+nSpUaBAgWMQYMG2bjyzGXx4sXG22+/bfzyyy8GYPz6668PXP/IkSOGu7u7MXjwYGPPnj3GlClTDAcHB2PJkiXpWqfCTSrUqFHD6Nu3b9LzuLg4o2DBgsaYMWPuuX779u2NVq1aJVtWs2ZNo3fv3ulaZ2aX2j7/V2xsrOHp6Wl8/fXX6VWiXXiUPsfGxhq1a9c2Pv/8c6Nbt24KNymQ2j5Pnz7dKF68uBEdHW2rEu1Cavvct29fo2HDhsmWDR482KhTp0661mlPUhJuhg4dalSoUCHZshdeeMFo1qxZOlZmGDoslULR0dFs3ryZxo0bJy2zWq00btyYdevW3fM169atS7Y+QLNmze67vjxan/8rMjKSmJgYcubMmV5lZnqP2uf33nuPvHnz8vLLL9uizEzvUfq8cOFCatWqRd++fcmXLx8VK1bkgw8+IC4uzlZlZzqP0ufatWuzefPmpENXR44cYfHixbRs2dImNWcVZv0ezHKDMx/VpUuXiIuLI1++fMmW58uXj3379t3zNefOnbvn+ufOnUu3OjO7R+nzf73xxhsULFjwrv+h5F+P0uc1a9bwxRdfsG3bNhtUaB8epc9Hjhxh+fLlBAUFsXjxYg4dOkSfPn2IiYlh+PDhtig703mUPnfq1IlLly5Rt25dDMMgNjaWV155hf/7v/+zRclZxv1+D4aHh3Pr1i3c3NzS5X2150bsytixY5k3bx6//vorrq6uZpdjNyIiIujSpQuzZs0id+7cZpdj1+Lj48mbNy+fffYZ1atX54UXXuDtt99mxowZZpdmV0JCQvjggw+YNm0aW7Zs4ZdffuGPP/7g/fffN7s0SQPac5NCuXPnxsHBgfPnzydbfv78efLnz3/P1+TPnz9V68uj9TnRxx9/zNixY/n777/x8/NLzzIzvdT2+fDhwxw7dozWrVsnLYuPjwfA0dGR/fv3U6JEifQtOhN6lO/nAgUK4OTkhIODQ9KycuXKce7cOaKjo3F2dk7XmjOjR+nzO++8Q5cuXejRowcAlSpV4ubNm/Tq1Yu3334bq1V/+6eF+/0e9PLySre9NqA9Nynm7OxM9erVWbZsWdKy+Ph4li1bRq1ate75mlq1aiVbHyA4OPi+68uj9Rlg3LhxvP/++yxZsgR/f39blJqppbbPZcuWZefOnWzbti3p8fTTTxMYGMi2bdvw8fGxZfmZxqN8P9epU4dDhw4lhUeAAwcOUKBAAQWb+3iUPkdGRt4VYBIDpaGRi2nGtN+D6Xq6sp2ZN2+e4eLiYsyePdvYs2eP0atXLyNHjhzGuXPnDMMwjC5duhhvvvlm0vpr1641HB0djY8//tjYu3evMXz4cF0KngKp7fPYsWMNZ2dn46effjLOnj2b9IiIiDDrI2QKqe3zf+lqqZRJbZ9PnDhheHp6Gv369TP2799vLFq0yMibN68xatQosz5CppDaPg8fPtzw9PQ0vv/+e+PIkSPGX3/9ZZQoUcJo3769WR8hU4iIiDC2bt1qbN261QCM8ePHG1u3bjWOHz9uGIZhvPnmm0aXLl2S1k+8FPz111839u7da3z66ae6FDwjmjJlilGkSBHD2dnZqFGjhrF+/fqkr9WvX9/o1q1bsvV//PFHo3Tp0oazs7NRoUIF448//rBxxZlTavpctGhRA7jrMXz4cNsXnsmk9vv5Tgo3KZfaPoeGhho1a9Y0XFxcjOLFixujR482YmNjbVx15pOaPsfExBgjRowwSpQoYbi6uho+Pj5Gnz59jKtXr9q+8ExkxYoV9/x5m9jbbt26GfXr17/rNVWqVDGcnZ2N4sWLG1999VW612kxDO1/ExEREfuhc25ERETErijciIiIiF1RuBERERG7onAjIiIidkXhRkREROyKwo2IiIjYFYUbERERsSsKNyKS5VksFhYsWGB2GSKSRhRuRMRU3bt3x2Kx3PVo3ry52aWJSCalqeAiYrrmzZvz1VdfJVvm4uJiUjUiktlpz42ImM7FxYX8+fMne3h7ewMJh4ymT59OixYtcHNzo3jx4vz000/JXr9z504aNmyIm5sbuXLlolevXty4cSPZOl9++SUVKlTAxcWFAgUK0K9fv2Rfv3TpEu3atcPd3Z1SpUqxcOHC9P3QIpJuFG5EJMN75513ePbZZ9m+fTtBQUF06NCBvXv3AnDz5k2aNWuGt7c3YWFhzJ8/n7///jtZeJk+fTp9+/alV69e7Ny5k4ULF1KyZMlk7zFy5Ejat2/Pjh07aNmyJUFBQVy5csWmn1NE0ki6j+YUEXmAbt26GQ4ODoaHh0eyx+jRow3DMAzAeOWVV5K9pmbNmsarr75qGIZhfPbZZ4a3t7dx48aNpK//8ccfhtVqNc6dO2cYhmEULFjQePvtt+9bA2AMGzYs6fmNGzcMwPjzzz/T7HOKiO3onBsRMV1gYCDTp09PtixnzpxJ/65Vq1ayr9WqVYtt27YBsHfvXipXroyHh0fS1+vUqUN8fDz79+/HYrFw5swZGjVq9MAa/Pz8kv7t4eGBl5cXFy5ceNSPJCImUrgREdN5eHjcdZgorbi5uaVoPScnp2TPLRYL8fHx6VGSiKQznXMjIhne+vXr73perlw5AMqVK8f27du5efNm0tfXrl2L1WqlTJkyeHp64uvry7Jly2xas4iYR3tuRMR0UVFRnDt3LtkyR0dHcufODcD8+fPx9/enbt26fPfdd2zcuJEvvvgCgKCgIIYPH063bt0YMWIEFy9e5LXXXqNLly7ky5cPgBEjRvDKK6+QN29eWrRoQUREBGvXruW1116z7QcVEZtQuBER0y1ZsoQCBQokW1amTBn27dsHJFzJNG/ePPr06UOBAgX4/vvvKV++PADu7u4sXbqUAQMG8MQTT+Du7s6zzz7L+PHjk7bVrVs3bt++zYQJExgyZAi5c+fmueees90HFBGbshiGYZhdhIjI/VgsFn799Vfatm1rdikikknonBsRERGxKwo3IiIiYld0zo2IZGg6ci4iqaU9NyIiImJXFG5ERETErijciIiIiF1RuBERERG7onAjIiIidkXhRkREROyKwo2IiIjYFYUbERERsSsKNyIiImJX/h98/D4zqiNbZAAAAABJRU5ErkJggg==\n"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"wrong_denom = len(small_val_loader) # 8\ncorrect_denom = len(val_dataloader) # 79\ncorrect_denom\n\ncorrection_factor = wrong_denom / correct_denom\n\nepoch_val_losses = [loss * correction_factor for loss in epoch_val_losses]\n\nepoch_val_losses","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-28T06:57:29.279260Z","iopub.execute_input":"2025-11-28T06:57:29.279536Z","iopub.status.idle":"2025-11-28T06:57:29.285279Z","shell.execute_reply.started":"2025-11-28T06:57:29.279514Z","shell.execute_reply":"2025-11-28T06:57:29.284675Z"},"collapsed":true,"jupyter":{"source_hidden":true,"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.plot(epoch_train_losses,label ='Train Loss')\nplt.plot(epoch_val_losses, label = 'Val Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.grid(True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T06:23:29.929480Z","iopub.execute_input":"2025-12-05T06:23:29.929826Z","iopub.status.idle":"2025-12-05T06:23:30.149002Z","shell.execute_reply.started":"2025-12-05T06:23:29.929802Z","shell.execute_reply":"2025-12-05T06:23:30.147975Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"plt.plot(epoch_train_accuracies, label = 'Train Accuracy')\nplt.plot(epoch_val_accuracies, label = 'Val Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel(\"Train Accuracy\")\nplt.legend()\nplt.grid(True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T06:23:32.445674Z","iopub.execute_input":"2025-12-05T06:23:32.446023Z","iopub.status.idle":"2025-12-05T06:23:32.647500Z","shell.execute_reply.started":"2025-12-05T06:23:32.445997Z","shell.execute_reply":"2025-12-05T06:23:32.646260Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"final_acc = epoch_train_accuracies[-1]\n\nfinal_loss = epoch_train_losses[-1]\n\nfinal_val_acc = epoch_val_accuracies[-1]\nfinal_val_loss = epoch_val_losses[-1]\n\nmax_train_acc = max(epoch_train_accuracies)\n\nprint(f'최종 학습 정확도 : {final_acc*100}')\nprint(f'최대 학습 정확도 : {max_train_acc*100}')\nprint(f'최종 검증 정확도 : {final_val_acc * 100}')\nprint(f'최대 검증 정확도 : {max(epoch_val_accuracies) * 100}')\n\n\nprint(f'최종 학습 Loss : {final_loss}')\nprint(f'최종 검증 loss : {final_val_loss}')\nprint(f'최소 학습 Loss : {min(epoch_train_losses)}')\nprint(f'최소 검증 Loss : {min(epoch_val_losses)}')\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T13:21:46.917281Z","iopub.execute_input":"2025-12-04T13:21:46.917589Z","iopub.status.idle":"2025-12-04T13:21:46.925714Z","shell.execute_reply.started":"2025-12-04T13:21:46.917567Z","shell.execute_reply":"2025-12-04T13:21:46.924701Z"}},"outputs":[{"name":"stdout","text":"최종 학습 정확도 : 11.725\n최대 학습 정확도 : 11.725\n최종 검증 정확도 : 18.07\n최대 검증 정확도 : 18.07\n최종 학습 Loss : 4.171926782593388\n최종 검증 loss : 3.736922735223374\n최소 학습 Loss : 4.171926782593388\n최소 검증 Loss : 3.736922735223374\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"# 1. 앞 1000개만 쓰는 subset 정의\nnum_small = 1000\nsmall_indices = list(range(num_small))\nsmall_train_dataset = Subset(train_dataset, small_indices)\n\n# 2. 작은 dataloader\nsmall_train_loader = DataLoader(\n    small_train_dataset,\n    batch_size=64,\n    shuffle=True,\n)\n\nsmall_val_dataset = Subset(val_dataset, small_indices)\n\n# 2. 작은 dataloader\nsmall_val_loader = DataLoader(\n    small_val_dataset,\n    batch_size=16,\n    shuffle=False,\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T02:39:16.927961Z","iopub.execute_input":"2025-12-04T02:39:16.928417Z","iopub.status.idle":"2025-12-04T02:39:16.935213Z","shell.execute_reply.started":"2025-12-04T02:39:16.928391Z","shell.execute_reply":"2025-12-04T02:39:16.934240Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"from collections import Counter\nimport numpy as np\n\nmodel.eval()\nall_preds = []\nall_labels = []\n\nwith torch.no_grad():\n    for x, y in small_train_loader:\n        x = x.to(device)\n        logits = model(x)\n        preds = logits.argmax(1).cpu().numpy()\n        all_preds.extend(list(preds))\n        all_labels.extend(list(y.numpy()))\n\nprint(\"pred label dist:\", Counter(all_preds))\nprint(\"true label dist:\", Counter(all_labels))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T05:42:29.560027Z","iopub.execute_input":"2025-12-01T05:42:29.560306Z","iopub.status.idle":"2025-12-01T05:42:31.898545Z","shell.execute_reply.started":"2025-12-01T05:42:29.560286Z","shell.execute_reply":"2025-12-01T05:42:31.897900Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 3. 3~5 epoch만 빠르게 돌려보기\nepoch_losses = []\nepoch_accuracies = []\nfor epoch in range(3):\n    epoch_loss = 0.0\n    correct = 0\n    total = 0\n    \n    for imgs, labels in small_train_loader:\n        model.train()\n        imgs, labels = imgs.to(device), labels.to(device)\n        optimizer.zero_grad()\n        logits = model(imgs)\n        loss = loss_fn(logits, labels)\n        loss.backward()\n        optimizer.step()\n\n        epoch_loss += loss.item() * imgs.size(0)\n        preds = logits.argmax(1)\n\n        print(f'preds : {preds}')\n        correct += (preds == labels).sum().item()\n        total += imgs.size(0)\n\n    with torch.no_grad():\n        for img,labels in small_val_loader:\n            model.eval()\n            # validate \n            # print(f'val img.shape : {img.shape }')\n            # B, ncrops, C, H, W = images.shape\n            # img = img.view(-1,C, H, W )\n            val_loss , val_true_prediction = validate(model, img,labels)\n            print(f'val loss :{val_loss}, val_accuracy : {val_true_prediction/labels.shape[0]}')\n        \n    print(f'[small] epoch {epoch} loss: {epoch_loss/total:.3f}, acc: {correct/total:.3f}')\n    epoch_losses.append(epoch_loss/total)\n    epoch_accuracies.append(correct/total)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T02:50:37.018698Z","iopub.execute_input":"2025-12-04T02:50:37.019032Z","iopub.status.idle":"2025-12-04T03:00:20.435790Z","shell.execute_reply.started":"2025-12-04T02:50:37.019007Z","shell.execute_reply":"2025-12-04T03:00:20.434420Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"preds : tensor([ 95, 153, 156,  29,  96, 140, 123,  93,  31,  93,  96,  70,  93, 154,\n        143,  31, 123,  84,  93,  48, 126, 156,  81,  93, 141,  70, 102, 172,\n         98, 129, 118,  21,  82, 129, 116,  31,  23,  59,  54, 123,  83,  96,\n         48, 118, 129,  29,  82,  96,  86, 159,  48,  60,  70, 145,  97,  78,\n        123, 147, 147,  43,  11,  43, 153, 172])\npreds : tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\npreds : tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\npreds : tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\npreds : tensor([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0])\npreds : tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\npreds : tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n        0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\npreds : tensor([1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n        1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\npreds : tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\npreds : tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\npreds : tensor([0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n        0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1,\n        1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0])\npreds : tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\npreds : tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\npreds : tensor([1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n        1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0,\n        1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0])\npreds : tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0,\n        1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0,\n        0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0])\npreds : tensor([1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\nVAL : 예측라벨 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], 정답 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\nval loss :1.0415995121002197, val_accuracy : 0.0\nVAL : 예측라벨 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], 정답 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\nval loss :1.0420546531677246, val_accuracy : 0.0\nVAL : 예측라벨 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], 정답 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\nval loss :1.0417444705963135, val_accuracy : 0.0\nVAL : 예측라벨 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], 정답 [0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\nval loss :0.5116612315177917, val_accuracy : 0.875\nVAL : 예측라벨 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], 정답 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\nval loss :0.43536102771759033, val_accuracy : 1.0\nVAL : 예측라벨 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], 정답 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\nval loss :0.43543195724487305, val_accuracy : 1.0\nVAL : 예측라벨 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], 정답 [1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2]\nval loss :17.8847599029541, val_accuracy : 0.25\nVAL : 예측라벨 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], 정답 [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\nval loss :23.700605392456055, val_accuracy : 0.0\nVAL : 예측라벨 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], 정답 [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\nval loss :23.700897216796875, val_accuracy : 0.0\nVAL : 예측라벨 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], 정답 [2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3]\nval loss :23.31629753112793, val_accuracy : 0.0\nVAL : 예측라벨 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], 정답 [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\nval loss :23.085880279541016, val_accuracy : 0.0\nVAL : 예측라벨 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], 정답 [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\nval loss :23.085935592651367, val_accuracy : 0.0\nVAL : 예측라벨 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], 정답 [3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4]\nval loss :23.586423873901367, val_accuracy : 0.0\nVAL : 예측라벨 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], 정답 [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\nval loss :24.087797164916992, val_accuracy : 0.0\nVAL : 예측라벨 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], 정답 [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\nval loss :24.087841033935547, val_accuracy : 0.0\nVAL : 예측라벨 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], 정답 [4 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5]\nval loss :23.975698471069336, val_accuracy : 0.0\nVAL : 예측라벨 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], 정답 [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\nval loss :23.788665771484375, val_accuracy : 0.0\nVAL : 예측라벨 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], 정답 [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\nval loss :23.78803825378418, val_accuracy : 0.0\nVAL : 예측라벨 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], 정답 [5 5 5 5 5 5 5 5 5 5 5 5 6 6 6 6]\nval loss :23.87175178527832, val_accuracy : 0.0\nVAL : 예측라벨 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], 정답 [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\nval loss :24.122352600097656, val_accuracy : 0.0\nVAL : 예측라벨 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], 정답 [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\nval loss :24.121891021728516, val_accuracy : 0.0\nVAL : 예측라벨 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], 정답 [6 6 6 6 6 6 6 6 6 6 6 6 6 6 7 7]\nval loss :24.11477279663086, val_accuracy : 0.0\nVAL : 예측라벨 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], 정답 [7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\nval loss :24.06171417236328, val_accuracy : 0.0\nVAL : 예측라벨 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], 정답 [7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\nval loss :24.061969757080078, val_accuracy : 0.0\nVAL : 예측라벨 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], 정답 [7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\nval loss :24.06121063232422, val_accuracy : 0.0\nVAL : 예측라벨 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], 정답 [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\nval loss :22.992847442626953, val_accuracy : 0.0\nVAL : 예측라벨 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], 정답 [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\nval loss :22.992124557495117, val_accuracy : 0.0\nVAL : 예측라벨 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], 정답 [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\nval loss :22.992223739624023, val_accuracy : 0.0\nVAL : 예측라벨 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], 정답 [8 8 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\nval loss :23.974979400634766, val_accuracy : 0.0\nVAL : 예측라벨 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], 정답 [9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\nval loss :24.115097045898438, val_accuracy : 0.0\nVAL : 예측라벨 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], 정답 [9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\nval loss :24.115100860595703, val_accuracy : 0.0\nVAL : 예측라벨 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], 정답 [ 9  9  9  9 10 10 10 10 10 10 10 10 10 10 10 10]\nval loss :23.883121490478516, val_accuracy : 0.0\nVAL : 예측라벨 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], 정답 [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10]\nval loss :23.8060245513916, val_accuracy : 0.0\nVAL : 예측라벨 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], 정답 [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10]\nval loss :23.8057861328125, val_accuracy : 0.0\nVAL : 예측라벨 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], 정답 [10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11]\nval loss :23.873395919799805, val_accuracy : 0.0\nVAL : 예측라벨 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], 정답 [11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11]\nval loss :23.91497230529785, val_accuracy : 0.0\nVAL : 예측라벨 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], 정답 [11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11]\nval loss :23.914522171020508, val_accuracy : 0.0\nVAL : 예측라벨 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], 정답 [11 11 11 11 11 11 11 11 12 12 12 12 12 12 12 12]\nval loss :23.951162338256836, val_accuracy : 0.0\nVAL : 예측라벨 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], 정답 [12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12]\nval loss :23.986896514892578, val_accuracy : 0.0\nVAL : 예측라벨 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], 정답 [12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12]\nval loss :23.986886978149414, val_accuracy : 0.0\nVAL : 예측라벨 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], 정답 [12 12 12 12 12 12 12 12 12 12 13 13 13 13 13 13]\nval loss :23.96840476989746, val_accuracy : 0.0\nVAL : 예측라벨 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], 정답 [13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13]\nval loss :23.937864303588867, val_accuracy : 0.0\nVAL : 예측라벨 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], 정답 [13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13]\nval loss :23.937726974487305, val_accuracy : 0.0\nVAL : 예측라벨 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], 정답 [13 13 13 13 13 13 13 13 13 13 13 13 14 14 14 14]\nval loss :23.855144500732422, val_accuracy : 0.0\nVAL : 예측라벨 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], 정답 [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14]\nval loss :23.608003616333008, val_accuracy : 0.0\nVAL : 예측라벨 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], 정답 [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14]\nval loss :23.607666015625, val_accuracy : 0.0\nVAL : 예측라벨 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], 정답 [14 14 14 14 14 14 14 14 14 14 14 14 14 14 15 15]\nval loss :23.71078109741211, val_accuracy : 0.0\nVAL : 예측라벨 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], 정답 [15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15]\nval loss :24.431976318359375, val_accuracy : 0.0\nVAL : 예측라벨 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], 정답 [15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15]\nval loss :24.432235717773438, val_accuracy : 0.0\nVAL : 예측라벨 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], 정답 [15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15]\nval loss :24.43100929260254, val_accuracy : 0.0\nVAL : 예측라벨 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], 정답 [16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16]\nval loss :24.376537322998047, val_accuracy : 0.0\nVAL : 예측라벨 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], 정답 [16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16]\nval loss :24.376760482788086, val_accuracy : 0.0\nVAL : 예측라벨 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], 정답 [16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16]\nval loss :24.376548767089844, val_accuracy : 0.0\nVAL : 예측라벨 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], 정답 [16 16 17 17 17 17 17 17 17 17 17 17 17 17 17 17]\nval loss :25.691762924194336, val_accuracy : 0.0\nVAL : 예측라벨 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], 정답 [17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17]\nval loss :25.880041122436523, val_accuracy : 0.0\nVAL : 예측라벨 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], 정답 [17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17]\nval loss :25.879701614379883, val_accuracy : 0.0\nVAL : 예측라벨 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], 정답 [17 17 17 17 18 18 18 18 18 18 18 18 18 18 18 18]\nval loss :24.457122802734375, val_accuracy : 0.0\nVAL : 예측라벨 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], 정답 [18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18]\nval loss :23.981550216674805, val_accuracy : 0.0\nVAL : 예측라벨 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], 정답 [18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18]\nval loss :23.98171615600586, val_accuracy : 0.0\nVAL : 예측라벨 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], 정답 [18 18 18 18 18 18 19 19 19 19 19 19 19 19 19 19]\nval loss :24.84672737121582, val_accuracy : 0.0\nVAL : 예측라벨 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], 정답 [19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19]\nval loss :25.364564895629883, val_accuracy : 0.0\nVAL : 예측라벨 : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], 정답 [19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19]\nval loss :25.363624572753906, val_accuracy : 0.0\nVAL : 예측라벨 : [1 1 1 1 1 1 1 1], 정답 [19 19 19 19 19 19 19 19]\nval loss :25.364994049072266, val_accuracy : 0.0\n[small] epoch 0 loss: 2.381, acc: 0.457\npreds : tensor([0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n        1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n        1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1])\npreds : tensor([0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1,\n        0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0])\npreds : tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1,\n        1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1])\npreds : tensor([1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0,\n        0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0,\n        0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0])\npreds : tensor([0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n        1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0,\n        0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1])\npreds : tensor([0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0,\n        1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0])\npreds : tensor([1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1])\npreds : tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1,\n        1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0,\n        1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1])\npreds : tensor([0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1,\n        1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0,\n        1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0])\npreds : tensor([1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1,\n        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0])\npreds : tensor([0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n        0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0])\npreds : tensor([1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0,\n        0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1,\n        1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1])\npreds : tensor([1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n        0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0,\n        1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1])\npreds : tensor([1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n        1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0,\n        0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1])\npreds : tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0,\n        1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1])\npreds : tensor([1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0,\n        1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1])\nVAL : 예측라벨 : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], 정답 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\nval loss :0.24142783880233765, val_accuracy : 1.0\nVAL : 예측라벨 : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], 정답 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\nval loss :0.24130120873451233, val_accuracy : 1.0\nVAL : 예측라벨 : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], 정답 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\nval loss :0.24130681157112122, val_accuracy : 1.0\nVAL : 예측라벨 : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], 정답 [0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\nval loss :1.3754568099975586, val_accuracy : 0.125\nVAL : 예측라벨 : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], 정답 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\nval loss :1.5377880334854126, val_accuracy : 0.0\nVAL : 예측라벨 : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], 정답 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\nval loss :1.5378365516662598, val_accuracy : 0.0\nVAL : 예측라벨 : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], 정답 [1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2]\nval loss :18.090436935424805, val_accuracy : 0.0\nVAL : 예측라벨 : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], 정답 [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\nval loss :23.60748291015625, val_accuracy : 0.0\nVAL : 예측라벨 : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], 정답 [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\nval loss :23.607444763183594, val_accuracy : 0.0\nVAL : 예측라벨 : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], 정답 [2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3]\nval loss :23.445838928222656, val_accuracy : 0.0\nVAL : 예측라벨 : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], 정답 [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\nval loss :23.349220275878906, val_accuracy : 0.0\nVAL : 예측라벨 : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], 정답 [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\nval loss :23.349136352539062, val_accuracy : 0.0\nVAL : 예측라벨 : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], 정답 [3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4]\nval loss :23.696821212768555, val_accuracy : 0.0\nVAL : 예측라벨 : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], 정답 [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\nval loss :24.044591903686523, val_accuracy : 0.0\nVAL : 예측라벨 : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], 정답 [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\nval loss :24.044532775878906, val_accuracy : 0.0\nVAL : 예측라벨 : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], 정답 [4 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5]\nval loss :23.97722625732422, val_accuracy : 0.0\nVAL : 예측라벨 : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], 정답 [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\nval loss :23.864723205566406, val_accuracy : 0.0\nVAL : 예측라벨 : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], 정답 [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\nval loss :23.864465713500977, val_accuracy : 0.0\nVAL : 예측라벨 : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], 정답 [5 5 5 5 5 5 5 5 5 5 5 5 6 6 6 6]\nval loss :23.95903205871582, val_accuracy : 0.0\nVAL : 예측라벨 : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], 정답 [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\nval loss :24.2424373626709, val_accuracy : 0.0\nVAL : 예측라벨 : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], 정답 [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\nval loss :24.242122650146484, val_accuracy : 0.0\nVAL : 예측라벨 : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], 정답 [6 6 6 6 6 6 6 6 6 6 6 6 6 6 7 7]\nval loss :24.243000030517578, val_accuracy : 0.0\nVAL : 예측라벨 : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], 정답 [7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\nval loss :24.249767303466797, val_accuracy : 0.0\nVAL : 예측라벨 : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], 정답 [7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\nval loss :24.249820709228516, val_accuracy : 0.0\nVAL : 예측라벨 : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], 정답 [7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\nval loss :24.24942398071289, val_accuracy : 0.0\nVAL : 예측라벨 : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], 정답 [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\nval loss :23.193044662475586, val_accuracy : 0.0\nVAL : 예측라벨 : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], 정답 [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\nval loss :23.193103790283203, val_accuracy : 0.0\nVAL : 예측라벨 : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], 정답 [8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\nval loss :23.19277572631836, val_accuracy : 0.0\nVAL : 예측라벨 : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], 정답 [8 8 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\nval loss :24.33271026611328, val_accuracy : 0.0\nVAL : 예측라벨 : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], 정답 [9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\nval loss :24.495182037353516, val_accuracy : 0.0\nVAL : 예측라벨 : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], 정답 [9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\nval loss :24.4952449798584, val_accuracy : 0.0\nVAL : 예측라벨 : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], 정답 [ 9  9  9  9 10 10 10 10 10 10 10 10 10 10 10 10]\nval loss :23.88022232055664, val_accuracy : 0.0\nVAL : 예측라벨 : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], 정답 [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10]\nval loss :23.67572593688965, val_accuracy : 0.0\nVAL : 예측라벨 : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], 정답 [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10]\nval loss :23.67559051513672, val_accuracy : 0.0\nVAL : 예측라벨 : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], 정답 [10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11]\nval loss :24.009340286254883, val_accuracy : 0.0\nVAL : 예측라벨 : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], 정답 [11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11]\nval loss :24.20977210998535, val_accuracy : 0.0\nVAL : 예측라벨 : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], 정답 [11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11]\nval loss :24.209814071655273, val_accuracy : 0.0\nVAL : 예측라벨 : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], 정답 [11 11 11 11 11 11 11 11 12 12 12 12 12 12 12 12]\nval loss :24.122663497924805, val_accuracy : 0.0\nVAL : 예측라벨 : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], 정답 [12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12]\nval loss :24.034912109375, val_accuracy : 0.0\nVAL : 예측라벨 : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], 정답 [12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12]\nval loss :24.03490447998047, val_accuracy : 0.0\nVAL : 예측라벨 : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], 정답 [12 12 12 12 12 12 12 12 12 12 13 13 13 13 13 13]\nval loss :23.98097801208496, val_accuracy : 0.0\nVAL : 예측라벨 : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], 정답 [13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13]\nval loss :23.891357421875, val_accuracy : 0.0\nVAL : 예측라벨 : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], 정답 [13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13]\nval loss :23.891571044921875, val_accuracy : 0.0\nVAL : 예측라벨 : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], 정답 [13 13 13 13 13 13 13 13 13 13 13 13 14 14 14 14]\nval loss :23.87908172607422, val_accuracy : 0.0\nVAL : 예측라벨 : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], 정답 [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14]\nval loss :23.841197967529297, val_accuracy : 0.0\nVAL : 예측라벨 : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], 정답 [14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14]\nval loss :23.841054916381836, val_accuracy : 0.0\nVAL : 예측라벨 : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], 정답 [14 14 14 14 14 14 14 14 14 14 14 14 14 14 15 15]\nval loss :23.968381881713867, val_accuracy : 0.0\nVAL : 예측라벨 : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], 정답 [15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15]\nval loss :24.85947036743164, val_accuracy : 0.0\nVAL : 예측라벨 : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], 정답 [15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15]\nval loss :24.859901428222656, val_accuracy : 0.0\nVAL : 예측라벨 : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], 정답 [15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15]\nval loss :24.858642578125, val_accuracy : 0.0\nVAL : 예측라벨 : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], 정답 [16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16]\nval loss :24.42965316772461, val_accuracy : 0.0\nVAL : 예측라벨 : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], 정답 [16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16]\nval loss :24.42942237854004, val_accuracy : 0.0\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_47/2033316765.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;31m# B, ncrops, C, H, W = images.shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;31m# img = img.view(-1,C, H, W )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mval_loss\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mval_true_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'val loss :{val_loss}, val_accuracy : {val_true_prediction/labels.shape[0]}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_47/828456332.py\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(model, data, label)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# bx10 , num_classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;31m# print(f'logits1.shape : {logits.shape}')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mflip\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_47/537886857.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;31m# print(f'x : {x.shape}')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0;31m#  Response Normalization 적용하기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mlrn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLocalResponseNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.75\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    547\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             )\n\u001b[0;32m--> 549\u001b[0;31m         return F.conv2d(\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m         )\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":22},{"cell_type":"code","source":"device = 'cuda' if( torch.cuda.is_available) else 'cpu'\ndevice","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T05:40:31.414030Z","iopub.execute_input":"2025-12-03T05:40:31.414290Z","iopub.status.idle":"2025-12-03T05:40:31.418071Z","shell.execute_reply.started":"2025-12-03T05:40:31.414274Z","shell.execute_reply":"2025-12-03T05:40:31.417288Z"}},"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}],"execution_count":42},{"cell_type":"code","source":"plt.plot(epoch_losses)\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title(\"Adam + lr : 1e-4\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T13:21:50.280060Z","iopub.status.idle":"2025-11-30T13:21:50.280361Z","shell.execute_reply.started":"2025-11-30T13:21:50.280191Z","shell.execute_reply":"2025-11-30T13:21:50.280207Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.plot(epoch_accuracies)\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.title(\"Adam + lr : 1e-4\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T13:49:36.555935Z","iopub.execute_input":"2025-11-27T13:49:36.556736Z","iopub.status.idle":"2025-11-27T13:49:36.738311Z","shell.execute_reply.started":"2025-11-27T13:49:36.556708Z","shell.execute_reply":"2025-11-27T13:49:36.737547Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for imgs, labels in small_train_loader:\n    print(np.unique(labels))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T13:25:20.531133Z","iopub.execute_input":"2025-11-27T13:25:20.531772Z","iopub.status.idle":"2025-11-27T13:25:22.378769Z","shell.execute_reply.started":"2025-11-27T13:25:20.531748Z","shell.execute_reply":"2025-11-27T13:25:22.377779Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"epoch_train_losses","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T13:42:10.845332Z","iopub.execute_input":"2025-12-01T13:42:10.845575Z","iopub.status.idle":"2025-12-01T13:42:10.849120Z","shell.execute_reply.started":"2025-12-01T13:42:10.845558Z","shell.execute_reply":"2025-12-01T13:42:10.848322Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"x0, y0 = train_dataset[0]      # #train_dataset[0] # 레이블 0인, 이미지들 \n\nx0 = x0.unsqueeze(0).to(device)\ny0 = torch.tensor([0], device=device)\nmodel.to(device)\nfor step in range(200):\n    optimizer.zero_grad()\n    logits = model(x0)\n    loss = loss_fn(logits, y0)\n    loss.backward()\n    optimizer.step()\n\n    pred = logits.argmax(1).item()\n    if step % 20 == 0:\n        print(step, \"loss:\", loss.item(), \"pred:\", pred)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T13:19:16.417314Z","iopub.execute_input":"2025-11-27T13:19:16.417675Z","iopub.status.idle":"2025-11-27T13:19:18.037418Z","shell.execute_reply.started":"2025-11-27T13:19:16.417643Z","shell.execute_reply":"2025-11-27T13:19:18.036753Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"images, labels = next(iter(train_dataloader))\nprint(\"batch label dist:\", np.bincount(labels.numpy()))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T12:44:51.811219Z","iopub.execute_input":"2025-11-27T12:44:51.811610Z","iopub.status.idle":"2025-11-27T12:44:52.438935Z","shell.execute_reply.started":"2025-11-27T12:44:51.811576Z","shell.execute_reply":"2025-11-27T12:44:52.437946Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nalex = torch.hub.load('pytorch/vision:v0.10.0', 'alexnet', pretrained=True)\nalex.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T12:46:35.202285Z","iopub.execute_input":"2025-11-27T12:46:35.203083Z","iopub.status.idle":"2025-11-27T12:46:35.957954Z","shell.execute_reply.started":"2025-11-27T12:46:35.203016Z","shell.execute_reply":"2025-11-27T12:46:35.957211Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"alex.classifier[6].out_features = 200\n\nalex","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T12:48:30.092725Z","iopub.execute_input":"2025-11-27T12:48:30.093037Z","iopub.status.idle":"2025-11-27T12:48:30.099022Z","shell.execute_reply.started":"2025-11-27T12:48:30.093016Z","shell.execute_reply":"2025-11-27T12:48:30.098307Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(val_dataloader.batch_size) # batch의 크기 33  , batch_size = 120\nlen(train_dataloader) # batch_size = 120 \n\nepoch_val_accuracies","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T13:42:33.566609Z","iopub.execute_input":"2025-12-01T13:42:33.566856Z","iopub.status.idle":"2025-12-01T13:42:33.570870Z","shell.execute_reply.started":"2025-12-01T13:42:33.566831Z","shell.execute_reply":"2025-12-01T13:42:33.570180Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.save(\n    {'epoch' : 4, # 4의 배치 483까지 돌아감\n     'batch' : 484,# 299부터 돌려야함\n    'model_state_dict':model.state_dict(),\n    'optimizer' : optimizer.state_dict(),\n    'train_loss': epoch_train_losses,\n    'val_loss': epoch_val_losses,\n     'train_accuracy' : epoch_train_accuracies,\n     'val_accuracy' : epoch_val_accuracies\n    }\n   ,'./alexnet_ckpt.pth')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T13:01:14.236284Z","iopub.execute_input":"2025-12-05T13:01:14.236715Z","iopub.status.idle":"2025-12-05T13:01:16.338662Z","shell.execute_reply.started":"2025-12-05T13:01:14.236669Z","shell.execute_reply":"2025-12-05T13:01:16.337556Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"checkpoint = torch.load('./alexnet_ckpt.pth',map_location = torch.device('cpu'),weights_only=False)\nmodel.load_state_dict(checkpoint['model_state_dict'])\noptimizer.load_state_dict(checkpoint['optimizer'])\nstart_epoch = checkpoint['epoch']+1\nepoch_train_losses = checkpoint['train_loss']\nepoch_val_losses = checkpoint['val_loss']\nepoch_train_accuracies = checkpoint['train_accuracy']\nepoch_val_accuracies = checkpoint['val_accuracy']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T06:25:19.945908Z","iopub.execute_input":"2025-12-05T06:25:19.946895Z","iopub.status.idle":"2025-12-05T06:25:20.493018Z","shell.execute_reply.started":"2025-12-05T06:25:19.946866Z","shell.execute_reply":"2025-12-05T06:25:20.491957Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"start_epoch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T01:40:59.351564Z","iopub.execute_input":"2025-12-05T01:40:59.352867Z","iopub.status.idle":"2025-12-05T01:40:59.359938Z","shell.execute_reply.started":"2025-12-05T01:40:59.352810Z","shell.execute_reply":"2025-12-05T01:40:59.358614Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"3"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T12:04:51.689828Z","iopub.execute_input":"2025-12-01T12:04:51.690125Z","iopub.status.idle":"2025-12-01T12:04:51.693863Z","shell.execute_reply.started":"2025-12-01T12:04:51.690104Z","shell.execute_reply":"2025-12-01T12:04:51.693105Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model2 =  Alexnet()\nmodel2.load_state_dict(torch.load('./model', weights_only=True))\nmodel2","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}